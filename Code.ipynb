{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x196d149a198>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 231,
       "width": 231
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,256),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(256,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(128,10),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_classifier(model, trainloader, testloader, learnrate):\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learnrate)\n",
    "\n",
    "    steps = 0\n",
    "    print_every = 50\n",
    "    epochs = 2\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            images = images.view(len(images),-1)\n",
    "            logps = model(images)\n",
    "            loss = criterion(logps, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            steps += 1\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                accuracy = 0\n",
    "                loss_test = 0\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for images, labels in testloader:\n",
    "                        images = images.view(len(images), -1)\n",
    "                        logps_test = model(images)\n",
    "                        loss_test += criterion(logps_test, labels)\n",
    "\n",
    "                        ps_test = torch.exp(logps_test)\n",
    "                        top_ps, top_class = ps_test.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                print(f'Epoch: {i+1}/{epochs} ',\n",
    "                      f'Training Loss: {running_loss/print_every:.3f} ',\n",
    "                      f'Test Loss: {loss_test/len(testloader):.3f} ',\n",
    "                      f'Test Accuracy: {accuracy/len(testloader):.3f}')\n",
    "                running_loss = 0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model and Update Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2  Training Loss: 1.140  Test Loss: 0.696  Test Accuracy: 0.747\n",
      "Epoch: 1/2  Training Loss: 0.691  Test Loss: 0.588  Test Accuracy: 0.779\n",
      "Epoch: 1/2  Training Loss: 0.651  Test Loss: 0.580  Test Accuracy: 0.785\n",
      "Epoch: 1/2  Training Loss: 0.580  Test Loss: 0.521  Test Accuracy: 0.806\n",
      "Epoch: 1/2  Training Loss: 0.535  Test Loss: 0.567  Test Accuracy: 0.788\n",
      "Epoch: 1/2  Training Loss: 0.535  Test Loss: 0.559  Test Accuracy: 0.789\n",
      "Epoch: 1/2  Training Loss: 0.526  Test Loss: 0.498  Test Accuracy: 0.816\n",
      "Epoch: 1/2  Training Loss: 0.509  Test Loss: 0.509  Test Accuracy: 0.816\n",
      "Epoch: 1/2  Training Loss: 0.492  Test Loss: 0.484  Test Accuracy: 0.823\n",
      "Epoch: 1/2  Training Loss: 0.495  Test Loss: 0.464  Test Accuracy: 0.828\n",
      "Epoch: 1/2  Training Loss: 0.498  Test Loss: 0.470  Test Accuracy: 0.829\n",
      "Epoch: 1/2  Training Loss: 0.468  Test Loss: 0.483  Test Accuracy: 0.823\n",
      "Epoch: 1/2  Training Loss: 0.472  Test Loss: 0.464  Test Accuracy: 0.830\n",
      "Epoch: 1/2  Training Loss: 0.459  Test Loss: 0.434  Test Accuracy: 0.843\n",
      "Epoch: 1/2  Training Loss: 0.451  Test Loss: 0.451  Test Accuracy: 0.839\n",
      "Epoch: 1/2  Training Loss: 0.457  Test Loss: 0.439  Test Accuracy: 0.839\n",
      "Epoch: 1/2  Training Loss: 0.444  Test Loss: 0.427  Test Accuracy: 0.843\n",
      "Epoch: 1/2  Training Loss: 0.434  Test Loss: 0.434  Test Accuracy: 0.840\n",
      "Epoch: 2/2  Training Loss: 0.087  Test Loss: 0.429  Test Accuracy: 0.845\n",
      "Epoch: 2/2  Training Loss: 0.415  Test Loss: 0.421  Test Accuracy: 0.842\n",
      "Epoch: 2/2  Training Loss: 0.452  Test Loss: 0.438  Test Accuracy: 0.840\n",
      "Epoch: 2/2  Training Loss: 0.432  Test Loss: 0.429  Test Accuracy: 0.842\n",
      "Epoch: 2/2  Training Loss: 0.444  Test Loss: 0.409  Test Accuracy: 0.848\n",
      "Epoch: 2/2  Training Loss: 0.405  Test Loss: 0.428  Test Accuracy: 0.845\n",
      "Epoch: 2/2  Training Loss: 0.423  Test Loss: 0.443  Test Accuracy: 0.843\n",
      "Epoch: 2/2  Training Loss: 0.421  Test Loss: 0.427  Test Accuracy: 0.844\n",
      "Epoch: 2/2  Training Loss: 0.404  Test Loss: 0.447  Test Accuracy: 0.833\n",
      "Epoch: 2/2  Training Loss: 0.410  Test Loss: 0.416  Test Accuracy: 0.846\n",
      "Epoch: 2/2  Training Loss: 0.419  Test Loss: 0.412  Test Accuracy: 0.849\n",
      "Epoch: 2/2  Training Loss: 0.416  Test Loss: 0.399  Test Accuracy: 0.850\n",
      "Epoch: 2/2  Training Loss: 0.388  Test Loss: 0.423  Test Accuracy: 0.850\n",
      "Epoch: 2/2  Training Loss: 0.422  Test Loss: 0.396  Test Accuracy: 0.855\n",
      "Epoch: 2/2  Training Loss: 0.396  Test Loss: 0.413  Test Accuracy: 0.848\n",
      "Epoch: 2/2  Training Loss: 0.394  Test Loss: 0.384  Test Accuracy: 0.859\n",
      "Epoch: 2/2  Training Loss: 0.372  Test Loss: 0.401  Test Accuracy: 0.854\n",
      "Epoch: 2/2  Training Loss: 0.416  Test Loss: 0.429  Test Accuracy: 0.847\n",
      "Epoch: 2/2  Training Loss: 0.383  Test Loss: 0.404  Test Accuracy: 0.851\n"
     ]
    }
   ],
   "source": [
    "model = model_classifier(model, trainloader, testloader, learnrate = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
    "\n",
    "The parameters for PyTorch networks are stored in a model's state_dict. We can see the state dict contains the weight and bias matrices for each of our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.2, inplace=False)\n",
      "  (6): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (7): LogSoftmax(dim=1)\n",
      ") \n",
      "\n",
      "The State Dict Keys \n",
      "\n",
      " odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias'])\n",
      "\n",
      " Updated Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[-1.8237e-02, -1.2456e-02, -3.3074e-02,  ..., -3.3185e-02,\n",
      "          1.2241e-05,  3.2015e-02],\n",
      "        [-5.7487e-02, -1.3906e-02, -4.4339e-02,  ..., -6.6442e-02,\n",
      "         -1.5064e-03, -1.3628e-02],\n",
      "        [-3.9085e-02, -5.3777e-02, -5.3834e-03,  ..., -3.5771e-02,\n",
      "         -5.1605e-02, -5.8616e-02],\n",
      "        ...,\n",
      "        [ 3.0376e-02,  2.0349e-02,  8.2986e-03,  ..., -5.8738e-03,\n",
      "          2.3354e-02,  1.4291e-03],\n",
      "        [ 5.3443e-02,  4.9977e-02,  2.0228e-02,  ...,  2.2779e-02,\n",
      "          4.1622e-02, -5.8922e-03],\n",
      "        [-1.1122e-02, -1.5371e-02,  2.1072e-02,  ...,  2.7892e-03,\n",
      "         -6.4000e-03, -2.3272e-02]])), ('0.bias', tensor([-2.1945e-02, -3.8062e-03,  7.0595e-02, -3.9122e-02, -2.7458e-02,\n",
      "        -3.7317e-02, -3.5384e-02, -5.4028e-02, -3.5895e-02, -1.0654e-02,\n",
      "         4.6649e-03, -2.0078e-02, -6.7733e-03, -4.0449e-02, -3.6234e-02,\n",
      "        -3.6078e-02, -1.6943e-02, -3.4679e-02,  4.3581e-03,  3.3778e-03,\n",
      "        -3.2545e-02, -5.6637e-02, -3.0140e-03,  2.8434e-03,  8.5097e-03,\n",
      "        -1.2159e-02, -2.8923e-02,  1.7233e-02, -3.3035e-02, -5.7876e-02,\n",
      "         2.4580e-02,  3.4918e-02,  1.2542e-03, -3.0805e-02,  7.3043e-03,\n",
      "         1.1872e-02, -5.7695e-03, -9.3192e-03,  8.8589e-03,  2.7369e-02,\n",
      "        -3.7828e-02,  9.3914e-04, -2.3670e-02,  6.4658e-03, -2.6454e-02,\n",
      "         1.4098e-02, -4.8351e-02, -2.3331e-02,  1.0899e-02, -6.5493e-02,\n",
      "        -3.5870e-02, -6.8158e-03, -8.2568e-04, -1.8889e-02, -7.5442e-02,\n",
      "        -3.2026e-02, -1.6899e-02, -2.3800e-03,  1.4411e-03, -2.6999e-02,\n",
      "        -2.3295e-03,  7.0197e-03, -4.4017e-03,  3.3737e-02, -7.2898e-03,\n",
      "         2.2088e-02, -4.5507e-02, -4.2669e-02, -1.1572e-02, -3.0772e-02,\n",
      "        -4.0646e-02,  3.0275e-02, -2.5402e-02,  2.5202e-02, -2.3627e-02,\n",
      "         1.0977e-03, -3.7234e-02, -1.5188e-02, -5.5469e-02, -1.5863e-02,\n",
      "         3.0666e-02, -1.5342e-02,  8.9206e-03,  2.5101e-04,  2.1902e-02,\n",
      "         1.8001e-02, -4.5124e-03, -3.5011e-02, -1.0843e-02, -4.5702e-02,\n",
      "        -1.9961e-02, -4.0651e-03, -6.7355e-03,  2.0679e-02, -1.4629e-02,\n",
      "        -1.8928e-02, -4.8855e-03, -4.2691e-02, -1.5767e-02,  3.2624e-03,\n",
      "        -4.7455e-02,  1.9699e-02, -9.9819e-03, -1.8694e-02, -1.0756e-02,\n",
      "        -1.9090e-02, -3.4328e-02, -4.2515e-02,  1.9330e-02, -4.9765e-02,\n",
      "         2.5744e-02, -4.9161e-03, -1.5234e-02, -3.5700e-03,  6.1691e-03,\n",
      "         4.1640e-03, -3.1263e-04,  1.1087e-03, -3.7247e-03, -1.2106e-02,\n",
      "        -3.7172e-02, -9.5518e-03, -3.5829e-02,  1.6553e-02, -3.6950e-02,\n",
      "        -8.5524e-03, -4.1531e-02, -5.2834e-02, -2.0141e-02,  1.5168e-02,\n",
      "        -6.0152e-03, -6.6813e-03, -2.0494e-02, -2.2279e-02, -5.1544e-03,\n",
      "         1.8343e-02,  2.2732e-02, -2.7678e-02, -7.7718e-03, -2.0068e-02,\n",
      "         1.8735e-02, -1.8635e-02, -2.4394e-02,  6.0135e-02, -3.3149e-02,\n",
      "        -1.8148e-02,  8.2134e-03, -1.8979e-02, -3.6010e-03,  1.1431e-02,\n",
      "         9.2628e-03, -6.1311e-03,  6.1579e-03, -1.6165e-02, -2.5014e-03,\n",
      "        -2.4449e-02, -8.5824e-03,  1.3554e-02, -7.4027e-02, -7.7435e-03,\n",
      "        -4.4888e-02, -2.2763e-02,  6.8386e-04,  2.0946e-02,  9.2549e-03,\n",
      "        -8.5557e-03,  3.2451e-02, -5.1435e-02, -3.6367e-02, -1.1157e-02,\n",
      "         4.9722e-03, -3.9401e-02, -2.9913e-02, -2.5854e-02,  3.0775e-02,\n",
      "        -2.1133e-04,  1.8281e-02, -3.9566e-02,  1.8461e-02, -3.7829e-03,\n",
      "         3.0486e-03, -4.8859e-03, -1.0103e-02, -1.7040e-02,  2.2291e-02,\n",
      "         4.8119e-03, -4.1733e-02, -4.0708e-02, -3.4994e-02, -1.0440e-02,\n",
      "        -5.2141e-02, -4.2774e-02, -1.1533e-02,  2.9106e-02,  3.4778e-03,\n",
      "        -2.2810e-02, -1.1569e-02,  4.5635e-03, -4.5871e-02,  1.1996e-03,\n",
      "         1.0151e-02, -1.5144e-02, -3.9439e-02, -5.0761e-02, -1.1345e-02,\n",
      "        -3.0454e-02,  2.9014e-02,  6.9574e-02, -4.5187e-02, -5.0584e-02,\n",
      "        -1.0652e-02, -5.7089e-03, -3.4882e-02, -3.4317e-02,  1.2238e-02,\n",
      "        -5.9401e-02, -6.6046e-03, -3.6132e-02, -1.4391e-02, -2.7932e-02,\n",
      "        -1.2442e-02,  2.5588e-03, -4.2052e-02, -5.1504e-02, -7.6741e-04,\n",
      "        -1.7772e-02,  2.0827e-02, -1.1206e-02, -3.1520e-02, -1.4308e-02,\n",
      "        -5.2045e-02, -2.8801e-02,  5.1163e-03, -5.7807e-02,  5.5257e-03,\n",
      "         1.8874e-02,  1.4427e-02, -3.1049e-02,  2.2746e-02, -5.0435e-02,\n",
      "         1.0840e-02, -2.2085e-02, -2.4467e-02,  1.4248e-02, -1.8957e-02,\n",
      "        -3.2259e-02, -4.9151e-03,  2.3247e-04, -5.6236e-02, -1.8674e-05,\n",
      "         7.4806e-03, -5.8888e-03, -1.5223e-02,  9.8124e-03, -3.1892e-02,\n",
      "        -7.6608e-04])), ('3.weight', tensor([[-2.7857e-02,  2.5303e-02, -2.5239e-02,  ..., -1.6580e-02,\n",
      "         -1.8431e-02, -1.3608e-02],\n",
      "        [ 2.4703e-02,  4.9209e-03, -5.3573e-02,  ..., -7.0647e-05,\n",
      "         -1.0849e-01, -3.5972e-02],\n",
      "        [-8.1634e-02,  2.2133e-02, -6.9569e-02,  ...,  3.4278e-02,\n",
      "          5.0518e-02,  2.5558e-02],\n",
      "        ...,\n",
      "        [ 5.3153e-02, -3.3958e-02, -1.3393e-01,  ..., -1.2402e-02,\n",
      "          1.1348e-01,  6.4385e-02],\n",
      "        [ 3.0527e-02, -1.3787e-01,  3.7568e-02,  ..., -5.0094e-02,\n",
      "          5.2052e-02,  2.6557e-02],\n",
      "        [ 8.4433e-02,  1.9722e-01,  4.1149e-02,  ...,  7.0486e-02,\n",
      "          1.6050e-01, -1.2795e-02]])), ('3.bias', tensor([ 0.0001, -0.0077,  0.0487,  0.0738,  0.0519,  0.0888, -0.0170,  0.0289,\n",
      "        -0.0181, -0.0067,  0.0132, -0.0182,  0.0071,  0.0543,  0.0486,  0.0398,\n",
      "         0.0805, -0.0480,  0.0121,  0.0667,  0.0849,  0.0157, -0.0065, -0.0047,\n",
      "         0.0034,  0.0167,  0.0419, -0.0409, -0.0401,  0.0206, -0.0344, -0.0022,\n",
      "         0.0272,  0.0908,  0.0502,  0.0180,  0.0192,  0.0691,  0.0405, -0.0203,\n",
      "         0.0187,  0.0313,  0.0426, -0.0080, -0.0100,  0.0604, -0.0385,  0.0165,\n",
      "         0.0448, -0.0493,  0.0849,  0.0620,  0.0220,  0.0809,  0.0471,  0.0710,\n",
      "        -0.0272,  0.0030,  0.0761,  0.0565,  0.0164, -0.0074, -0.0096, -0.0676,\n",
      "         0.0596, -0.0165, -0.0153, -0.0052, -0.0012,  0.0185, -0.0436, -0.0710,\n",
      "         0.0027, -0.0118,  0.0230, -0.0400,  0.0584,  0.0148,  0.0048, -0.0155,\n",
      "        -0.0246,  0.0583, -0.0394,  0.0189,  0.0725,  0.1057, -0.0407,  0.0439,\n",
      "        -0.0450,  0.0351, -0.0548,  0.0287, -0.0037,  0.0303, -0.0286, -0.0391,\n",
      "        -0.0343,  0.0084,  0.0114,  0.0159, -0.0026,  0.0303, -0.0317, -0.0109,\n",
      "         0.0534,  0.0052, -0.0021, -0.0847,  0.0361,  0.0299, -0.0719,  0.1112,\n",
      "         0.0309, -0.0632, -0.0481,  0.0695, -0.0273, -0.0214,  0.0893, -0.0099,\n",
      "        -0.0497,  0.0353, -0.0456,  0.0126, -0.0184,  0.0532, -0.0071,  0.0315])), ('6.weight', tensor([[-0.0123, -0.1325,  0.0592,  ...,  0.0356,  0.0440,  0.0159],\n",
      "        [-0.1361, -0.0352, -0.0503,  ..., -0.0451,  0.0718,  0.1387],\n",
      "        [-0.0105, -0.0647,  0.0272,  ..., -0.1559,  0.0960, -0.0050],\n",
      "        ...,\n",
      "        [-0.0240,  0.0730,  0.0101,  ...,  0.0747, -0.2306, -0.0561],\n",
      "        [ 0.0665,  0.0948,  0.0195,  ..., -0.1175, -0.0568,  0.0580],\n",
      "        [-0.0314, -0.0661, -0.1587,  ...,  0.0872, -0.0791, -0.0706]])), ('6.bias', tensor([ 0.0086, -0.0191, -0.0349,  0.1023,  0.0439, -0.0238, -0.0458, -0.0102,\n",
      "        -0.0345, -0.0241]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The State Dict Keys \\n\\n\", model.state_dict().keys())\n",
    "print(\"\\n Updated Weights & Bias \\n\\n\", model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save state_dict of trained model to the file 'model_save.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_save.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define a new model with the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = nn.Sequential(nn.Linear(784,256),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(256,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(128,10),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly initial weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random (Initial) Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[ 2.8938e-02,  3.4191e-02,  2.8179e-02,  ...,  3.6585e-03,\n",
      "         -4.1004e-03, -2.6044e-05],\n",
      "        [-1.4645e-02, -2.5215e-02, -3.3820e-02,  ...,  1.2206e-02,\n",
      "          3.5478e-02, -1.6743e-02],\n",
      "        [ 1.7446e-02, -3.0919e-02, -2.8210e-02,  ..., -3.2175e-02,\n",
      "          1.7067e-02,  2.3889e-02],\n",
      "        ...,\n",
      "        [-1.2997e-02,  2.0965e-02,  1.0596e-02,  ...,  1.1728e-02,\n",
      "         -7.1311e-03,  2.2190e-02],\n",
      "        [-1.5601e-02, -1.9358e-03,  6.2410e-03,  ..., -2.9804e-02,\n",
      "          2.6205e-02, -5.0250e-03],\n",
      "        [-6.0843e-03,  7.2321e-03, -2.3176e-02,  ...,  6.7067e-03,\n",
      "          8.6357e-03,  2.7227e-02]])), ('0.bias', tensor([-2.4501e-02,  2.3262e-03, -9.8405e-04,  3.4239e-02,  3.4529e-02,\n",
      "         2.1217e-02,  2.4215e-02,  2.4014e-02, -2.6450e-02,  7.8406e-03,\n",
      "         1.2935e-03,  1.6229e-02,  3.4904e-02,  2.6604e-02,  1.4109e-02,\n",
      "         2.5701e-02, -6.6797e-03, -4.3051e-03, -1.9710e-02, -3.5110e-02,\n",
      "         2.8293e-02, -7.4518e-03, -1.5396e-02, -2.9049e-02,  2.4183e-02,\n",
      "         7.4108e-03, -3.3300e-03, -1.2320e-02, -2.3103e-03, -1.8669e-02,\n",
      "        -4.0301e-03, -2.1701e-02, -9.1521e-03, -3.1694e-02,  1.3119e-02,\n",
      "         1.5084e-02, -5.4645e-03,  2.3081e-02,  2.0304e-02, -2.6580e-02,\n",
      "         1.2017e-02,  3.4889e-02,  1.4810e-03, -1.1574e-02, -3.5641e-02,\n",
      "         1.9451e-02,  1.2063e-02, -3.4590e-02,  2.1369e-02,  1.5635e-02,\n",
      "         6.7353e-05, -1.0184e-02, -7.0479e-03,  2.5726e-02,  2.3840e-02,\n",
      "        -1.6739e-02, -2.8385e-02, -2.2482e-02, -4.4718e-03,  3.2930e-02,\n",
      "         1.2235e-02,  1.4299e-02,  2.1324e-02,  1.2872e-02,  2.6230e-02,\n",
      "        -6.7123e-03, -8.8292e-03,  2.5405e-02,  2.5985e-02,  1.6119e-02,\n",
      "         1.7171e-02,  1.8136e-02,  2.4918e-02,  2.0399e-02,  1.4711e-02,\n",
      "         3.2998e-02, -2.7084e-02, -3.6830e-03,  1.5885e-02,  2.0929e-02,\n",
      "        -1.7039e-02,  9.2351e-03, -4.0228e-03,  4.9493e-03, -1.7012e-03,\n",
      "         2.2287e-02,  3.4776e-02,  1.7737e-02,  3.1793e-02,  1.8829e-02,\n",
      "        -2.9850e-02,  2.7486e-03, -3.3391e-03, -1.6428e-03, -1.8503e-02,\n",
      "         2.0764e-02, -1.3899e-02,  2.9700e-02,  1.7401e-02, -7.3416e-03,\n",
      "        -3.4452e-02, -3.2398e-02, -4.9110e-03,  9.1080e-03, -2.5574e-02,\n",
      "         3.0546e-02,  1.5500e-02,  3.1065e-03, -1.8329e-02, -2.0967e-02,\n",
      "         2.7181e-02, -3.2162e-02, -4.2800e-03, -3.2646e-02,  1.7396e-02,\n",
      "         4.4147e-03,  3.4751e-03, -1.9633e-03, -1.3739e-02,  1.4896e-02,\n",
      "        -4.2660e-03,  1.3801e-02, -8.7073e-03, -3.1873e-02,  2.3961e-03,\n",
      "        -1.7425e-02,  2.2738e-02,  1.9111e-02,  2.2723e-02, -3.1560e-03,\n",
      "        -2.3972e-02, -9.0113e-03, -3.3021e-02, -2.0044e-02, -2.6023e-03,\n",
      "         1.6983e-02, -1.1689e-02, -7.9685e-03, -1.6751e-02, -3.5032e-02,\n",
      "         2.8356e-02, -2.8271e-02, -1.0107e-02, -1.9605e-02,  2.1949e-02,\n",
      "        -2.8690e-02, -2.0051e-02, -2.8568e-02,  5.5443e-03, -1.3440e-02,\n",
      "         2.6108e-02,  2.3455e-02, -7.6605e-03,  1.9404e-02,  2.5197e-02,\n",
      "         1.0757e-02,  2.8127e-03,  4.8696e-03,  1.5063e-02, -6.8511e-03,\n",
      "        -3.3827e-02, -1.5783e-02, -1.4253e-02,  1.9059e-02, -1.1543e-02,\n",
      "        -2.4998e-02, -1.8041e-02,  1.7150e-02,  2.4620e-02,  2.9830e-02,\n",
      "         3.5151e-02,  1.9755e-03,  2.3214e-04,  2.3808e-02,  3.2348e-02,\n",
      "        -1.0488e-02,  1.0014e-02,  1.8609e-02,  3.7401e-03, -5.0959e-03,\n",
      "        -2.8240e-02, -5.9088e-03, -5.1038e-04,  2.6959e-02,  3.1403e-02,\n",
      "         1.8314e-02,  2.6746e-02, -2.3642e-02,  1.9601e-02, -1.6216e-03,\n",
      "        -4.3614e-03, -2.0882e-03,  3.1106e-02, -1.6846e-02,  8.0891e-03,\n",
      "        -2.1757e-02,  2.0852e-04,  3.3350e-02, -2.8382e-02, -3.1935e-02,\n",
      "        -3.2450e-02, -6.0918e-03, -2.7510e-02,  1.0793e-02, -5.6088e-03,\n",
      "        -1.9521e-02,  1.3272e-02,  1.9753e-03, -8.1175e-03, -2.1637e-03,\n",
      "        -2.6929e-02,  1.6337e-02,  3.3017e-02, -1.0039e-02,  6.3276e-04,\n",
      "        -9.4023e-03,  2.8246e-02,  2.3926e-02,  2.3362e-02, -3.4766e-02,\n",
      "        -2.3870e-02, -1.9951e-02, -1.0472e-02, -2.6865e-02, -1.5670e-02,\n",
      "         2.9364e-02, -3.0000e-02, -1.0379e-02,  1.5173e-02,  8.7961e-03,\n",
      "        -1.0778e-02, -1.2283e-02,  1.8275e-02, -5.9389e-03,  2.2419e-02,\n",
      "        -1.0689e-02, -2.2263e-02, -2.5829e-02, -7.9167e-03,  2.2399e-03,\n",
      "        -3.0160e-02, -1.0844e-03,  2.5367e-02, -1.5941e-02, -3.3358e-02,\n",
      "        -6.7248e-03,  1.3519e-02,  1.0101e-02, -1.9355e-02,  3.2748e-02,\n",
      "        -1.8524e-02, -2.7400e-02, -2.4365e-02, -2.1103e-02, -3.4761e-02,\n",
      "        -2.8129e-02])), ('3.weight', tensor([[-0.0364,  0.0456,  0.0591,  ..., -0.0356,  0.0204,  0.0512],\n",
      "        [-0.0379,  0.0412,  0.0272,  ...,  0.0438,  0.0441,  0.0541],\n",
      "        [-0.0582, -0.0336, -0.0519,  ..., -0.0208,  0.0322,  0.0585],\n",
      "        ...,\n",
      "        [-0.0491, -0.0068,  0.0424,  ..., -0.0104,  0.0076, -0.0450],\n",
      "        [-0.0422,  0.0266, -0.0190,  ..., -0.0012,  0.0074, -0.0256],\n",
      "        [-0.0301, -0.0548, -0.0122,  ..., -0.0293, -0.0245, -0.0139]])), ('3.bias', tensor([ 0.0236, -0.0396, -0.0385,  0.0369,  0.0483,  0.0298,  0.0409,  0.0594,\n",
      "         0.0413, -0.0340, -0.0358,  0.0096, -0.0285, -0.0333,  0.0110,  0.0308,\n",
      "        -0.0133,  0.0202,  0.0431,  0.0457, -0.0106,  0.0585,  0.0469, -0.0218,\n",
      "         0.0038, -0.0026, -0.0307, -0.0491, -0.0402, -0.0470, -0.0305, -0.0371,\n",
      "         0.0218,  0.0577,  0.0190, -0.0454,  0.0344,  0.0593,  0.0536, -0.0295,\n",
      "        -0.0253, -0.0546,  0.0563,  0.0575, -0.0302, -0.0232,  0.0568,  0.0338,\n",
      "         0.0460,  0.0136,  0.0620, -0.0589, -0.0191,  0.0108, -0.0613,  0.0280,\n",
      "         0.0382,  0.0082, -0.0094,  0.0057,  0.0189,  0.0321,  0.0121,  0.0199,\n",
      "        -0.0261, -0.0284, -0.0429, -0.0308,  0.0375, -0.0614, -0.0183, -0.0274,\n",
      "         0.0321, -0.0227, -0.0499,  0.0379,  0.0452,  0.0090,  0.0533, -0.0303,\n",
      "        -0.0275,  0.0441,  0.0603, -0.0585,  0.0353, -0.0221,  0.0372, -0.0294,\n",
      "         0.0054,  0.0464, -0.0056,  0.0318,  0.0142,  0.0572, -0.0402,  0.0320,\n",
      "         0.0544,  0.0513, -0.0430,  0.0071, -0.0562, -0.0117,  0.0587,  0.0428,\n",
      "         0.0470,  0.0325, -0.0603,  0.0563,  0.0297,  0.0221, -0.0591,  0.0597,\n",
      "        -0.0040, -0.0270,  0.0544, -0.0414,  0.0042, -0.0044,  0.0025, -0.0131,\n",
      "        -0.0070, -0.0169, -0.0365,  0.0326, -0.0354, -0.0112, -0.0598,  0.0244])), ('6.weight', tensor([[ 0.0464,  0.0352, -0.0325,  ..., -0.0678, -0.0008, -0.0867],\n",
      "        [-0.0107,  0.0113, -0.0631,  ..., -0.0620, -0.0115, -0.0709],\n",
      "        [-0.0031, -0.0700, -0.0593,  ..., -0.0271, -0.0852,  0.0160],\n",
      "        ...,\n",
      "        [ 0.0716, -0.0229,  0.0216,  ...,  0.0267, -0.0709,  0.0302],\n",
      "        [-0.0468, -0.0145, -0.0376,  ...,  0.0805,  0.0331,  0.0256],\n",
      "        [-0.0690, -0.0407,  0.0711,  ..., -0.0126, -0.0258, -0.0235]])), ('6.bias', tensor([-0.0439,  0.0749,  0.0744, -0.0415,  0.0296, -0.0614,  0.0827, -0.0616,\n",
      "         0.0787, -0.0182]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Random (Initial) Weights & Bias \\n\\n\", model1.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the state dict with torch.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict_saved = torch.load('model_save.pth')\n",
    "print(state_dict_saved.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the state dict into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(state_dict_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[-1.8237e-02, -1.2456e-02, -3.3074e-02,  ..., -3.3185e-02,\n",
      "          1.2241e-05,  3.2015e-02],\n",
      "        [-5.7487e-02, -1.3906e-02, -4.4339e-02,  ..., -6.6442e-02,\n",
      "         -1.5064e-03, -1.3628e-02],\n",
      "        [-3.9085e-02, -5.3777e-02, -5.3834e-03,  ..., -3.5771e-02,\n",
      "         -5.1605e-02, -5.8616e-02],\n",
      "        ...,\n",
      "        [ 3.0376e-02,  2.0349e-02,  8.2986e-03,  ..., -5.8738e-03,\n",
      "          2.3354e-02,  1.4291e-03],\n",
      "        [ 5.3443e-02,  4.9977e-02,  2.0228e-02,  ...,  2.2779e-02,\n",
      "          4.1622e-02, -5.8922e-03],\n",
      "        [-1.1122e-02, -1.5371e-02,  2.1072e-02,  ...,  2.7892e-03,\n",
      "         -6.4000e-03, -2.3272e-02]])), ('0.bias', tensor([-2.1945e-02, -3.8062e-03,  7.0595e-02, -3.9122e-02, -2.7458e-02,\n",
      "        -3.7317e-02, -3.5384e-02, -5.4028e-02, -3.5895e-02, -1.0654e-02,\n",
      "         4.6649e-03, -2.0078e-02, -6.7733e-03, -4.0449e-02, -3.6234e-02,\n",
      "        -3.6078e-02, -1.6943e-02, -3.4679e-02,  4.3581e-03,  3.3778e-03,\n",
      "        -3.2545e-02, -5.6637e-02, -3.0140e-03,  2.8434e-03,  8.5097e-03,\n",
      "        -1.2159e-02, -2.8923e-02,  1.7233e-02, -3.3035e-02, -5.7876e-02,\n",
      "         2.4580e-02,  3.4918e-02,  1.2542e-03, -3.0805e-02,  7.3043e-03,\n",
      "         1.1872e-02, -5.7695e-03, -9.3192e-03,  8.8589e-03,  2.7369e-02,\n",
      "        -3.7828e-02,  9.3914e-04, -2.3670e-02,  6.4658e-03, -2.6454e-02,\n",
      "         1.4098e-02, -4.8351e-02, -2.3331e-02,  1.0899e-02, -6.5493e-02,\n",
      "        -3.5870e-02, -6.8158e-03, -8.2568e-04, -1.8889e-02, -7.5442e-02,\n",
      "        -3.2026e-02, -1.6899e-02, -2.3800e-03,  1.4411e-03, -2.6999e-02,\n",
      "        -2.3295e-03,  7.0197e-03, -4.4017e-03,  3.3737e-02, -7.2898e-03,\n",
      "         2.2088e-02, -4.5507e-02, -4.2669e-02, -1.1572e-02, -3.0772e-02,\n",
      "        -4.0646e-02,  3.0275e-02, -2.5402e-02,  2.5202e-02, -2.3627e-02,\n",
      "         1.0977e-03, -3.7234e-02, -1.5188e-02, -5.5469e-02, -1.5863e-02,\n",
      "         3.0666e-02, -1.5342e-02,  8.9206e-03,  2.5101e-04,  2.1902e-02,\n",
      "         1.8001e-02, -4.5124e-03, -3.5011e-02, -1.0843e-02, -4.5702e-02,\n",
      "        -1.9961e-02, -4.0651e-03, -6.7355e-03,  2.0679e-02, -1.4629e-02,\n",
      "        -1.8928e-02, -4.8855e-03, -4.2691e-02, -1.5767e-02,  3.2624e-03,\n",
      "        -4.7455e-02,  1.9699e-02, -9.9819e-03, -1.8694e-02, -1.0756e-02,\n",
      "        -1.9090e-02, -3.4328e-02, -4.2515e-02,  1.9330e-02, -4.9765e-02,\n",
      "         2.5744e-02, -4.9161e-03, -1.5234e-02, -3.5700e-03,  6.1691e-03,\n",
      "         4.1640e-03, -3.1263e-04,  1.1087e-03, -3.7247e-03, -1.2106e-02,\n",
      "        -3.7172e-02, -9.5518e-03, -3.5829e-02,  1.6553e-02, -3.6950e-02,\n",
      "        -8.5524e-03, -4.1531e-02, -5.2834e-02, -2.0141e-02,  1.5168e-02,\n",
      "        -6.0152e-03, -6.6813e-03, -2.0494e-02, -2.2279e-02, -5.1544e-03,\n",
      "         1.8343e-02,  2.2732e-02, -2.7678e-02, -7.7718e-03, -2.0068e-02,\n",
      "         1.8735e-02, -1.8635e-02, -2.4394e-02,  6.0135e-02, -3.3149e-02,\n",
      "        -1.8148e-02,  8.2134e-03, -1.8979e-02, -3.6010e-03,  1.1431e-02,\n",
      "         9.2628e-03, -6.1311e-03,  6.1579e-03, -1.6165e-02, -2.5014e-03,\n",
      "        -2.4449e-02, -8.5824e-03,  1.3554e-02, -7.4027e-02, -7.7435e-03,\n",
      "        -4.4888e-02, -2.2763e-02,  6.8386e-04,  2.0946e-02,  9.2549e-03,\n",
      "        -8.5557e-03,  3.2451e-02, -5.1435e-02, -3.6367e-02, -1.1157e-02,\n",
      "         4.9722e-03, -3.9401e-02, -2.9913e-02, -2.5854e-02,  3.0775e-02,\n",
      "        -2.1133e-04,  1.8281e-02, -3.9566e-02,  1.8461e-02, -3.7829e-03,\n",
      "         3.0486e-03, -4.8859e-03, -1.0103e-02, -1.7040e-02,  2.2291e-02,\n",
      "         4.8119e-03, -4.1733e-02, -4.0708e-02, -3.4994e-02, -1.0440e-02,\n",
      "        -5.2141e-02, -4.2774e-02, -1.1533e-02,  2.9106e-02,  3.4778e-03,\n",
      "        -2.2810e-02, -1.1569e-02,  4.5635e-03, -4.5871e-02,  1.1996e-03,\n",
      "         1.0151e-02, -1.5144e-02, -3.9439e-02, -5.0761e-02, -1.1345e-02,\n",
      "        -3.0454e-02,  2.9014e-02,  6.9574e-02, -4.5187e-02, -5.0584e-02,\n",
      "        -1.0652e-02, -5.7089e-03, -3.4882e-02, -3.4317e-02,  1.2238e-02,\n",
      "        -5.9401e-02, -6.6046e-03, -3.6132e-02, -1.4391e-02, -2.7932e-02,\n",
      "        -1.2442e-02,  2.5588e-03, -4.2052e-02, -5.1504e-02, -7.6741e-04,\n",
      "        -1.7772e-02,  2.0827e-02, -1.1206e-02, -3.1520e-02, -1.4308e-02,\n",
      "        -5.2045e-02, -2.8801e-02,  5.1163e-03, -5.7807e-02,  5.5257e-03,\n",
      "         1.8874e-02,  1.4427e-02, -3.1049e-02,  2.2746e-02, -5.0435e-02,\n",
      "         1.0840e-02, -2.2085e-02, -2.4467e-02,  1.4248e-02, -1.8957e-02,\n",
      "        -3.2259e-02, -4.9151e-03,  2.3247e-04, -5.6236e-02, -1.8674e-05,\n",
      "         7.4806e-03, -5.8888e-03, -1.5223e-02,  9.8124e-03, -3.1892e-02,\n",
      "        -7.6608e-04])), ('3.weight', tensor([[-2.7857e-02,  2.5303e-02, -2.5239e-02,  ..., -1.6580e-02,\n",
      "         -1.8431e-02, -1.3608e-02],\n",
      "        [ 2.4703e-02,  4.9209e-03, -5.3573e-02,  ..., -7.0647e-05,\n",
      "         -1.0849e-01, -3.5972e-02],\n",
      "        [-8.1634e-02,  2.2133e-02, -6.9569e-02,  ...,  3.4278e-02,\n",
      "          5.0518e-02,  2.5558e-02],\n",
      "        ...,\n",
      "        [ 5.3153e-02, -3.3958e-02, -1.3393e-01,  ..., -1.2402e-02,\n",
      "          1.1348e-01,  6.4385e-02],\n",
      "        [ 3.0527e-02, -1.3787e-01,  3.7568e-02,  ..., -5.0094e-02,\n",
      "          5.2052e-02,  2.6557e-02],\n",
      "        [ 8.4433e-02,  1.9722e-01,  4.1149e-02,  ...,  7.0486e-02,\n",
      "          1.6050e-01, -1.2795e-02]])), ('3.bias', tensor([ 0.0001, -0.0077,  0.0487,  0.0738,  0.0519,  0.0888, -0.0170,  0.0289,\n",
      "        -0.0181, -0.0067,  0.0132, -0.0182,  0.0071,  0.0543,  0.0486,  0.0398,\n",
      "         0.0805, -0.0480,  0.0121,  0.0667,  0.0849,  0.0157, -0.0065, -0.0047,\n",
      "         0.0034,  0.0167,  0.0419, -0.0409, -0.0401,  0.0206, -0.0344, -0.0022,\n",
      "         0.0272,  0.0908,  0.0502,  0.0180,  0.0192,  0.0691,  0.0405, -0.0203,\n",
      "         0.0187,  0.0313,  0.0426, -0.0080, -0.0100,  0.0604, -0.0385,  0.0165,\n",
      "         0.0448, -0.0493,  0.0849,  0.0620,  0.0220,  0.0809,  0.0471,  0.0710,\n",
      "        -0.0272,  0.0030,  0.0761,  0.0565,  0.0164, -0.0074, -0.0096, -0.0676,\n",
      "         0.0596, -0.0165, -0.0153, -0.0052, -0.0012,  0.0185, -0.0436, -0.0710,\n",
      "         0.0027, -0.0118,  0.0230, -0.0400,  0.0584,  0.0148,  0.0048, -0.0155,\n",
      "        -0.0246,  0.0583, -0.0394,  0.0189,  0.0725,  0.1057, -0.0407,  0.0439,\n",
      "        -0.0450,  0.0351, -0.0548,  0.0287, -0.0037,  0.0303, -0.0286, -0.0391,\n",
      "        -0.0343,  0.0084,  0.0114,  0.0159, -0.0026,  0.0303, -0.0317, -0.0109,\n",
      "         0.0534,  0.0052, -0.0021, -0.0847,  0.0361,  0.0299, -0.0719,  0.1112,\n",
      "         0.0309, -0.0632, -0.0481,  0.0695, -0.0273, -0.0214,  0.0893, -0.0099,\n",
      "        -0.0497,  0.0353, -0.0456,  0.0126, -0.0184,  0.0532, -0.0071,  0.0315])), ('6.weight', tensor([[-0.0123, -0.1325,  0.0592,  ...,  0.0356,  0.0440,  0.0159],\n",
      "        [-0.1361, -0.0352, -0.0503,  ..., -0.0451,  0.0718,  0.1387],\n",
      "        [-0.0105, -0.0647,  0.0272,  ..., -0.1559,  0.0960, -0.0050],\n",
      "        ...,\n",
      "        [-0.0240,  0.0730,  0.0101,  ...,  0.0747, -0.2306, -0.0561],\n",
      "        [ 0.0665,  0.0948,  0.0195,  ..., -0.1175, -0.0568,  0.0580],\n",
      "        [-0.0314, -0.0661, -0.1587,  ...,  0.0872, -0.0791, -0.0706]])), ('6.bias', tensor([ 0.0086, -0.0191, -0.0349,  0.1023,  0.0439, -0.0238, -0.0458, -0.0102,\n",
      "        -0.0345, -0.0241]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights & Bias \\n\\n\", model1.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the saved model architecture. If we create a model with a different architecture, this fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.Sequential(nn.Linear(784,250),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(250,125),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(125,10),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([256, 784]) from checkpoint, the shape in current model is torch.Size([250, 784]).\n\tsize mismatch for 0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([250]).\n\tsize mismatch for 3.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([125, 250]).\n\tsize mismatch for 3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([125]).\n\tsize mismatch for 6.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 125]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a628f7be4a8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict_saved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1045\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([256, 784]) from checkpoint, the shape in current model is torch.Size([250, 784]).\n\tsize mismatch for 0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([250]).\n\tsize mismatch for 3.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([125, 250]).\n\tsize mismatch for 3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([125]).\n\tsize mismatch for 6.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 125])."
     ]
    }
   ],
   "source": [
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model2.load_state_dict(state_dict_saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Model with Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the 'model_save.pth', along with the state dict. To do this, we build a dictionary with all the information we need to compeletely rebuild the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model with model dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter               # for getting specific layers (hidden layers) while saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\"input_size\" : 784,\n",
    "              \"output_size\" : 10,\n",
    "              \"hidden_layers\" : [each.out_features for each in itemgetter(0,3,6)(model)],  #0,3,6 - hidden layers with weights & bias\n",
    "              \"state_dict\" : model.state_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, 'model_save2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Model dimensions, Weights & Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint1 = torch.load('model_save2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = checkpoint1['input_size']\n",
    "out_size = checkpoint1['output_size']\n",
    "hidden_size = checkpoint1['hidden_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = nn.Sequential(nn.Linear(in_size,hidden_size[0]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(hidden_size[0],hidden_size[1]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(hidden_size[1],hidden_size[2]),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random (Initial) Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[ 0.0291,  0.0217,  0.0087,  ..., -0.0248,  0.0110, -0.0151],\n",
      "        [ 0.0295, -0.0120,  0.0121,  ...,  0.0136, -0.0138,  0.0224],\n",
      "        [-0.0335, -0.0272,  0.0264,  ..., -0.0069,  0.0124,  0.0038],\n",
      "        ...,\n",
      "        [-0.0134,  0.0320,  0.0041,  ...,  0.0284, -0.0152,  0.0179],\n",
      "        [-0.0337,  0.0345,  0.0016,  ..., -0.0214, -0.0327, -0.0315],\n",
      "        [-0.0256,  0.0026, -0.0003,  ...,  0.0079, -0.0068, -0.0120]])), ('0.bias', tensor([ 0.0195,  0.0122, -0.0253, -0.0272,  0.0072, -0.0012, -0.0289, -0.0324,\n",
      "        -0.0054,  0.0246,  0.0087, -0.0112, -0.0088, -0.0242,  0.0173,  0.0214,\n",
      "        -0.0162, -0.0122,  0.0240, -0.0288, -0.0265,  0.0030, -0.0330,  0.0311,\n",
      "         0.0340, -0.0197,  0.0029,  0.0101,  0.0302,  0.0174, -0.0128,  0.0325,\n",
      "         0.0165,  0.0163, -0.0041, -0.0155,  0.0349, -0.0171, -0.0177, -0.0076,\n",
      "         0.0242, -0.0119, -0.0112, -0.0342, -0.0041, -0.0310, -0.0310, -0.0113,\n",
      "        -0.0229,  0.0296, -0.0202, -0.0008,  0.0044, -0.0120, -0.0332,  0.0189,\n",
      "         0.0289, -0.0307,  0.0350,  0.0250,  0.0103, -0.0120, -0.0076, -0.0311,\n",
      "         0.0222,  0.0310, -0.0095,  0.0307,  0.0295, -0.0303, -0.0144,  0.0127,\n",
      "         0.0070,  0.0202,  0.0283, -0.0103,  0.0063, -0.0274, -0.0283,  0.0262,\n",
      "         0.0009, -0.0255, -0.0256,  0.0304,  0.0313, -0.0331, -0.0265, -0.0213,\n",
      "        -0.0010,  0.0128,  0.0074,  0.0174,  0.0163, -0.0157, -0.0020,  0.0079,\n",
      "         0.0198,  0.0330,  0.0067,  0.0306, -0.0222,  0.0111,  0.0031, -0.0124,\n",
      "         0.0098, -0.0041, -0.0146, -0.0195,  0.0235, -0.0171, -0.0031, -0.0285,\n",
      "        -0.0256,  0.0015, -0.0202,  0.0179, -0.0066,  0.0237,  0.0352, -0.0321,\n",
      "         0.0288, -0.0055,  0.0232,  0.0111, -0.0278,  0.0146, -0.0302, -0.0128,\n",
      "        -0.0133, -0.0163, -0.0006,  0.0285, -0.0209, -0.0202, -0.0022, -0.0338,\n",
      "        -0.0081,  0.0286,  0.0307,  0.0142,  0.0239, -0.0065,  0.0255,  0.0042,\n",
      "        -0.0346, -0.0162, -0.0343, -0.0334,  0.0094,  0.0079,  0.0127, -0.0053,\n",
      "        -0.0292, -0.0227, -0.0146,  0.0155,  0.0054, -0.0252,  0.0245,  0.0054,\n",
      "         0.0086,  0.0202,  0.0240, -0.0346, -0.0339,  0.0201, -0.0146, -0.0251,\n",
      "         0.0137,  0.0099,  0.0127,  0.0010, -0.0327, -0.0110,  0.0135,  0.0305,\n",
      "        -0.0100,  0.0067, -0.0021,  0.0252,  0.0116, -0.0058, -0.0042,  0.0274,\n",
      "         0.0320,  0.0091, -0.0196, -0.0330, -0.0188,  0.0134, -0.0269,  0.0085,\n",
      "        -0.0297, -0.0243, -0.0258,  0.0152, -0.0285,  0.0207,  0.0213, -0.0198,\n",
      "         0.0033,  0.0292,  0.0055,  0.0301, -0.0076, -0.0228,  0.0037,  0.0278,\n",
      "        -0.0010, -0.0123, -0.0339,  0.0332, -0.0118, -0.0345, -0.0179, -0.0200,\n",
      "        -0.0291,  0.0154,  0.0007,  0.0011, -0.0282, -0.0324, -0.0235, -0.0051,\n",
      "         0.0052,  0.0006, -0.0201,  0.0243, -0.0210,  0.0343,  0.0190,  0.0317,\n",
      "         0.0184,  0.0089,  0.0138, -0.0182,  0.0286,  0.0322,  0.0350,  0.0059,\n",
      "         0.0305,  0.0084, -0.0087,  0.0073,  0.0166,  0.0201,  0.0089, -0.0281,\n",
      "         0.0079, -0.0242,  0.0316, -0.0333,  0.0341, -0.0231, -0.0244, -0.0027])), ('3.weight', tensor([[ 0.0441,  0.0044,  0.0232,  ...,  0.0478, -0.0330, -0.0563],\n",
      "        [-0.0200,  0.0498,  0.0118,  ...,  0.0219, -0.0444,  0.0531],\n",
      "        [-0.0179, -0.0222, -0.0432,  ...,  0.0117,  0.0179,  0.0582],\n",
      "        ...,\n",
      "        [-0.0126, -0.0300,  0.0316,  ..., -0.0373,  0.0063, -0.0383],\n",
      "        [-0.0422, -0.0100, -0.0407,  ..., -0.0571, -0.0291,  0.0043],\n",
      "        [-0.0278,  0.0507, -0.0588,  ..., -0.0051, -0.0037, -0.0228]])), ('3.bias', tensor([-0.0401,  0.0329, -0.0390, -0.0187,  0.0358,  0.0038, -0.0138, -0.0475,\n",
      "         0.0253, -0.0166, -0.0430, -0.0477, -0.0285, -0.0320, -0.0422,  0.0265,\n",
      "        -0.0583, -0.0431,  0.0038, -0.0082, -0.0561,  0.0563,  0.0155, -0.0206,\n",
      "         0.0291,  0.0538,  0.0021,  0.0366, -0.0418,  0.0142,  0.0338, -0.0036,\n",
      "        -0.0219, -0.0334, -0.0538, -0.0185, -0.0339, -0.0410,  0.0061, -0.0516,\n",
      "         0.0507, -0.0179,  0.0198,  0.0024, -0.0283,  0.0591, -0.0195, -0.0138,\n",
      "        -0.0014, -0.0012,  0.0387,  0.0310,  0.0347, -0.0083,  0.0530,  0.0205,\n",
      "        -0.0335,  0.0412,  0.0198,  0.0251,  0.0578, -0.0017,  0.0318,  0.0264,\n",
      "         0.0211,  0.0527,  0.0010,  0.0200, -0.0101, -0.0090, -0.0098,  0.0260,\n",
      "         0.0551, -0.0331, -0.0417, -0.0263, -0.0028, -0.0026,  0.0406,  0.0547,\n",
      "         0.0290, -0.0105, -0.0092,  0.0418, -0.0232, -0.0164, -0.0600,  0.0233,\n",
      "         0.0222,  0.0135, -0.0357, -0.0046, -0.0619,  0.0245,  0.0081, -0.0297,\n",
      "        -0.0446, -0.0480,  0.0526, -0.0193, -0.0492, -0.0049, -0.0032,  0.0051,\n",
      "        -0.0257,  0.0148,  0.0136,  0.0031,  0.0452,  0.0086,  0.0333,  0.0027,\n",
      "        -0.0141,  0.0371, -0.0595, -0.0408, -0.0520, -0.0194,  0.0248, -0.0351,\n",
      "        -0.0588,  0.0414,  0.0051,  0.0596,  0.0423, -0.0565, -0.0292,  0.0036])), ('6.weight', tensor([[ 0.0815, -0.0077, -0.0440,  ...,  0.0158,  0.0796,  0.0272],\n",
      "        [-0.0313,  0.0298,  0.0471,  ..., -0.0661,  0.0488, -0.0724],\n",
      "        [-0.0804, -0.0436, -0.0661,  ..., -0.0009,  0.0540, -0.0267],\n",
      "        ...,\n",
      "        [ 0.0319,  0.0750, -0.0754,  ..., -0.0836, -0.0651, -0.0581],\n",
      "        [-0.0221, -0.0465, -0.0279,  ...,  0.0877,  0.0716, -0.0840],\n",
      "        [ 0.0558, -0.0332, -0.0679,  ...,  0.0196, -0.0079,  0.0790]])), ('6.bias', tensor([-0.0119, -0.0003, -0.0298,  0.0244, -0.0292, -0.0321,  0.0555, -0.0797,\n",
      "         0.0665,  0.0026]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Random (Initial) Weights & Bias \\n\\n\", model3.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.load_state_dict(checkpoint1['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[-1.8237e-02, -1.2456e-02, -3.3074e-02,  ..., -3.3185e-02,\n",
      "          1.2241e-05,  3.2015e-02],\n",
      "        [-5.7487e-02, -1.3906e-02, -4.4339e-02,  ..., -6.6442e-02,\n",
      "         -1.5064e-03, -1.3628e-02],\n",
      "        [-3.9085e-02, -5.3777e-02, -5.3834e-03,  ..., -3.5771e-02,\n",
      "         -5.1605e-02, -5.8616e-02],\n",
      "        ...,\n",
      "        [ 3.0376e-02,  2.0349e-02,  8.2986e-03,  ..., -5.8738e-03,\n",
      "          2.3354e-02,  1.4291e-03],\n",
      "        [ 5.3443e-02,  4.9977e-02,  2.0228e-02,  ...,  2.2779e-02,\n",
      "          4.1622e-02, -5.8922e-03],\n",
      "        [-1.1122e-02, -1.5371e-02,  2.1072e-02,  ...,  2.7892e-03,\n",
      "         -6.4000e-03, -2.3272e-02]])), ('0.bias', tensor([-2.1945e-02, -3.8062e-03,  7.0595e-02, -3.9122e-02, -2.7458e-02,\n",
      "        -3.7317e-02, -3.5384e-02, -5.4028e-02, -3.5895e-02, -1.0654e-02,\n",
      "         4.6649e-03, -2.0078e-02, -6.7733e-03, -4.0449e-02, -3.6234e-02,\n",
      "        -3.6078e-02, -1.6943e-02, -3.4679e-02,  4.3581e-03,  3.3778e-03,\n",
      "        -3.2545e-02, -5.6637e-02, -3.0140e-03,  2.8434e-03,  8.5097e-03,\n",
      "        -1.2159e-02, -2.8923e-02,  1.7233e-02, -3.3035e-02, -5.7876e-02,\n",
      "         2.4580e-02,  3.4918e-02,  1.2542e-03, -3.0805e-02,  7.3043e-03,\n",
      "         1.1872e-02, -5.7695e-03, -9.3192e-03,  8.8589e-03,  2.7369e-02,\n",
      "        -3.7828e-02,  9.3914e-04, -2.3670e-02,  6.4658e-03, -2.6454e-02,\n",
      "         1.4098e-02, -4.8351e-02, -2.3331e-02,  1.0899e-02, -6.5493e-02,\n",
      "        -3.5870e-02, -6.8158e-03, -8.2568e-04, -1.8889e-02, -7.5442e-02,\n",
      "        -3.2026e-02, -1.6899e-02, -2.3800e-03,  1.4411e-03, -2.6999e-02,\n",
      "        -2.3295e-03,  7.0197e-03, -4.4017e-03,  3.3737e-02, -7.2898e-03,\n",
      "         2.2088e-02, -4.5507e-02, -4.2669e-02, -1.1572e-02, -3.0772e-02,\n",
      "        -4.0646e-02,  3.0275e-02, -2.5402e-02,  2.5202e-02, -2.3627e-02,\n",
      "         1.0977e-03, -3.7234e-02, -1.5188e-02, -5.5469e-02, -1.5863e-02,\n",
      "         3.0666e-02, -1.5342e-02,  8.9206e-03,  2.5101e-04,  2.1902e-02,\n",
      "         1.8001e-02, -4.5124e-03, -3.5011e-02, -1.0843e-02, -4.5702e-02,\n",
      "        -1.9961e-02, -4.0651e-03, -6.7355e-03,  2.0679e-02, -1.4629e-02,\n",
      "        -1.8928e-02, -4.8855e-03, -4.2691e-02, -1.5767e-02,  3.2624e-03,\n",
      "        -4.7455e-02,  1.9699e-02, -9.9819e-03, -1.8694e-02, -1.0756e-02,\n",
      "        -1.9090e-02, -3.4328e-02, -4.2515e-02,  1.9330e-02, -4.9765e-02,\n",
      "         2.5744e-02, -4.9161e-03, -1.5234e-02, -3.5700e-03,  6.1691e-03,\n",
      "         4.1640e-03, -3.1263e-04,  1.1087e-03, -3.7247e-03, -1.2106e-02,\n",
      "        -3.7172e-02, -9.5518e-03, -3.5829e-02,  1.6553e-02, -3.6950e-02,\n",
      "        -8.5524e-03, -4.1531e-02, -5.2834e-02, -2.0141e-02,  1.5168e-02,\n",
      "        -6.0152e-03, -6.6813e-03, -2.0494e-02, -2.2279e-02, -5.1544e-03,\n",
      "         1.8343e-02,  2.2732e-02, -2.7678e-02, -7.7718e-03, -2.0068e-02,\n",
      "         1.8735e-02, -1.8635e-02, -2.4394e-02,  6.0135e-02, -3.3149e-02,\n",
      "        -1.8148e-02,  8.2134e-03, -1.8979e-02, -3.6010e-03,  1.1431e-02,\n",
      "         9.2628e-03, -6.1311e-03,  6.1579e-03, -1.6165e-02, -2.5014e-03,\n",
      "        -2.4449e-02, -8.5824e-03,  1.3554e-02, -7.4027e-02, -7.7435e-03,\n",
      "        -4.4888e-02, -2.2763e-02,  6.8386e-04,  2.0946e-02,  9.2549e-03,\n",
      "        -8.5557e-03,  3.2451e-02, -5.1435e-02, -3.6367e-02, -1.1157e-02,\n",
      "         4.9722e-03, -3.9401e-02, -2.9913e-02, -2.5854e-02,  3.0775e-02,\n",
      "        -2.1133e-04,  1.8281e-02, -3.9566e-02,  1.8461e-02, -3.7829e-03,\n",
      "         3.0486e-03, -4.8859e-03, -1.0103e-02, -1.7040e-02,  2.2291e-02,\n",
      "         4.8119e-03, -4.1733e-02, -4.0708e-02, -3.4994e-02, -1.0440e-02,\n",
      "        -5.2141e-02, -4.2774e-02, -1.1533e-02,  2.9106e-02,  3.4778e-03,\n",
      "        -2.2810e-02, -1.1569e-02,  4.5635e-03, -4.5871e-02,  1.1996e-03,\n",
      "         1.0151e-02, -1.5144e-02, -3.9439e-02, -5.0761e-02, -1.1345e-02,\n",
      "        -3.0454e-02,  2.9014e-02,  6.9574e-02, -4.5187e-02, -5.0584e-02,\n",
      "        -1.0652e-02, -5.7089e-03, -3.4882e-02, -3.4317e-02,  1.2238e-02,\n",
      "        -5.9401e-02, -6.6046e-03, -3.6132e-02, -1.4391e-02, -2.7932e-02,\n",
      "        -1.2442e-02,  2.5588e-03, -4.2052e-02, -5.1504e-02, -7.6741e-04,\n",
      "        -1.7772e-02,  2.0827e-02, -1.1206e-02, -3.1520e-02, -1.4308e-02,\n",
      "        -5.2045e-02, -2.8801e-02,  5.1163e-03, -5.7807e-02,  5.5257e-03,\n",
      "         1.8874e-02,  1.4427e-02, -3.1049e-02,  2.2746e-02, -5.0435e-02,\n",
      "         1.0840e-02, -2.2085e-02, -2.4467e-02,  1.4248e-02, -1.8957e-02,\n",
      "        -3.2259e-02, -4.9151e-03,  2.3247e-04, -5.6236e-02, -1.8674e-05,\n",
      "         7.4806e-03, -5.8888e-03, -1.5223e-02,  9.8124e-03, -3.1892e-02,\n",
      "        -7.6608e-04])), ('3.weight', tensor([[-2.7857e-02,  2.5303e-02, -2.5239e-02,  ..., -1.6580e-02,\n",
      "         -1.8431e-02, -1.3608e-02],\n",
      "        [ 2.4703e-02,  4.9209e-03, -5.3573e-02,  ..., -7.0647e-05,\n",
      "         -1.0849e-01, -3.5972e-02],\n",
      "        [-8.1634e-02,  2.2133e-02, -6.9569e-02,  ...,  3.4278e-02,\n",
      "          5.0518e-02,  2.5558e-02],\n",
      "        ...,\n",
      "        [ 5.3153e-02, -3.3958e-02, -1.3393e-01,  ..., -1.2402e-02,\n",
      "          1.1348e-01,  6.4385e-02],\n",
      "        [ 3.0527e-02, -1.3787e-01,  3.7568e-02,  ..., -5.0094e-02,\n",
      "          5.2052e-02,  2.6557e-02],\n",
      "        [ 8.4433e-02,  1.9722e-01,  4.1149e-02,  ...,  7.0486e-02,\n",
      "          1.6050e-01, -1.2795e-02]])), ('3.bias', tensor([ 0.0001, -0.0077,  0.0487,  0.0738,  0.0519,  0.0888, -0.0170,  0.0289,\n",
      "        -0.0181, -0.0067,  0.0132, -0.0182,  0.0071,  0.0543,  0.0486,  0.0398,\n",
      "         0.0805, -0.0480,  0.0121,  0.0667,  0.0849,  0.0157, -0.0065, -0.0047,\n",
      "         0.0034,  0.0167,  0.0419, -0.0409, -0.0401,  0.0206, -0.0344, -0.0022,\n",
      "         0.0272,  0.0908,  0.0502,  0.0180,  0.0192,  0.0691,  0.0405, -0.0203,\n",
      "         0.0187,  0.0313,  0.0426, -0.0080, -0.0100,  0.0604, -0.0385,  0.0165,\n",
      "         0.0448, -0.0493,  0.0849,  0.0620,  0.0220,  0.0809,  0.0471,  0.0710,\n",
      "        -0.0272,  0.0030,  0.0761,  0.0565,  0.0164, -0.0074, -0.0096, -0.0676,\n",
      "         0.0596, -0.0165, -0.0153, -0.0052, -0.0012,  0.0185, -0.0436, -0.0710,\n",
      "         0.0027, -0.0118,  0.0230, -0.0400,  0.0584,  0.0148,  0.0048, -0.0155,\n",
      "        -0.0246,  0.0583, -0.0394,  0.0189,  0.0725,  0.1057, -0.0407,  0.0439,\n",
      "        -0.0450,  0.0351, -0.0548,  0.0287, -0.0037,  0.0303, -0.0286, -0.0391,\n",
      "        -0.0343,  0.0084,  0.0114,  0.0159, -0.0026,  0.0303, -0.0317, -0.0109,\n",
      "         0.0534,  0.0052, -0.0021, -0.0847,  0.0361,  0.0299, -0.0719,  0.1112,\n",
      "         0.0309, -0.0632, -0.0481,  0.0695, -0.0273, -0.0214,  0.0893, -0.0099,\n",
      "        -0.0497,  0.0353, -0.0456,  0.0126, -0.0184,  0.0532, -0.0071,  0.0315])), ('6.weight', tensor([[-0.0123, -0.1325,  0.0592,  ...,  0.0356,  0.0440,  0.0159],\n",
      "        [-0.1361, -0.0352, -0.0503,  ..., -0.0451,  0.0718,  0.1387],\n",
      "        [-0.0105, -0.0647,  0.0272,  ..., -0.1559,  0.0960, -0.0050],\n",
      "        ...,\n",
      "        [-0.0240,  0.0730,  0.0101,  ...,  0.0747, -0.2306, -0.0561],\n",
      "        [ 0.0665,  0.0948,  0.0195,  ..., -0.1175, -0.0568,  0.0580],\n",
      "        [-0.0314, -0.0661, -0.1587,  ...,  0.0872, -0.0791, -0.0706]])), ('6.bias', tensor([ 0.0086, -0.0191, -0.0349,  0.1023,  0.0439, -0.0238, -0.0458, -0.0102,\n",
      "        -0.0345, -0.0241]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded Weights & Bias \\n\\n\", model3.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
