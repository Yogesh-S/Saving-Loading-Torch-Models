{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ab26ef4828>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 231,
       "width": 231
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,256),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(256,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[-0.0224,  0.0122,  0.0071,  ..., -0.0343, -0.0114, -0.0071],\n",
      "        [-0.0148,  0.0174,  0.0332,  ..., -0.0302, -0.0046, -0.0259],\n",
      "        [ 0.0244,  0.0176,  0.0189,  ...,  0.0081,  0.0227, -0.0051],\n",
      "        ...,\n",
      "        [-0.0232,  0.0312, -0.0016,  ..., -0.0199,  0.0069,  0.0068],\n",
      "        [-0.0097, -0.0139,  0.0182,  ...,  0.0221,  0.0055,  0.0128],\n",
      "        [ 0.0025, -0.0021,  0.0335,  ..., -0.0282, -0.0059, -0.0296]])), ('0.bias', tensor([ 0.0019, -0.0043, -0.0190, -0.0311, -0.0290,  0.0236,  0.0096, -0.0237,\n",
      "         0.0065, -0.0128,  0.0136,  0.0164, -0.0140,  0.0057,  0.0259, -0.0035,\n",
      "         0.0122,  0.0118, -0.0176,  0.0262,  0.0271, -0.0116, -0.0169,  0.0141,\n",
      "        -0.0113, -0.0185,  0.0163, -0.0003,  0.0143, -0.0097,  0.0046, -0.0113,\n",
      "         0.0355,  0.0351,  0.0028, -0.0071,  0.0133, -0.0197, -0.0356,  0.0217,\n",
      "        -0.0083, -0.0061, -0.0204, -0.0003, -0.0021,  0.0352,  0.0028, -0.0069,\n",
      "         0.0124,  0.0045,  0.0040,  0.0033, -0.0297, -0.0037, -0.0238,  0.0055,\n",
      "         0.0252,  0.0111, -0.0041,  0.0168,  0.0095,  0.0180, -0.0331, -0.0139,\n",
      "        -0.0007,  0.0049, -0.0206, -0.0093,  0.0106, -0.0250, -0.0286, -0.0067,\n",
      "         0.0160, -0.0309, -0.0239,  0.0038, -0.0226,  0.0131,  0.0152, -0.0276,\n",
      "         0.0232, -0.0080, -0.0346, -0.0244,  0.0057,  0.0018, -0.0095,  0.0321,\n",
      "         0.0163, -0.0135,  0.0245, -0.0286,  0.0016, -0.0321, -0.0147, -0.0255,\n",
      "        -0.0256, -0.0138, -0.0168, -0.0092,  0.0311, -0.0049,  0.0018, -0.0248,\n",
      "        -0.0112, -0.0005,  0.0314, -0.0049, -0.0027, -0.0263, -0.0115,  0.0240,\n",
      "         0.0092, -0.0237, -0.0275,  0.0133,  0.0355,  0.0256, -0.0154, -0.0338,\n",
      "         0.0111, -0.0310,  0.0343,  0.0215, -0.0270, -0.0123, -0.0132,  0.0300,\n",
      "        -0.0212,  0.0155,  0.0273,  0.0074, -0.0279, -0.0226,  0.0085,  0.0269,\n",
      "         0.0192,  0.0092, -0.0156, -0.0242, -0.0200, -0.0356,  0.0042, -0.0055,\n",
      "        -0.0257,  0.0247, -0.0286, -0.0014, -0.0313, -0.0162,  0.0179,  0.0119,\n",
      "         0.0129,  0.0262, -0.0300, -0.0243,  0.0081,  0.0320,  0.0148,  0.0277,\n",
      "        -0.0015,  0.0257,  0.0017, -0.0120,  0.0233,  0.0242, -0.0028,  0.0005,\n",
      "        -0.0265, -0.0181,  0.0153,  0.0227, -0.0204,  0.0347,  0.0297,  0.0071,\n",
      "        -0.0194, -0.0328, -0.0088,  0.0054, -0.0115, -0.0238,  0.0051,  0.0030,\n",
      "        -0.0279, -0.0258,  0.0253, -0.0165, -0.0172, -0.0226,  0.0305,  0.0302,\n",
      "         0.0019,  0.0157, -0.0090,  0.0351,  0.0191, -0.0252,  0.0334,  0.0194,\n",
      "         0.0333, -0.0194,  0.0152,  0.0175,  0.0182,  0.0150, -0.0338,  0.0052,\n",
      "         0.0153,  0.0174, -0.0356,  0.0300, -0.0101, -0.0023, -0.0195, -0.0200,\n",
      "        -0.0119, -0.0106, -0.0026, -0.0201,  0.0014,  0.0093, -0.0353,  0.0339,\n",
      "         0.0203,  0.0053, -0.0103, -0.0060,  0.0005, -0.0346,  0.0284, -0.0247,\n",
      "        -0.0041,  0.0315,  0.0060,  0.0125, -0.0201,  0.0345,  0.0182, -0.0328,\n",
      "        -0.0026, -0.0257, -0.0075,  0.0176, -0.0105,  0.0300, -0.0108, -0.0089,\n",
      "         0.0291, -0.0288, -0.0124,  0.0002, -0.0304,  0.0121,  0.0306, -0.0250])), ('3.weight', tensor([[-0.0155, -0.0261,  0.0020,  ...,  0.0572, -0.0429, -0.0074],\n",
      "        [-0.0137, -0.0160,  0.0288,  ...,  0.0116, -0.0534, -0.0120],\n",
      "        [-0.0431, -0.0393, -0.0444,  ...,  0.0073, -0.0333,  0.0478],\n",
      "        ...,\n",
      "        [-0.0074,  0.0160, -0.0465,  ...,  0.0322,  0.0544,  0.0346],\n",
      "        [ 0.0022,  0.0602, -0.0496,  ...,  0.0503,  0.0490, -0.0486],\n",
      "        [-0.0602, -0.0263,  0.0052,  ...,  0.0280, -0.0219,  0.0385]])), ('3.bias', tensor([-0.0593,  0.0140, -0.0093,  0.0275,  0.0350, -0.0543, -0.0184,  0.0375,\n",
      "        -0.0250,  0.0186, -0.0145,  0.0179,  0.0031,  0.0415, -0.0233, -0.0453,\n",
      "         0.0425, -0.0575,  0.0509, -0.0041,  0.0054, -0.0437, -0.0185, -0.0461,\n",
      "        -0.0096, -0.0017,  0.0533, -0.0054,  0.0424,  0.0572,  0.0198,  0.0138,\n",
      "         0.0169, -0.0026, -0.0345, -0.0479,  0.0508,  0.0466,  0.0599, -0.0369,\n",
      "         0.0073, -0.0245, -0.0468,  0.0522, -0.0399,  0.0547,  0.0284, -0.0548,\n",
      "         0.0019, -0.0211, -0.0252, -0.0289,  0.0623, -0.0481,  0.0482,  0.0321,\n",
      "         0.0082,  0.0197, -0.0402, -0.0196, -0.0569, -0.0092, -0.0032,  0.0287,\n",
      "         0.0549, -0.0039, -0.0422,  0.0526, -0.0268,  0.0432, -0.0377, -0.0454,\n",
      "         0.0465,  0.0433, -0.0527, -0.0268, -0.0454,  0.0555, -0.0564,  0.0612,\n",
      "         0.0237,  0.0606,  0.0016, -0.0579,  0.0189,  0.0322, -0.0454,  0.0049,\n",
      "        -0.0455, -0.0395,  0.0432, -0.0150,  0.0044, -0.0181, -0.0066,  0.0255,\n",
      "         0.0460, -0.0345, -0.0088,  0.0191, -0.0474,  0.0185,  0.0618, -0.0593,\n",
      "         0.0292,  0.0370, -0.0563,  0.0363, -0.0319, -0.0352,  0.0206,  0.0066,\n",
      "        -0.0281,  0.0346,  0.0044,  0.0320,  0.0140,  0.0151, -0.0247, -0.0143,\n",
      "         0.0136,  0.0534,  0.0570,  0.0187, -0.0404, -0.0174,  0.0451, -0.0290])), ('6.weight', tensor([[-0.0630,  0.0475, -0.0212,  ..., -0.0532, -0.0217,  0.0407],\n",
      "        [ 0.0124, -0.0608,  0.0460,  ...,  0.0881, -0.0553,  0.0579],\n",
      "        [ 0.0781, -0.0085,  0.0761,  ...,  0.0048, -0.0350, -0.0706],\n",
      "        ...,\n",
      "        [-0.0705, -0.0675, -0.0846,  ..., -0.0565,  0.0131,  0.0316],\n",
      "        [-0.0755,  0.0570,  0.0811,  ...,  0.0860, -0.0152, -0.0261],\n",
      "        [-0.0513, -0.0727, -0.0087,  ...,  0.0021, -0.0237, -0.0375]])), ('6.bias', tensor([-0.0264,  0.0671,  0.0435,  0.0405, -0.0539, -0.0686,  0.0012, -0.0832,\n",
      "        -0.0160,  0.0738,  0.0197, -0.0391,  0.0512, -0.0688, -0.0173,  0.0032,\n",
      "        -0.0386,  0.0116, -0.0498, -0.0687, -0.0757,  0.0496,  0.0712,  0.0015,\n",
      "         0.0039, -0.0674,  0.0090, -0.0083, -0.0257, -0.0735,  0.0653, -0.0154,\n",
      "         0.0534,  0.0174,  0.0579,  0.0878, -0.0489, -0.0003, -0.0780,  0.0423,\n",
      "        -0.0623, -0.0399,  0.0249,  0.0739,  0.0189, -0.0579, -0.0681,  0.0735,\n",
      "         0.0284, -0.0029,  0.0152, -0.0402,  0.0548,  0.0276, -0.0109, -0.0226,\n",
      "         0.0720,  0.0239, -0.0726, -0.0192, -0.0101, -0.0662, -0.0528,  0.0493])), ('9.weight', tensor([[-0.0198, -0.0011, -0.0710, -0.0999, -0.0764,  0.0565,  0.0308, -0.0800,\n",
      "          0.0072,  0.0503, -0.0273,  0.1129,  0.0297,  0.0878,  0.0107, -0.0015,\n",
      "          0.1071, -0.0286,  0.0771, -0.0472,  0.0015,  0.0011,  0.0186,  0.1137,\n",
      "         -0.0221,  0.1034,  0.0164, -0.0120,  0.1158,  0.0867,  0.1247, -0.0935,\n",
      "          0.1151,  0.0069,  0.0803, -0.0678,  0.0281,  0.0037, -0.0535, -0.1096,\n",
      "         -0.0225,  0.0628,  0.1199, -0.0591,  0.0919,  0.0134, -0.0778,  0.0823,\n",
      "         -0.0194,  0.0089,  0.1004,  0.0146, -0.1246, -0.0656,  0.0235,  0.0300,\n",
      "         -0.0495, -0.1092,  0.0442, -0.0879, -0.0864, -0.0660,  0.0981,  0.0282],\n",
      "        [ 0.0481, -0.0199, -0.0436,  0.0274,  0.0259,  0.0739,  0.0934,  0.0048,\n",
      "         -0.0730,  0.1204,  0.0353, -0.0940, -0.0175, -0.0421, -0.0584,  0.0323,\n",
      "         -0.1191,  0.0362,  0.0766, -0.0585,  0.0267, -0.1185,  0.0856, -0.0013,\n",
      "         -0.0039,  0.1232, -0.0076,  0.0030,  0.0625, -0.1221, -0.0309,  0.0059,\n",
      "          0.1161, -0.1069,  0.0328, -0.0728, -0.0615,  0.1205, -0.0334, -0.0471,\n",
      "          0.1084, -0.0792,  0.0511,  0.0598, -0.0487,  0.1231,  0.0906, -0.0220,\n",
      "          0.0896,  0.0134,  0.0385,  0.1204, -0.0768, -0.0535, -0.1021,  0.1234,\n",
      "          0.1197, -0.0727, -0.0018, -0.1110,  0.0292,  0.0604,  0.1070, -0.0314],\n",
      "        [ 0.0879,  0.0146,  0.0075,  0.1171, -0.0766,  0.0597, -0.0417,  0.0782,\n",
      "         -0.0625,  0.0612,  0.0390,  0.0928,  0.0265,  0.0627, -0.0597, -0.0973,\n",
      "          0.0002,  0.1081, -0.1052, -0.0179,  0.0130, -0.0251,  0.1203, -0.0783,\n",
      "         -0.0316, -0.1150,  0.0337, -0.0125,  0.0722,  0.0563, -0.0210, -0.0473,\n",
      "         -0.1050,  0.0418,  0.1151, -0.0407,  0.0233, -0.0935, -0.0892,  0.0524,\n",
      "         -0.0682,  0.0681, -0.0578,  0.0498,  0.1139,  0.1026, -0.0874, -0.0459,\n",
      "         -0.0786, -0.0789, -0.0363,  0.0884, -0.0824,  0.1151, -0.1169,  0.0471,\n",
      "          0.0064,  0.1134,  0.0213,  0.0770, -0.0866,  0.0450, -0.0830,  0.0418],\n",
      "        [-0.0047, -0.0896,  0.0275,  0.0519, -0.0797, -0.0415, -0.0802, -0.0110,\n",
      "          0.0050, -0.0238,  0.0186, -0.0726,  0.0904,  0.1114,  0.0840, -0.0361,\n",
      "         -0.0974,  0.0581,  0.0794, -0.0914,  0.1234, -0.0224,  0.0382, -0.0132,\n",
      "          0.1248,  0.0581, -0.0009, -0.1112, -0.0089,  0.0087, -0.0058,  0.0068,\n",
      "          0.0527, -0.0734,  0.0083, -0.0196, -0.0144, -0.1082, -0.0488,  0.0254,\n",
      "          0.0336, -0.0022,  0.0263, -0.0453, -0.0138, -0.0089,  0.0967, -0.0490,\n",
      "         -0.0038, -0.1023,  0.0070, -0.0382,  0.0852,  0.0171,  0.0187,  0.0920,\n",
      "         -0.0720,  0.0461,  0.0966,  0.1213, -0.0289,  0.0171, -0.0413,  0.0873],\n",
      "        [-0.0195,  0.1061,  0.0631, -0.0104,  0.1113,  0.0124,  0.0376,  0.1127,\n",
      "         -0.1074,  0.0508,  0.1238,  0.0739, -0.0969, -0.1001,  0.0232,  0.0542,\n",
      "          0.0624, -0.0786,  0.0819,  0.0312, -0.1192,  0.1030, -0.1161,  0.0981,\n",
      "         -0.0992,  0.0718,  0.0265, -0.0577, -0.0251,  0.0268, -0.0910, -0.0612,\n",
      "         -0.0833, -0.1017, -0.0975, -0.0129,  0.1128, -0.0640,  0.0659, -0.1205,\n",
      "         -0.0253, -0.1121,  0.0929, -0.0994,  0.1054,  0.0824, -0.1238, -0.1050,\n",
      "          0.0453, -0.0741,  0.0723, -0.1227,  0.0615, -0.0444,  0.0874, -0.0812,\n",
      "         -0.0516, -0.0926, -0.0630,  0.0989,  0.0905, -0.0223, -0.0756, -0.0179],\n",
      "        [ 0.0529, -0.0559,  0.0883, -0.0609,  0.1096,  0.0621,  0.0026,  0.0192,\n",
      "         -0.0240, -0.0704,  0.0233, -0.0449,  0.0787, -0.0773, -0.0860,  0.0466,\n",
      "         -0.0750, -0.0099,  0.0714,  0.0641,  0.0608,  0.0056,  0.1208, -0.0890,\n",
      "          0.0327, -0.1013,  0.0884,  0.0295, -0.0292,  0.0423,  0.0684, -0.0341,\n",
      "          0.0776,  0.0622, -0.1118, -0.0106, -0.0135,  0.0570, -0.0695, -0.0187,\n",
      "         -0.0673,  0.0733, -0.0789, -0.0560,  0.0629, -0.0681,  0.0804,  0.0361,\n",
      "          0.0768,  0.0040,  0.0913, -0.0512,  0.0622,  0.0150,  0.0752,  0.0200,\n",
      "         -0.0937, -0.0134, -0.0711, -0.0568,  0.0644, -0.0278,  0.0600, -0.0792],\n",
      "        [-0.0484,  0.0018,  0.1003,  0.0845,  0.0994,  0.0575, -0.0971,  0.0337,\n",
      "          0.0325,  0.0403, -0.1177, -0.0208,  0.0267, -0.0674, -0.0473,  0.0976,\n",
      "         -0.0507,  0.0115, -0.0787, -0.0685,  0.1123, -0.0844,  0.0989,  0.0699,\n",
      "         -0.0764, -0.0846, -0.1187, -0.0590, -0.0860, -0.1055, -0.0357,  0.0573,\n",
      "          0.0008,  0.0877, -0.0748, -0.0313,  0.0039,  0.1152,  0.0756, -0.0016,\n",
      "         -0.0175, -0.0717, -0.0893,  0.0127, -0.0794,  0.1054,  0.0579, -0.0048,\n",
      "          0.0302, -0.0237, -0.0774,  0.0599, -0.0816,  0.1250, -0.0846, -0.0804,\n",
      "         -0.1055,  0.0957,  0.0206, -0.0166,  0.0385, -0.0178, -0.0305, -0.0198],\n",
      "        [-0.0898,  0.1184, -0.1076, -0.0036, -0.0232,  0.0095,  0.0242, -0.0840,\n",
      "          0.1100,  0.0740,  0.0016, -0.0430,  0.0281,  0.0979, -0.0640, -0.0957,\n",
      "         -0.1205, -0.0919, -0.0727, -0.0918, -0.0319, -0.1090,  0.0288, -0.0461,\n",
      "         -0.0031, -0.1042,  0.0420, -0.0146,  0.0614,  0.0443, -0.0662,  0.0437,\n",
      "         -0.1045,  0.1003,  0.0757, -0.0664,  0.0739, -0.0248, -0.0784, -0.0164,\n",
      "         -0.0057,  0.0862,  0.0887, -0.0090, -0.1203, -0.0124, -0.0833, -0.0003,\n",
      "         -0.0853, -0.0009, -0.0613, -0.0139,  0.0304,  0.1116, -0.0134, -0.0774,\n",
      "         -0.0492, -0.0275, -0.0802,  0.0838,  0.1042, -0.0873,  0.0404,  0.0587],\n",
      "        [-0.1047, -0.0849,  0.1005,  0.0554, -0.0978,  0.0022,  0.0714,  0.0443,\n",
      "         -0.0994,  0.0464,  0.0337,  0.0950, -0.0098,  0.0845,  0.0468,  0.0496,\n",
      "         -0.0597, -0.0179, -0.0637, -0.0150,  0.0763,  0.0239, -0.0356,  0.0765,\n",
      "         -0.0165, -0.0232, -0.0220, -0.0963,  0.0394, -0.0859, -0.0392, -0.1070,\n",
      "         -0.0299,  0.0591, -0.0937,  0.0829,  0.1204, -0.0175,  0.0995,  0.0432,\n",
      "         -0.0196, -0.0307, -0.0238, -0.0943, -0.0133, -0.0584, -0.0657, -0.0556,\n",
      "          0.0548,  0.0245, -0.0132,  0.0060,  0.0957,  0.0776,  0.0059,  0.0310,\n",
      "          0.0089,  0.0812, -0.0638, -0.0778,  0.1085,  0.0843,  0.0451,  0.0563],\n",
      "        [ 0.0042, -0.0530, -0.0948,  0.0954, -0.0581, -0.0419,  0.0503, -0.0123,\n",
      "          0.0229, -0.0807,  0.1067,  0.0555,  0.0547, -0.1241,  0.0795,  0.0464,\n",
      "         -0.0320, -0.0980,  0.1104, -0.0591,  0.0082, -0.1200,  0.0140,  0.0412,\n",
      "          0.1009, -0.0030,  0.0937,  0.0501,  0.0881, -0.0015,  0.1075,  0.1198,\n",
      "         -0.0482,  0.1235,  0.0026, -0.0189,  0.1114,  0.0865, -0.1172, -0.1070,\n",
      "         -0.0328,  0.0316,  0.0960, -0.0645,  0.0924, -0.0821,  0.1204,  0.0886,\n",
      "         -0.1250,  0.0987,  0.0031, -0.0068,  0.0873, -0.0430, -0.0334, -0.0048,\n",
      "          0.0703,  0.0261, -0.0377, -0.0956,  0.0986, -0.0859,  0.0156, -0.1246]])), ('9.bias', tensor([-0.0216,  0.1135,  0.0527,  0.0103, -0.0215, -0.0930,  0.0957, -0.0825,\n",
      "        -0.0642,  0.0640]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Weights & Bias \\n\\n\", model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_classifier(model, trainloader, testloader, learnrate):\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learnrate)\n",
    "\n",
    "    steps = 0\n",
    "    print_every = 40\n",
    "    epochs = 2\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            images = images.view(len(images),-1)\n",
    "            logps = model(images)\n",
    "            loss = criterion(logps, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            steps += 1\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                accuracy = 0\n",
    "                loss_test = 0\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for images, labels in testloader:\n",
    "                        images = images.view(len(images), -1)\n",
    "                        logps_test = model(images)\n",
    "                        loss_test += criterion(logps_test, labels)\n",
    "\n",
    "                        ps_test = torch.exp(logps_test)\n",
    "                        top_ps, top_class = ps_test.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                print(f'Epoch: {i+1}/{epochs} ',\n",
    "                      f'Training Loss: {running_loss/print_every:.3f} ',\n",
    "                      f'Test Loss: {loss_test/len(testloader):.3f} ',\n",
    "                      f'Test Accuracy: {accuracy/len(testloader):.3f}')\n",
    "                running_loss = 0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model and Update Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2  Training Loss: 1.511  Test Loss: 0.854  Test Accuracy: 0.702\n",
      "Epoch: 1/2  Training Loss: 0.875  Test Loss: 0.710  Test Accuracy: 0.735\n",
      "Epoch: 1/2  Training Loss: 0.715  Test Loss: 0.660  Test Accuracy: 0.745\n",
      "Epoch: 1/2  Training Loss: 0.695  Test Loss: 0.599  Test Accuracy: 0.775\n",
      "Epoch: 1/2  Training Loss: 0.698  Test Loss: 0.583  Test Accuracy: 0.775\n",
      "Epoch: 1/2  Training Loss: 0.634  Test Loss: 0.554  Test Accuracy: 0.791\n",
      "Epoch: 1/2  Training Loss: 0.581  Test Loss: 0.567  Test Accuracy: 0.790\n",
      "Epoch: 1/2  Training Loss: 0.623  Test Loss: 0.554  Test Accuracy: 0.793\n",
      "Epoch: 1/2  Training Loss: 0.620  Test Loss: 0.509  Test Accuracy: 0.814\n",
      "Epoch: 1/2  Training Loss: 0.578  Test Loss: 0.504  Test Accuracy: 0.814\n",
      "Epoch: 1/2  Training Loss: 0.532  Test Loss: 0.540  Test Accuracy: 0.800\n",
      "Epoch: 1/2  Training Loss: 0.514  Test Loss: 0.488  Test Accuracy: 0.823\n",
      "Epoch: 1/2  Training Loss: 0.530  Test Loss: 0.522  Test Accuracy: 0.804\n",
      "Epoch: 1/2  Training Loss: 0.544  Test Loss: 0.507  Test Accuracy: 0.812\n",
      "Epoch: 1/2  Training Loss: 0.514  Test Loss: 0.465  Test Accuracy: 0.825\n",
      "Epoch: 1/2  Training Loss: 0.499  Test Loss: 0.490  Test Accuracy: 0.819\n",
      "Epoch: 1/2  Training Loss: 0.510  Test Loss: 0.492  Test Accuracy: 0.824\n",
      "Epoch: 1/2  Training Loss: 0.486  Test Loss: 0.455  Test Accuracy: 0.834\n",
      "Epoch: 1/2  Training Loss: 0.496  Test Loss: 0.448  Test Accuracy: 0.836\n",
      "Epoch: 1/2  Training Loss: 0.427  Test Loss: 0.444  Test Accuracy: 0.837\n",
      "Epoch: 1/2  Training Loss: 0.466  Test Loss: 0.451  Test Accuracy: 0.833\n",
      "Epoch: 1/2  Training Loss: 0.503  Test Loss: 0.443  Test Accuracy: 0.835\n",
      "Epoch: 1/2  Training Loss: 0.469  Test Loss: 0.438  Test Accuracy: 0.841\n",
      "Epoch: 2/2  Training Loss: 0.222  Test Loss: 0.453  Test Accuracy: 0.838\n",
      "Epoch: 2/2  Training Loss: 0.444  Test Loss: 0.434  Test Accuracy: 0.841\n",
      "Epoch: 2/2  Training Loss: 0.477  Test Loss: 0.440  Test Accuracy: 0.843\n",
      "Epoch: 2/2  Training Loss: 0.424  Test Loss: 0.448  Test Accuracy: 0.840\n",
      "Epoch: 2/2  Training Loss: 0.446  Test Loss: 0.425  Test Accuracy: 0.849\n",
      "Epoch: 2/2  Training Loss: 0.456  Test Loss: 0.454  Test Accuracy: 0.835\n",
      "Epoch: 2/2  Training Loss: 0.457  Test Loss: 0.438  Test Accuracy: 0.846\n",
      "Epoch: 2/2  Training Loss: 0.446  Test Loss: 0.440  Test Accuracy: 0.841\n",
      "Epoch: 2/2  Training Loss: 0.454  Test Loss: 0.422  Test Accuracy: 0.847\n",
      "Epoch: 2/2  Training Loss: 0.434  Test Loss: 0.441  Test Accuracy: 0.841\n",
      "Epoch: 2/2  Training Loss: 0.452  Test Loss: 0.417  Test Accuracy: 0.847\n",
      "Epoch: 2/2  Training Loss: 0.436  Test Loss: 0.430  Test Accuracy: 0.843\n",
      "Epoch: 2/2  Training Loss: 0.433  Test Loss: 0.427  Test Accuracy: 0.845\n",
      "Epoch: 2/2  Training Loss: 0.436  Test Loss: 0.427  Test Accuracy: 0.846\n",
      "Epoch: 2/2  Training Loss: 0.452  Test Loss: 0.411  Test Accuracy: 0.853\n",
      "Epoch: 2/2  Training Loss: 0.419  Test Loss: 0.425  Test Accuracy: 0.844\n",
      "Epoch: 2/2  Training Loss: 0.433  Test Loss: 0.414  Test Accuracy: 0.849\n",
      "Epoch: 2/2  Training Loss: 0.423  Test Loss: 0.433  Test Accuracy: 0.843\n",
      "Epoch: 2/2  Training Loss: 0.422  Test Loss: 0.416  Test Accuracy: 0.851\n",
      "Epoch: 2/2  Training Loss: 0.416  Test Loss: 0.419  Test Accuracy: 0.846\n",
      "Epoch: 2/2  Training Loss: 0.431  Test Loss: 0.446  Test Accuracy: 0.830\n",
      "Epoch: 2/2  Training Loss: 0.401  Test Loss: 0.428  Test Accuracy: 0.843\n",
      "Epoch: 2/2  Training Loss: 0.423  Test Loss: 0.413  Test Accuracy: 0.850\n"
     ]
    }
   ],
   "source": [
    "model = model_classifier(model, trainloader, testloader, learnrate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784,256),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(256,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "steps = 0\n",
    "print_every = 40\n",
    "epochs = 2\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(len(images),-1)\n",
    "        logps = model(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        steps += 1\n",
    "    \n",
    "        if steps % print_every == 0:\n",
    "            accuracy = 0\n",
    "            loss_test = 0\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for images, labels in testloader:\n",
    "                    images = images.view(len(images), -1)\n",
    "                    logps_test = model(images)\n",
    "                    loss_test += criterion(logps_test, labels)\n",
    "\n",
    "                    ps_test = torch.exp(logps_test)\n",
    "                    top_ps, top_class = ps_test.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                    \n",
    "            model.train()\n",
    "\n",
    "            print(f'Epoch: {i+1}/{epochs} ',\n",
    "                  f'Training Loss: {running_loss/print_every:.3f} ',\n",
    "                  f'Test Loss: {loss_test/len(testloader):.3f} ',\n",
    "                  f'Test Accuracy: {accuracy/len(testloader):.3f}')\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
    "\n",
    "The parameters for PyTorch networks are stored in a model's state_dict. We can see the state dict contains the weight and bias matrices for each of our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.2, inplace=False)\n",
      "  (6): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Dropout(p=0.2, inplace=False)\n",
      "  (9): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (10): LogSoftmax(dim=1)\n",
      ") \n",
      "\n",
      "The State Dict Keys \n",
      "\n",
      " odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias', '9.weight', '9.bias'])\n",
      "\n",
      " Updated Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[-1.0629e-02,  2.3848e-02,  1.9177e-02,  ..., -2.4077e-02,\n",
      "         -9.6044e-05,  5.7990e-03],\n",
      "        [ 3.1818e-03,  3.5432e-02,  5.1608e-02,  ...,  1.5174e-02,\n",
      "          2.4117e-02, -6.1167e-03],\n",
      "        [ 6.7755e-02,  6.0934e-02,  6.1954e-02,  ...,  5.0990e-02,\n",
      "          6.7887e-02,  3.7037e-02],\n",
      "        ...,\n",
      "        [ 1.2702e-02,  6.7123e-02,  3.4306e-02,  ...,  1.4496e-02,\n",
      "          4.1974e-02,  4.2661e-02],\n",
      "        [-1.0375e-02, -1.4728e-02,  1.7473e-02,  ...,  3.5640e-02,\n",
      "          1.0475e-02,  1.3153e-02],\n",
      "        [ 3.7357e-02,  3.2882e-02,  6.8365e-02,  ...,  7.8092e-03,\n",
      "          2.7375e-02,  4.6199e-03]])), ('0.bias', tensor([-0.0096, -0.0223, -0.0626, -0.0365, -0.0339,  0.0192, -0.0418, -0.0289,\n",
      "        -0.0135, -0.0173, -0.0139, -0.0338, -0.0147, -0.0206,  0.0100, -0.0203,\n",
      "        -0.0236,  0.0318, -0.0084,  0.0175,  0.0152, -0.0269, -0.0035,  0.0122,\n",
      "        -0.0835, -0.0497, -0.0235,  0.0139,  0.0343, -0.0369,  0.0085, -0.0328,\n",
      "         0.0264, -0.0021, -0.0084,  0.0024, -0.0238, -0.0170, -0.0340,  0.0112,\n",
      "         0.0006, -0.0147, -0.0658, -0.0115, -0.0194,  0.0488, -0.0012, -0.0213,\n",
      "        -0.0061,  0.0081,  0.0046,  0.0109, -0.0238, -0.0204, -0.0424, -0.0294,\n",
      "         0.0030, -0.0076, -0.0243,  0.0322,  0.0148,  0.0023, -0.0446, -0.0311,\n",
      "        -0.0143, -0.0085, -0.0437, -0.0285,  0.0065, -0.0307, -0.0468, -0.0248,\n",
      "        -0.0055, -0.0173, -0.0310, -0.0172, -0.0494, -0.0057,  0.0707, -0.0389,\n",
      "         0.0638, -0.0477, -0.0510, -0.0475, -0.0109,  0.0074, -0.0260,  0.0003,\n",
      "        -0.0037, -0.0426,  0.0043, -0.0360, -0.0088, -0.0213, -0.0239, -0.0336,\n",
      "        -0.0395, -0.0117, -0.0274, -0.0287,  0.0455, -0.0349,  0.0065, -0.0363,\n",
      "        -0.0106,  0.0051, -0.0027, -0.0216, -0.0166, -0.0216, -0.0499,  0.0101,\n",
      "         0.0036, -0.0426, -0.0264, -0.0295,  0.0313,  0.0044, -0.0298, -0.0662,\n",
      "         0.0149, -0.0444,  0.0337,  0.0071, -0.0288, -0.0200, -0.0626, -0.0157,\n",
      "        -0.0316,  0.0030,  0.0160,  0.0129, -0.0124, -0.0289,  0.0185,  0.0086,\n",
      "        -0.0091, -0.0101, -0.0593, -0.0446, -0.0338, -0.0096, -0.0177, -0.0203,\n",
      "        -0.0528,  0.0263, -0.0556, -0.0057, -0.0572, -0.0028, -0.0135, -0.0216,\n",
      "        -0.0199,  0.0177, -0.0514, -0.0519,  0.0001,  0.0004,  0.0491,  0.0061,\n",
      "        -0.0154,  0.0199, -0.0310, -0.0262, -0.0017, -0.0116, -0.0065, -0.0043,\n",
      "        -0.0340,  0.0135, -0.0057,  0.0157, -0.0393,  0.0222,  0.0399,  0.0528,\n",
      "        -0.0245, -0.0698, -0.0389,  0.0124, -0.0158, -0.0367,  0.0031, -0.0233,\n",
      "        -0.0310, -0.0464, -0.0040, -0.0422, -0.0239, -0.0512,  0.0151,  0.0188,\n",
      "        -0.0392,  0.0059, -0.0278,  0.0586,  0.0010, -0.0318, -0.0009, -0.0020,\n",
      "         0.0171, -0.0324, -0.0003,  0.0245,  0.0299,  0.0068, -0.0602, -0.0046,\n",
      "         0.0101,  0.0484, -0.0176,  0.0193, -0.0273, -0.0338, -0.0480, -0.0378,\n",
      "        -0.0408, -0.0314, -0.0313, -0.0471, -0.0127, -0.0020, -0.0506,  0.0234,\n",
      "         0.0123, -0.0122, -0.0163, -0.0281,  0.0160, -0.0439,  0.0503, -0.0430,\n",
      "        -0.0300,  0.0366,  0.0543, -0.0453, -0.0388,  0.0076, -0.0082, -0.0268,\n",
      "        -0.0213, -0.0333,  0.0120,  0.0045, -0.0200,  0.0403, -0.0220, -0.0347,\n",
      "         0.0410, -0.0149, -0.0252, -0.0249, -0.0116, -0.0237,  0.0312, -0.0600])), ('3.weight', tensor([[-0.0411, -0.0378,  0.0481,  ...,  0.0484, -0.0691,  0.0482],\n",
      "        [-0.0214, -0.0293,  0.0879,  ...,  0.0101, -0.0734,  0.0510],\n",
      "        [-0.1310, -0.0348,  0.0058,  ...,  0.0016, -0.0887,  0.0942],\n",
      "        ...,\n",
      "        [-0.0267,  0.0109,  0.0057,  ...,  0.0262, -0.0277,  0.0147],\n",
      "        [ 0.0430,  0.0883, -0.0597,  ...,  0.0568,  0.0954, -0.0548],\n",
      "        [-0.0787, -0.0237, -0.0519,  ...,  0.0117,  0.0058,  0.0619]])), ('3.bias', tensor([-6.5583e-02,  2.3154e-02, -3.6025e-02,  9.5174e-02,  3.6254e-02,\n",
      "        -7.2742e-02,  2.9106e-02,  6.2240e-02,  1.7085e-02,  2.5768e-02,\n",
      "         6.8722e-03,  2.6153e-02,  1.6909e-02,  9.2107e-02, -6.4423e-04,\n",
      "        -1.3342e-02,  6.5962e-02, -1.5862e-02,  5.3566e-02, -4.4076e-03,\n",
      "         3.5854e-02, -2.0666e-02, -1.2552e-02, -1.9238e-02, -3.8179e-02,\n",
      "        -6.0219e-03,  2.6119e-02,  1.2368e-02,  3.0472e-02,  8.5000e-02,\n",
      "        -1.3772e-02, -3.4152e-02, -8.8036e-03, -3.8642e-02, -3.2361e-02,\n",
      "        -7.3230e-02,  7.6408e-02,  6.9840e-02,  2.5925e-02, -2.6220e-02,\n",
      "         1.3004e-02, -1.0427e-03,  4.8017e-02,  3.5804e-02,  6.4338e-03,\n",
      "         6.6247e-02, -4.0609e-03, -4.0797e-02, -7.0638e-03,  3.9552e-03,\n",
      "        -6.8746e-02, -1.0034e-01,  8.5212e-02, -5.8667e-02,  1.0520e-01,\n",
      "        -1.5373e-02,  2.7377e-02,  2.0232e-02, -2.1149e-02, -8.8462e-03,\n",
      "        -4.3299e-02,  4.2306e-02,  3.6085e-02,  2.8836e-02,  8.1326e-02,\n",
      "         3.2759e-02, -5.6091e-03,  2.9893e-02, -1.4543e-02,  8.9615e-02,\n",
      "         2.6314e-02, -5.7912e-02,  6.8314e-02,  3.9965e-02, -2.6251e-02,\n",
      "        -3.7666e-03, -5.4455e-02,  3.0670e-02, -7.1779e-02,  3.0194e-02,\n",
      "         9.0521e-02,  9.0599e-02, -1.0471e-02, -5.9196e-02,  8.9625e-03,\n",
      "         4.8281e-02, -3.1859e-02, -2.1395e-03,  3.4442e-02, -9.6536e-02,\n",
      "         1.5150e-02, -2.0613e-03,  3.3460e-02,  1.0150e-04, -3.7292e-02,\n",
      "         1.3835e-02,  6.4895e-02, -4.3077e-02,  1.1438e-02,  5.1525e-02,\n",
      "        -2.5730e-02,  3.9306e-02,  5.6190e-03, -8.7690e-02,  5.1530e-02,\n",
      "         6.0572e-02, -8.8471e-02,  4.3302e-02,  1.6708e-02, -3.8199e-02,\n",
      "         8.1025e-03,  3.7126e-02,  1.9570e-02, -7.3511e-03, -2.1652e-02,\n",
      "        -2.1109e-02,  6.4984e-02,  1.0264e-01, -1.6922e-02,  1.4501e-02,\n",
      "        -2.0006e-02,  7.4786e-02,  5.3976e-02, -1.1856e-02, -3.2624e-02,\n",
      "        -4.9350e-02,  9.6758e-02, -3.6679e-03])), ('6.weight', tensor([[-1.1401e-01, -1.4953e-02, -6.7941e-02,  ...,  5.2792e-02,\n",
      "         -2.9096e-03,  5.7292e-02],\n",
      "        [ 2.5998e-02, -8.5555e-02,  2.6918e-02,  ...,  7.2161e-02,\n",
      "         -1.7829e-02,  1.3939e-01],\n",
      "        [ 8.3104e-02, -1.0355e-02,  8.8939e-02,  ..., -1.2005e-02,\n",
      "         -9.7056e-03,  2.0286e-03],\n",
      "        ...,\n",
      "        [-1.2601e-01, -1.2774e-01, -1.6399e-01,  ...,  5.6293e-02,\n",
      "          7.3997e-02, -1.7623e-03],\n",
      "        [ 6.7218e-04,  7.6284e-02,  1.6413e-01,  ...,  1.6735e-01,\n",
      "         -6.7303e-02, -6.4638e-02],\n",
      "        [-1.6173e-02, -7.3387e-02, -1.1623e-04,  ..., -1.0812e-01,\n",
      "          5.0720e-02, -1.2220e-01]])), ('6.bias', tensor([-0.0294,  0.0823,  0.1139,  0.1187, -0.0755, -0.0560,  0.0051,  0.0147,\n",
      "         0.0089,  0.1343,  0.0326,  0.0200,  0.1095, -0.0368,  0.0244,  0.0147,\n",
      "         0.0259,  0.0757, -0.0009, -0.0687, -0.0237,  0.1519,  0.1176,  0.0262,\n",
      "         0.0493, -0.0346,  0.0031, -0.0331, -0.0359, -0.0385,  0.0525, -0.0464,\n",
      "         0.0525,  0.0688,  0.0746,  0.1293, -0.0016, -0.0294, -0.0378,  0.0960,\n",
      "        -0.0155,  0.0619,  0.0521,  0.0941, -0.0077,  0.0234, -0.0668,  0.0500,\n",
      "         0.0203,  0.0516, -0.0144, -0.0718,  0.0965,  0.1099,  0.0306, -0.0627,\n",
      "         0.0437,  0.1318, -0.0293,  0.0832,  0.0170, -0.0090, -0.0650,  0.1893])), ('9.weight', tensor([[-9.6290e-02, -1.3258e-01, -8.7186e-02, -1.0907e-01, -1.5673e-01,\n",
      "          8.1905e-02, -5.8897e-02, -9.1020e-02,  3.9074e-02,  5.3010e-02,\n",
      "         -1.9476e-01,  9.5412e-02,  1.9982e-02,  9.3282e-02,  2.8000e-02,\n",
      "          4.4400e-02,  6.6623e-02,  4.9247e-02, -3.4384e-02, -7.2358e-02,\n",
      "          8.6819e-02,  1.2543e-02,  7.8896e-02,  1.2547e-01, -4.8052e-02,\n",
      "          9.4385e-02, -1.2029e-01, -8.9305e-02, -1.3470e-01, -1.5213e-01,\n",
      "          1.0081e-01, -1.5949e-01,  9.2761e-02,  3.6099e-02,  9.2145e-02,\n",
      "         -3.3487e-02,  5.8893e-02,  8.1415e-02, -4.6240e-02, -4.4576e-02,\n",
      "         -1.1621e-01,  5.0285e-02,  8.3130e-02, -1.3157e-01,  9.5474e-02,\n",
      "          3.5050e-02, -1.1450e-01,  7.5207e-02, -1.8076e-02, -4.6408e-02,\n",
      "          6.2409e-02, -1.3175e-02, -1.5795e-01, -4.3468e-02, -6.8000e-02,\n",
      "          1.3760e-02, -1.0090e-01,  1.0520e-02, -4.1695e-02, -1.2313e-01,\n",
      "         -8.3159e-02, -5.6531e-02,  5.6615e-02,  5.9973e-02],\n",
      "        [ 7.1416e-02, -8.3931e-02, -1.4999e-01, -9.5918e-02,  1.2114e-01,\n",
      "          6.2775e-02, -6.9773e-03, -1.2578e-01, -1.8640e-01,  6.1290e-02,\n",
      "          3.2622e-02, -1.8543e-01, -2.9967e-02, -4.9480e-02, -6.9708e-02,\n",
      "          6.6239e-03, -2.0850e-01, -4.8207e-03,  6.4832e-02, -1.7073e-01,\n",
      "         -1.5248e-02, -1.7130e-01,  9.8841e-02, -2.5993e-02, -3.0298e-02,\n",
      "          1.3111e-01, -1.4341e-01, -8.3435e-02, -6.5278e-02, -2.7373e-01,\n",
      "         -1.3242e-01,  2.6511e-02,  1.2410e-01, -2.1577e-01,  4.2768e-02,\n",
      "         -1.7951e-01, -1.0298e-01,  4.8853e-02, -1.9543e-01, -7.5096e-02,\n",
      "          9.8496e-02, -1.4906e-01,  8.1415e-02,  7.8582e-02, -1.2621e-01,\n",
      "          5.8128e-02,  1.2378e-01, -9.1667e-02,  9.7862e-02, -8.9879e-02,\n",
      "          7.6107e-02,  9.5542e-02, -1.0603e-01, -7.6868e-02, -1.2126e-01,\n",
      "          7.0941e-02,  1.5294e-01, -1.9096e-01, -2.1554e-01, -1.9311e-01,\n",
      "         -9.2571e-02,  7.4255e-02,  1.0601e-01, -8.7786e-02],\n",
      "        [ 9.3008e-02,  4.7331e-02, -1.5464e-03,  1.1366e-01, -7.4621e-02,\n",
      "          5.3617e-02, -6.1243e-02,  1.0415e-01, -1.8168e-01,  7.0292e-02,\n",
      "          7.6815e-02,  8.7659e-02, -4.2151e-02, -5.2377e-03, -9.0479e-02,\n",
      "         -1.0022e-01,  3.9783e-02,  8.5566e-02, -1.5354e-02, -9.4759e-03,\n",
      "         -1.1870e-02,  1.8760e-02,  1.2489e-01, -8.8964e-02, -1.3614e-01,\n",
      "         -1.3028e-01, -1.4531e-01, -6.7674e-02,  5.1359e-02, -1.7202e-01,\n",
      "          5.5221e-03, -1.3273e-01, -1.5337e-01,  1.8162e-02,  1.0994e-01,\n",
      "         -1.0677e-01, -1.4035e-02, -1.0385e-01, -8.6859e-02,  5.2062e-02,\n",
      "         -1.3462e-02,  4.1651e-02, -1.3533e-01,  4.8903e-02,  1.0288e-01,\n",
      "          1.0292e-01, -1.2647e-01, -9.3699e-02, -5.4412e-02, -1.0472e-01,\n",
      "         -4.7063e-02,  8.8008e-02, -1.1451e-01, -4.7884e-02, -1.8338e-01,\n",
      "         -1.1930e-02, -9.1963e-02,  1.1815e-01, -2.1794e-01,  8.2699e-02,\n",
      "         -1.1827e-01,  3.5981e-02, -1.1086e-01,  4.8546e-02],\n",
      "        [-7.1939e-02, -7.6700e-02,  1.0041e-01, -1.2009e-01, -1.4825e-01,\n",
      "         -7.5404e-02, -1.5200e-01,  2.6522e-02,  4.9608e-03,  3.3485e-02,\n",
      "         -2.1566e-02, -1.0739e-01,  1.0757e-01,  6.6557e-02,  9.6821e-02,\n",
      "         -6.1385e-02, -7.4928e-02,  6.5977e-02,  1.3149e-01, -2.5354e-01,\n",
      "          1.3687e-01,  2.3155e-02,  3.5695e-02,  5.1275e-02,  1.1769e-01,\n",
      "          1.2490e-01, -6.3704e-02, -1.6428e-01, -1.6244e-01, -1.9245e-01,\n",
      "          6.0573e-03, -5.7233e-02,  1.1455e-01, -1.6349e-01,  2.9709e-02,\n",
      "         -1.0158e-01, -6.4530e-02, -9.3483e-02, -2.4063e-01, -2.6152e-03,\n",
      "          4.5542e-02,  2.2394e-03,  1.1930e-01, -5.3276e-02, -7.3231e-02,\n",
      "          7.4034e-02,  1.3418e-01, -2.3045e-02,  1.1555e-02, -2.7325e-01,\n",
      "          6.2278e-02, -3.9896e-02,  5.7264e-02,  1.4134e-02,  3.2377e-02,\n",
      "          1.0987e-01, -3.7498e-02, -7.5184e-02,  1.1986e-02,  1.0402e-01,\n",
      "         -1.2565e-01,  7.1137e-02, -4.6554e-02,  6.8666e-02],\n",
      "        [ 5.9701e-02,  7.0029e-02,  8.8363e-02,  8.6606e-02, -3.7731e-02,\n",
      "          3.2672e-02, -3.8140e-03,  9.8403e-02, -8.0044e-02,  8.5610e-02,\n",
      "          6.8538e-02,  6.3538e-02, -1.4580e-01, -9.2738e-02,  3.4113e-02,\n",
      "          6.7538e-02,  5.0480e-02, -5.7523e-02,  1.0432e-01,  4.2485e-03,\n",
      "         -1.2177e-01,  6.0774e-02, -8.5711e-02,  6.6401e-02, -9.7765e-02,\n",
      "          5.7525e-02, -1.3633e-01, -1.9662e-01, -6.1381e-02, -2.0332e-01,\n",
      "         -1.7784e-01, -1.1425e-01, -9.9450e-02, -1.7931e-01, -6.2840e-02,\n",
      "         -1.1198e-01,  7.0863e-02, -1.8820e-01,  3.6205e-02, -1.0027e-01,\n",
      "          4.6111e-02, -2.2024e-01,  7.7875e-02,  4.6559e-04,  8.2028e-02,\n",
      "          1.2016e-01, -1.4353e-01, -1.9955e-01,  4.7539e-02, -1.3882e-01,\n",
      "         -4.8186e-02, -1.0136e-01,  3.3076e-02,  1.2384e-02, -5.9924e-02,\n",
      "         -6.1011e-02, -1.5107e-01, -5.5874e-02, -2.2160e-01,  1.1698e-01,\n",
      "         -6.4422e-02,  4.1672e-02, -2.0208e-01,  8.4244e-03],\n",
      "        [-1.4049e-01, -5.5585e-03,  7.4961e-02, -1.2847e-01,  1.1058e-01,\n",
      "          5.7836e-02,  1.5932e-02, -2.2940e-02,  3.1654e-03, -1.9052e-01,\n",
      "          6.3212e-02, -1.7397e-01,  9.5210e-02, -3.2885e-02, -1.8914e-01,\n",
      "          9.7367e-03, -2.6982e-01, -2.0727e-02, -1.8332e-01,  8.8186e-02,\n",
      "          6.6013e-04, -1.3434e-01,  1.3477e-01, -2.1602e-01,  1.2854e-02,\n",
      "         -2.6095e-01,  1.1191e-01,  4.5590e-02, -8.2291e-02,  5.3742e-02,\n",
      "          8.3926e-02,  1.0942e-02, -1.5419e-02,  1.1488e-01, -3.2335e-01,\n",
      "          2.7156e-02, -1.2982e-02,  6.0294e-02, -1.6787e-02, -1.4779e-01,\n",
      "         -1.2095e-01, -3.3478e-01, -3.1627e-01, -1.3141e-02,  9.1183e-02,\n",
      "         -2.4488e-01,  6.3956e-02,  6.8447e-02,  5.9657e-02, -4.0927e-02,\n",
      "          8.6765e-02, -1.2044e-02,  8.4029e-02, -9.3350e-03,  9.7583e-02,\n",
      "          7.3829e-03, -1.0569e-01, -4.0556e-02, -1.5779e-01, -1.8306e-01,\n",
      "          1.2078e-01, -2.0669e-01,  7.1839e-02, -1.4523e-01],\n",
      "        [-2.5595e-02,  9.5863e-02,  1.0017e-01,  5.5463e-02,  3.0516e-02,\n",
      "          8.5716e-02, -1.7048e-01,  9.6320e-02,  3.9505e-02,  6.2963e-02,\n",
      "         -9.3019e-02,  9.3191e-02,  1.6441e-02, -1.2394e-01,  6.5662e-03,\n",
      "          1.0073e-01,  4.1441e-02,  3.1335e-02, -7.6790e-02, -5.5916e-02,\n",
      "          1.1903e-01,  6.1417e-03,  3.5092e-02,  1.2316e-01, -7.9201e-02,\n",
      "         -5.4857e-02, -1.7534e-01, -1.5592e-01, -5.9001e-02, -2.6758e-01,\n",
      "          5.7256e-02, -9.2056e-04,  5.1574e-02,  5.7372e-02, -4.2858e-02,\n",
      "         -1.4628e-01, -3.6915e-02,  8.1214e-02,  1.0283e-01, -6.3452e-02,\n",
      "         -1.6161e-01,  2.6348e-02, -3.0098e-02, -5.5432e-02, -5.8935e-03,\n",
      "          1.0977e-01, -1.4395e-02,  6.9508e-02, -1.3682e-03, -2.1998e-02,\n",
      "         -5.0461e-02,  4.5233e-02, -1.5710e-01, -5.4831e-02, -9.0636e-02,\n",
      "         -1.0095e-01, -1.2523e-01,  7.8972e-02, -3.3252e-02,  8.4882e-02,\n",
      "         -8.9181e-02, -8.4411e-02, -3.0337e-02,  4.0991e-02],\n",
      "        [-2.2083e-01,  1.1059e-01, -1.0613e-01, -3.7527e-02,  7.0097e-02,\n",
      "          3.5166e-02,  6.8907e-02, -2.3649e-01,  9.8044e-02,  1.8309e-02,\n",
      "          2.2175e-02, -1.4726e-01,  6.1599e-02,  6.2750e-02, -5.2564e-02,\n",
      "         -1.4990e-01, -3.6670e-01, -2.1704e-01, -3.3108e-01, -6.4647e-02,\n",
      "         -8.9012e-02, -3.1081e-01,  4.4855e-02, -2.0260e-01,  8.0815e-02,\n",
      "         -3.4682e-01,  8.5377e-02,  5.6135e-02,  9.1445e-02,  6.5806e-02,\n",
      "         -7.4416e-02,  1.0852e-01, -3.2495e-01,  1.1389e-01, -1.5274e-01,\n",
      "         -4.3355e-02,  1.0635e-01,  1.7159e-03, -1.5228e-01, -2.0082e-01,\n",
      "          1.4359e-02, -5.3108e-01, -2.4339e-01, -2.0755e-03, -1.3760e-01,\n",
      "         -2.2099e-01, -1.2169e-01,  1.8068e-02, -9.4910e-02,  8.3403e-02,\n",
      "         -4.5648e-02, -3.7699e-02,  8.4109e-02,  1.0616e-01,  7.2545e-02,\n",
      "         -7.0414e-02,  3.2907e-02, -1.5637e-01, -4.7229e-02, -1.2104e-01,\n",
      "          1.2420e-01, -3.2036e-01,  6.9894e-02, -3.4248e-02],\n",
      "        [-1.8184e-01, -1.5735e-01,  8.4266e-02,  7.3584e-02, -1.2249e-01,\n",
      "         -5.3354e-02,  8.9682e-02,  2.6798e-02, -1.7222e-01, -5.2879e-02,\n",
      "         -5.7986e-02,  1.0726e-01, -6.3733e-02,  1.5775e-01,  6.8542e-02,\n",
      "          6.3722e-02, -1.3791e-01, -7.9338e-02, -1.6829e-01,  2.2124e-02,\n",
      "          8.3927e-02, -1.1728e-02, -6.3121e-02,  4.6421e-02,  7.8204e-03,\n",
      "         -7.4792e-02, -6.1370e-02, -1.8925e-01,  1.2405e-02, -1.3292e-01,\n",
      "         -8.5325e-02, -1.4218e-01, -1.3629e-01,  8.6831e-02, -1.3824e-01,\n",
      "          9.2855e-02,  1.3393e-01, -1.3611e-01,  1.1944e-01, -1.2666e-01,\n",
      "         -7.8857e-02, -8.1609e-02, -9.8908e-02, -2.4441e-01, -6.7936e-02,\n",
      "         -1.3216e-01, -7.6921e-02, -1.4921e-01,  8.3423e-02,  6.5453e-02,\n",
      "         -6.3166e-02, -1.0269e-02,  8.8826e-02,  1.7025e-01,  4.7478e-02,\n",
      "          1.3483e-02, -4.4136e-02,  8.9867e-02, -2.1287e-01, -2.2058e-01,\n",
      "          9.3829e-02,  1.4975e-02,  8.4485e-02,  5.8296e-02],\n",
      "        [-1.7884e-01, -9.2574e-02, -1.9252e-01,  4.4802e-02, -9.1473e-02,\n",
      "         -1.5487e-01,  4.1162e-02, -1.9472e-01,  3.7310e-02, -1.6760e-01,\n",
      "          1.1250e-01, -5.5428e-02,  5.7675e-02, -1.2097e-01,  3.1338e-03,\n",
      "          2.3052e-02, -2.1660e-01, -1.7187e-01, -2.1197e-01, -9.3301e-02,\n",
      "         -6.8246e-02, -3.5444e-01, -6.6514e-02, -1.0652e-01,  6.5215e-02,\n",
      "         -1.9885e-01,  1.1737e-01,  6.5421e-02,  1.0291e-01,  1.6147e-02,\n",
      "          9.4479e-02,  9.6720e-02, -1.0984e-01,  1.1410e-01, -1.4253e-01,\n",
      "          9.8457e-03,  1.1058e-01,  8.6753e-02, -1.6419e-01, -1.1106e-01,\n",
      "         -1.2587e-01, -2.8568e-01, -2.1443e-01, -1.1912e-01,  9.6955e-02,\n",
      "         -2.2528e-01,  1.2558e-01,  7.8796e-02, -1.5936e-01,  5.2777e-02,\n",
      "         -3.2741e-02, -8.6573e-02,  7.3390e-02, -4.6412e-02, -1.1729e-01,\n",
      "          8.3446e-03,  5.2218e-02, -5.4819e-02, -8.5389e-03, -2.7739e-01,\n",
      "          1.1533e-01, -2.2743e-01,  3.6141e-04, -2.6744e-01]])), ('9.bias', tensor([-0.0565, -0.0279,  0.1148,  0.0852, -0.0270, -0.1219,  0.1397, -0.0573,\n",
      "        -0.0347, -0.0424]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The State Dict Keys \\n\\n\", model.state_dict().keys())\n",
    "print(\"\\n Updated Weights & Bias \\n\\n\", model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save state_dict of trained model to the file 'model_save.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_save.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define a new model with the same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = nn.Sequential(nn.Linear(784,256),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(256,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly initial weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[-0.0111, -0.0326, -0.0316,  ..., -0.0154, -0.0307, -0.0180],\n",
      "        [ 0.0088, -0.0185,  0.0188,  ...,  0.0228, -0.0146, -0.0287],\n",
      "        [-0.0076,  0.0239,  0.0042,  ..., -0.0220, -0.0321,  0.0095],\n",
      "        ...,\n",
      "        [ 0.0242,  0.0200, -0.0227,  ...,  0.0120,  0.0230, -0.0321],\n",
      "        [-0.0252, -0.0081, -0.0233,  ...,  0.0117, -0.0356, -0.0298],\n",
      "        [ 0.0298, -0.0244,  0.0031,  ...,  0.0289,  0.0311,  0.0318]])), ('0.bias', tensor([ 0.0027, -0.0156,  0.0312,  0.0081, -0.0259, -0.0323,  0.0340,  0.0161,\n",
      "         0.0275, -0.0143,  0.0146, -0.0023,  0.0324,  0.0173,  0.0114,  0.0327,\n",
      "         0.0211, -0.0177, -0.0104, -0.0088,  0.0352,  0.0070,  0.0229,  0.0305,\n",
      "         0.0013, -0.0192, -0.0299,  0.0268,  0.0151, -0.0046,  0.0023,  0.0154,\n",
      "         0.0081, -0.0207,  0.0094,  0.0068, -0.0341,  0.0216,  0.0102, -0.0252,\n",
      "         0.0258, -0.0028,  0.0136, -0.0167,  0.0307, -0.0342, -0.0279,  0.0077,\n",
      "         0.0269, -0.0136,  0.0069, -0.0093,  0.0213, -0.0298, -0.0347, -0.0059,\n",
      "        -0.0289, -0.0350, -0.0175,  0.0090,  0.0122, -0.0338,  0.0015,  0.0061,\n",
      "         0.0197, -0.0013, -0.0029, -0.0240,  0.0141, -0.0326, -0.0019, -0.0141,\n",
      "        -0.0190, -0.0223, -0.0132, -0.0268, -0.0028,  0.0105,  0.0013, -0.0298,\n",
      "        -0.0066,  0.0044,  0.0167,  0.0138, -0.0062,  0.0331, -0.0263, -0.0150,\n",
      "         0.0323,  0.0256,  0.0196,  0.0208,  0.0312,  0.0209,  0.0277,  0.0018,\n",
      "        -0.0089,  0.0061, -0.0217, -0.0062, -0.0297,  0.0156,  0.0268, -0.0161,\n",
      "        -0.0169,  0.0281,  0.0215,  0.0133,  0.0070, -0.0233, -0.0038, -0.0041,\n",
      "         0.0336,  0.0252, -0.0045,  0.0181, -0.0242,  0.0016, -0.0080,  0.0289,\n",
      "        -0.0160,  0.0334,  0.0100, -0.0090, -0.0337,  0.0308, -0.0345, -0.0321,\n",
      "        -0.0138,  0.0163, -0.0115, -0.0227, -0.0020,  0.0080,  0.0135,  0.0016,\n",
      "        -0.0135, -0.0096, -0.0032, -0.0050, -0.0213,  0.0344,  0.0335, -0.0293,\n",
      "        -0.0125,  0.0094, -0.0294, -0.0094, -0.0004,  0.0316,  0.0040,  0.0339,\n",
      "        -0.0120,  0.0281, -0.0331,  0.0226,  0.0261,  0.0347, -0.0165, -0.0353,\n",
      "         0.0348, -0.0232,  0.0317, -0.0277,  0.0061,  0.0198, -0.0343, -0.0345,\n",
      "         0.0283,  0.0079, -0.0198, -0.0159,  0.0292,  0.0067, -0.0206,  0.0217,\n",
      "         0.0344, -0.0190,  0.0285,  0.0082, -0.0067,  0.0259,  0.0306, -0.0332,\n",
      "         0.0271, -0.0230, -0.0087,  0.0086, -0.0067, -0.0197,  0.0121, -0.0264,\n",
      "         0.0322,  0.0028,  0.0324, -0.0200, -0.0221, -0.0184, -0.0272,  0.0026,\n",
      "        -0.0119,  0.0352, -0.0352,  0.0235, -0.0118, -0.0081, -0.0259, -0.0149,\n",
      "         0.0243, -0.0207, -0.0315, -0.0055,  0.0164,  0.0062,  0.0166, -0.0016,\n",
      "        -0.0126, -0.0290,  0.0054,  0.0199,  0.0057, -0.0097, -0.0162,  0.0208,\n",
      "         0.0281, -0.0081,  0.0071, -0.0143,  0.0159,  0.0163, -0.0073, -0.0160,\n",
      "         0.0264,  0.0048,  0.0171,  0.0127,  0.0254,  0.0294,  0.0001,  0.0328,\n",
      "        -0.0098, -0.0314, -0.0063,  0.0056,  0.0126, -0.0064,  0.0152, -0.0292,\n",
      "         0.0116,  0.0142,  0.0340, -0.0187,  0.0182,  0.0228,  0.0283,  0.0133])), ('3.weight', tensor([[-0.0106,  0.0032, -0.0249,  ..., -0.0083,  0.0606, -0.0237],\n",
      "        [-0.0114,  0.0194, -0.0066,  ..., -0.0048, -0.0295, -0.0489],\n",
      "        [ 0.0288,  0.0266,  0.0275,  ...,  0.0374,  0.0334, -0.0218],\n",
      "        ...,\n",
      "        [ 0.0052,  0.0443,  0.0561,  ..., -0.0193,  0.0234,  0.0598],\n",
      "        [-0.0207, -0.0344, -0.0083,  ...,  0.0430, -0.0431,  0.0402],\n",
      "        [-0.0092,  0.0428,  0.0381,  ..., -0.0622,  0.0576,  0.0505]])), ('3.bias', tensor([ 0.0350,  0.0084,  0.0464, -0.0116,  0.0168, -0.0347,  0.0525,  0.0054,\n",
      "         0.0360,  0.0043,  0.0441, -0.0479,  0.0356,  0.0030, -0.0065, -0.0222,\n",
      "         0.0038,  0.0483,  0.0276,  0.0012,  0.0348, -0.0010,  0.0347,  0.0128,\n",
      "         0.0521, -0.0613, -0.0423,  0.0246, -0.0290,  0.0123, -0.0494,  0.0489,\n",
      "        -0.0046, -0.0375, -0.0016, -0.0222,  0.0559, -0.0372, -0.0032, -0.0538,\n",
      "         0.0117, -0.0516,  0.0216, -0.0547, -0.0385,  0.0534, -0.0429, -0.0005,\n",
      "        -0.0090, -0.0092,  0.0013, -0.0336,  0.0220,  0.0332, -0.0322,  0.0315,\n",
      "         0.0039,  0.0017,  0.0397, -0.0243,  0.0316,  0.0302,  0.0558,  0.0153,\n",
      "        -0.0206, -0.0109, -0.0306,  0.0580, -0.0447, -0.0519,  0.0586,  0.0352,\n",
      "        -0.0086,  0.0245, -0.0131,  0.0310, -0.0106, -0.0571,  0.0525, -0.0587,\n",
      "         0.0458,  0.0260, -0.0208,  0.0307, -0.0519, -0.0525, -0.0482, -0.0567,\n",
      "        -0.0204,  0.0624,  0.0493,  0.0125,  0.0078,  0.0497,  0.0605, -0.0271,\n",
      "         0.0233, -0.0264, -0.0059, -0.0439,  0.0353, -0.0584, -0.0188, -0.0605,\n",
      "        -0.0453, -0.0494,  0.0062,  0.0510, -0.0129,  0.0093,  0.0199, -0.0117,\n",
      "        -0.0236,  0.0409,  0.0171, -0.0234, -0.0530, -0.0620, -0.0480,  0.0098,\n",
      "        -0.0315,  0.0506,  0.0079,  0.0242, -0.0114,  0.0050,  0.0619,  0.0595])), ('6.weight', tensor([[ 0.0867, -0.0877, -0.0853,  ..., -0.0631,  0.0070, -0.0769],\n",
      "        [-0.0055, -0.0703,  0.0645,  ..., -0.0340, -0.0437,  0.0337],\n",
      "        [-0.0478,  0.0761, -0.0375,  ...,  0.0085,  0.0857, -0.0121],\n",
      "        ...,\n",
      "        [-0.0187,  0.0662, -0.0159,  ...,  0.0556, -0.0658, -0.0368],\n",
      "        [ 0.0497,  0.0358, -0.0477,  ...,  0.0808, -0.0185, -0.0285],\n",
      "        [ 0.0550,  0.0490, -0.0882,  ...,  0.0858,  0.0240,  0.0369]])), ('6.bias', tensor([ 0.0602,  0.0876,  0.0840,  0.0176, -0.0807, -0.0069, -0.0723, -0.0842,\n",
      "         0.0391, -0.0802,  0.0743, -0.0058, -0.0069, -0.0413,  0.0101, -0.0818,\n",
      "         0.0793,  0.0519,  0.0727,  0.0816, -0.0827,  0.0773, -0.0416,  0.0763,\n",
      "         0.0877,  0.0800, -0.0775, -0.0523, -0.0039,  0.0460, -0.0156,  0.0120,\n",
      "         0.0683,  0.0350, -0.0159,  0.0665, -0.0342,  0.0386, -0.0127,  0.0696,\n",
      "         0.0433,  0.0531, -0.0760, -0.0589,  0.0219,  0.0147,  0.0753, -0.0510,\n",
      "        -0.0614, -0.0801,  0.0232, -0.0855,  0.0713,  0.0139, -0.0422,  0.0059,\n",
      "        -0.0777,  0.0852,  0.0142,  0.0272,  0.0238,  0.0776, -0.0216, -0.0234])), ('9.weight', tensor([[ 3.7823e-02,  9.5958e-02, -3.9999e-02,  9.2133e-02,  7.4682e-02,\n",
      "          6.7648e-02,  7.1469e-02, -2.5914e-02, -1.6464e-02,  6.5652e-02,\n",
      "         -9.9999e-02, -2.0534e-02, -4.0731e-02,  2.5396e-02,  5.1350e-02,\n",
      "          1.0509e-01,  1.7415e-02,  1.0567e-01,  1.7758e-02, -1.2485e-01,\n",
      "          1.0667e-01,  1.6592e-02,  1.2839e-02,  3.5512e-04, -3.9839e-02,\n",
      "         -3.7548e-02,  2.7979e-02,  1.6759e-02, -2.3987e-02, -4.6024e-03,\n",
      "         -9.6443e-03, -4.0760e-02, -5.6739e-02, -1.2385e-01, -9.8506e-02,\n",
      "         -9.1308e-02, -5.8568e-02, -8.1458e-02, -9.4237e-03,  9.4927e-02,\n",
      "          1.0353e-02,  1.1384e-01, -7.0919e-02,  5.0312e-02,  4.3038e-02,\n",
      "          7.3241e-02, -1.1130e-01,  5.7239e-02, -8.3715e-02,  3.4574e-03,\n",
      "          6.7410e-02,  3.9623e-02,  1.2366e-01,  1.1993e-01,  1.1692e-02,\n",
      "         -8.4966e-02,  4.6290e-02,  2.6654e-03, -5.2730e-03,  2.3185e-02,\n",
      "          1.1157e-01,  1.1976e-01, -3.2839e-03, -1.2372e-01],\n",
      "        [ 9.6199e-02, -1.0329e-01, -9.8674e-02, -7.4133e-02, -1.1354e-01,\n",
      "         -7.2538e-02, -1.2040e-01,  1.1518e-02,  2.2913e-02,  2.0508e-02,\n",
      "         -5.6552e-02, -3.8772e-02, -1.5212e-02, -3.3931e-02,  7.7438e-03,\n",
      "          6.8660e-02,  1.2008e-01, -1.0721e-01, -8.5945e-02,  1.6604e-02,\n",
      "          8.1734e-02,  2.6384e-03,  1.1664e-01, -5.1400e-02,  5.3652e-02,\n",
      "         -1.0827e-01, -1.6020e-02,  5.3220e-02,  4.4013e-02,  1.9776e-03,\n",
      "          1.3747e-03, -3.3892e-02,  1.1055e-03,  1.2844e-02, -6.4532e-02,\n",
      "          1.0485e-01,  9.1286e-02, -2.7284e-02, -5.0472e-02, -1.1431e-01,\n",
      "         -1.0511e-01, -6.6597e-02,  4.1904e-02,  1.7565e-02, -4.3027e-02,\n",
      "          2.5205e-02,  7.4961e-02, -3.6894e-02, -1.0419e-01,  6.2368e-02,\n",
      "         -9.4708e-03, -2.5374e-02,  7.5722e-02,  6.7411e-03,  6.4976e-02,\n",
      "         -5.3846e-02,  1.2193e-01, -9.8387e-02,  1.2058e-01,  1.0444e-01,\n",
      "          9.1100e-02, -3.9980e-02,  4.3486e-02, -1.0397e-01],\n",
      "        [-2.2774e-02, -7.1035e-02,  2.9088e-02,  1.1890e-01, -3.2821e-02,\n",
      "         -1.2209e-01,  1.1128e-01,  1.0857e-01,  9.5129e-02,  9.1001e-02,\n",
      "         -4.2564e-02,  1.7652e-02, -1.3561e-02,  7.5090e-02, -5.7516e-02,\n",
      "          6.0918e-02, -9.0036e-02,  2.5042e-02, -7.4420e-02,  1.5878e-02,\n",
      "         -8.1336e-02, -5.1730e-02,  3.2176e-02,  1.8198e-02, -1.2279e-02,\n",
      "          3.8025e-02, -7.3382e-02, -9.9547e-02,  1.2285e-01,  2.0080e-02,\n",
      "          1.1436e-01,  2.8803e-02, -6.3959e-02,  3.3809e-02,  1.3152e-02,\n",
      "         -6.3084e-02,  1.0826e-01,  1.1807e-01, -6.7375e-02,  1.0862e-01,\n",
      "          5.6646e-02,  6.9267e-02, -1.0394e-01,  1.0802e-01, -1.4885e-02,\n",
      "          9.4025e-02, -3.2864e-02,  4.8729e-02,  4.4396e-02, -5.6523e-02,\n",
      "          1.9641e-02, -5.7841e-02,  3.6594e-02, -1.0785e-01, -1.1335e-01,\n",
      "          5.0433e-02,  5.0195e-02,  1.8829e-02,  9.2381e-02,  1.6543e-02,\n",
      "         -9.3324e-03, -6.7204e-02, -1.1139e-01, -5.9511e-02],\n",
      "        [-3.9437e-03, -8.5768e-03,  6.0863e-02, -6.3396e-02, -8.3249e-03,\n",
      "          1.1588e-01, -9.0260e-02, -7.6535e-02,  1.1847e-01,  6.5666e-02,\n",
      "         -6.6116e-02,  5.2228e-02, -6.0142e-02, -1.1118e-01, -4.1503e-02,\n",
      "         -7.3545e-02, -2.8307e-02, -8.2177e-03, -3.7933e-03, -5.6703e-02,\n",
      "         -1.0388e-01, -2.5459e-03,  7.6445e-02, -2.0355e-02, -9.0169e-02,\n",
      "         -1.1666e-01, -9.4797e-02, -6.8986e-02,  3.4985e-02,  6.6822e-02,\n",
      "          1.2193e-01,  1.9073e-02,  1.2205e-01,  6.6806e-02,  5.8805e-02,\n",
      "         -5.2040e-03,  3.5429e-02, -8.1004e-02, -6.0791e-02, -3.1531e-02,\n",
      "          3.9036e-02,  1.1105e-01,  4.1689e-02,  7.7693e-03,  8.4910e-02,\n",
      "         -1.0857e-01, -1.2287e-02, -3.9385e-02, -1.2295e-01, -8.5276e-02,\n",
      "         -1.0815e-01, -1.0331e-01,  2.8726e-02, -4.5477e-02, -6.9480e-02,\n",
      "         -8.6087e-02,  1.1926e-02,  3.2254e-02, -6.7248e-03, -7.9249e-02,\n",
      "          1.2090e-01, -1.1705e-01,  1.1981e-01,  9.1578e-02],\n",
      "        [-7.9349e-03, -2.1944e-02, -5.1481e-02, -8.2100e-02,  6.2579e-02,\n",
      "         -7.6572e-02, -1.1909e-01,  4.9780e-02,  6.5073e-02,  1.0320e-01,\n",
      "          2.8110e-02,  6.0556e-02, -7.9141e-02,  3.7294e-02, -1.2469e-01,\n",
      "          1.2389e-01,  8.9605e-02, -3.2572e-02, -9.8978e-02,  1.2071e-01,\n",
      "          1.1396e-01, -1.5748e-02,  1.0195e-01, -6.6950e-02,  7.3294e-02,\n",
      "          6.9349e-02,  4.2142e-02, -4.0369e-02,  9.1261e-02,  2.6445e-02,\n",
      "          8.0833e-02,  6.2966e-02,  3.5121e-02,  5.7652e-02,  1.1033e-01,\n",
      "         -5.9603e-02, -6.1980e-02, -9.4468e-02,  6.6779e-02,  7.9101e-02,\n",
      "          1.0548e-01,  3.3645e-02, -3.4622e-02,  9.5259e-02,  2.9464e-02,\n",
      "         -9.2565e-02,  6.7511e-02,  8.6482e-03,  1.0681e-01, -4.2326e-02,\n",
      "         -6.7634e-02,  2.8405e-02, -1.2145e-01,  5.6053e-02,  9.9126e-02,\n",
      "         -3.1483e-02, -1.1027e-01,  1.0964e-01,  7.6936e-03,  1.7784e-02,\n",
      "         -9.1078e-02,  4.4597e-02, -8.3759e-02, -1.2321e-01],\n",
      "        [ 8.0928e-02,  8.9473e-02,  1.1145e-01, -1.2424e-01, -5.4444e-02,\n",
      "         -3.1255e-02,  3.4334e-02, -1.2203e-01, -8.9144e-02, -1.2228e-01,\n",
      "         -4.0434e-02,  8.8442e-02, -1.6907e-02,  1.1497e-01,  1.1375e-01,\n",
      "         -1.9878e-02,  8.1923e-02, -1.2355e-01, -2.8388e-02, -1.0557e-01,\n",
      "          1.6023e-02,  5.4429e-02,  1.1614e-02, -1.1841e-01, -3.4447e-02,\n",
      "         -1.9620e-02,  6.3347e-02,  1.1104e-01,  6.4657e-02, -5.7781e-02,\n",
      "          1.6202e-02,  8.4906e-02,  6.6360e-03, -3.1360e-02, -5.1435e-03,\n",
      "         -7.9966e-02, -9.3107e-02,  1.1151e-02,  3.4856e-03,  9.9230e-02,\n",
      "         -6.1267e-02,  1.0555e-01, -1.2135e-02, -5.1156e-03, -1.0612e-01,\n",
      "         -4.2021e-02, -9.4603e-02, -1.0139e-01,  7.2686e-02, -7.8233e-02,\n",
      "         -6.4200e-02,  1.0589e-01,  1.4524e-02, -1.1449e-01, -9.6966e-02,\n",
      "         -1.1398e-01, -4.8521e-02, -6.6102e-03, -1.0802e-01,  5.9025e-02,\n",
      "          2.3625e-02, -3.2233e-02, -7.6636e-02, -5.2268e-02],\n",
      "        [ 1.0521e-01, -6.0873e-03,  7.2480e-02,  1.9754e-02,  9.2632e-02,\n",
      "          7.9551e-02,  5.8347e-02, -2.1279e-02, -7.4070e-02, -5.4305e-02,\n",
      "         -1.0573e-01, -3.3881e-02, -3.6600e-03, -2.6108e-02,  9.0266e-02,\n",
      "          9.9594e-02,  1.0047e-01,  9.9195e-02,  1.1913e-01, -9.4789e-02,\n",
      "          6.6319e-02,  8.8072e-02,  1.2111e-01, -1.1433e-01, -8.0421e-03,\n",
      "          4.3681e-02, -1.1370e-01, -9.2491e-02, -1.2496e-01,  3.1584e-02,\n",
      "         -5.3841e-02, -1.1604e-01,  8.3985e-02, -5.1804e-03, -1.1561e-01,\n",
      "         -7.4128e-02, -1.3464e-02, -1.2183e-02, -5.8443e-02, -4.5827e-02,\n",
      "         -8.4972e-02, -9.1990e-02, -1.6623e-03, -4.5450e-02, -1.0839e-01,\n",
      "          1.0006e-01,  9.3296e-02, -6.4472e-02, -6.8514e-02, -1.0436e-01,\n",
      "          7.1986e-02,  2.3523e-02,  4.8164e-03, -9.9068e-02,  4.0067e-02,\n",
      "          1.9389e-02,  5.2638e-02,  6.6239e-02, -9.4044e-02,  1.6576e-02,\n",
      "         -1.0843e-01,  1.1880e-02,  3.7185e-02, -1.1419e-01],\n",
      "        [ 1.6594e-02, -9.0213e-02,  9.4101e-02,  1.2195e-01,  5.9778e-02,\n",
      "         -2.3964e-02,  6.4587e-03, -2.5271e-03, -9.9926e-03,  4.0495e-02,\n",
      "          8.5401e-02, -3.9698e-02,  4.3577e-02,  4.3801e-02,  1.0287e-01,\n",
      "          1.0660e-01,  4.5145e-02, -3.5650e-02,  1.1130e-01, -6.5712e-02,\n",
      "         -8.5863e-02, -9.2597e-02,  4.0459e-02,  5.6384e-02,  3.5141e-02,\n",
      "          2.9120e-02, -9.2349e-02, -3.3021e-02, -8.3790e-02, -1.1132e-01,\n",
      "          1.2108e-01,  4.7037e-02, -8.8922e-02, -2.8021e-02,  4.4981e-02,\n",
      "          1.5711e-02,  2.8551e-02, -1.1457e-01,  6.7066e-02,  1.1694e-01,\n",
      "          7.3510e-02, -2.1779e-03, -2.8747e-02, -1.0030e-01, -1.2341e-01,\n",
      "         -1.1592e-01,  3.6090e-03,  7.4509e-03,  5.8766e-02,  7.7517e-03,\n",
      "         -4.0577e-02,  1.6987e-06,  8.3815e-02,  1.2321e-02,  2.5518e-02,\n",
      "          8.9567e-02, -4.2093e-03,  5.8459e-03,  1.0564e-01,  3.9712e-02,\n",
      "          7.6405e-02,  8.7495e-02,  7.6468e-02,  7.5133e-02],\n",
      "        [-1.4673e-02, -7.2462e-02, -3.8072e-02, -4.6941e-02,  1.2523e-02,\n",
      "         -8.2744e-02,  4.4389e-02, -2.6141e-02, -6.6484e-02, -8.4299e-02,\n",
      "         -2.9009e-03, -1.2416e-01, -2.3100e-02,  6.1589e-02,  8.5719e-02,\n",
      "         -5.6403e-02, -7.4173e-03,  6.5308e-02,  4.9898e-02, -7.5979e-02,\n",
      "         -9.3497e-02,  2.5854e-02,  3.7321e-02, -6.5589e-02, -6.1782e-02,\n",
      "          6.2971e-02,  1.2311e-01, -6.5195e-02, -1.0364e-01, -1.1990e-01,\n",
      "         -8.2711e-02,  9.2625e-02, -8.9688e-02,  7.9031e-02, -2.6097e-02,\n",
      "          3.1776e-02,  8.1834e-02,  7.2371e-02,  5.5801e-03,  9.5111e-02,\n",
      "          9.3442e-02, -7.4877e-02,  1.1008e-01,  2.7953e-02, -5.7211e-02,\n",
      "          1.6629e-02,  1.1335e-01, -7.2923e-02, -1.8353e-03,  1.1174e-01,\n",
      "         -1.2908e-03,  5.3769e-02,  7.9439e-02,  9.8154e-02, -1.0855e-01,\n",
      "          6.0937e-02, -7.4109e-02,  8.1727e-02, -4.6252e-02,  2.6965e-02,\n",
      "         -4.0692e-02,  3.7406e-03, -3.3993e-02, -1.1365e-01],\n",
      "        [ 6.1148e-02, -4.6160e-02,  7.9979e-02,  7.7551e-02,  3.2589e-02,\n",
      "         -9.8234e-02,  3.0158e-02,  7.2415e-03,  2.0905e-02, -6.5363e-02,\n",
      "         -5.9861e-02, -3.7634e-02, -6.6334e-02,  1.5074e-02, -6.1892e-02,\n",
      "         -7.0141e-02, -8.7670e-02,  4.1318e-02, -1.0632e-01,  1.0155e-01,\n",
      "         -7.8238e-02, -7.5697e-02, -1.1250e-01,  7.7698e-02,  6.3980e-02,\n",
      "          1.0809e-01, -1.2291e-01, -1.1096e-01, -1.1491e-01, -4.6814e-02,\n",
      "         -5.7697e-02, -7.6053e-02,  3.2428e-02,  4.1987e-02, -8.0657e-02,\n",
      "          1.2428e-01,  6.8662e-02, -5.9531e-02,  8.4605e-02, -4.4022e-03,\n",
      "          4.6544e-03, -5.5225e-02, -6.5995e-02,  1.1112e-01,  8.7356e-02,\n",
      "         -7.6917e-02,  4.9720e-02, -8.0273e-02, -1.7156e-02, -6.3038e-02,\n",
      "          1.2785e-02, -6.0386e-02,  6.4783e-02, -3.4440e-02, -9.0039e-02,\n",
      "          7.7076e-03, -1.2291e-02, -9.8477e-02, -6.6212e-02, -1.1082e-01,\n",
      "          5.7467e-02, -7.8470e-02, -1.3033e-02, -1.1459e-01]])), ('9.bias', tensor([ 0.0709, -0.0476,  0.1227,  0.0893,  0.0540,  0.0694, -0.0103, -0.1055,\n",
      "        -0.0118, -0.0700]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Weights & Bias \\n\\n\", model1.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the state dict with torch.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias', '9.weight', '9.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict_saved = torch.load('model_save.pth')\n",
    "print(state_dict_saved.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the state dict into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(state_dict_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[-1.0629e-02,  2.3848e-02,  1.9177e-02,  ..., -2.4077e-02,\n",
      "         -9.6044e-05,  5.7990e-03],\n",
      "        [ 3.1818e-03,  3.5432e-02,  5.1608e-02,  ...,  1.5174e-02,\n",
      "          2.4117e-02, -6.1167e-03],\n",
      "        [ 6.7755e-02,  6.0934e-02,  6.1954e-02,  ...,  5.0990e-02,\n",
      "          6.7887e-02,  3.7037e-02],\n",
      "        ...,\n",
      "        [ 1.2702e-02,  6.7123e-02,  3.4306e-02,  ...,  1.4496e-02,\n",
      "          4.1974e-02,  4.2661e-02],\n",
      "        [-1.0375e-02, -1.4728e-02,  1.7473e-02,  ...,  3.5640e-02,\n",
      "          1.0475e-02,  1.3153e-02],\n",
      "        [ 3.7357e-02,  3.2882e-02,  6.8365e-02,  ...,  7.8092e-03,\n",
      "          2.7375e-02,  4.6199e-03]])), ('0.bias', tensor([-0.0096, -0.0223, -0.0626, -0.0365, -0.0339,  0.0192, -0.0418, -0.0289,\n",
      "        -0.0135, -0.0173, -0.0139, -0.0338, -0.0147, -0.0206,  0.0100, -0.0203,\n",
      "        -0.0236,  0.0318, -0.0084,  0.0175,  0.0152, -0.0269, -0.0035,  0.0122,\n",
      "        -0.0835, -0.0497, -0.0235,  0.0139,  0.0343, -0.0369,  0.0085, -0.0328,\n",
      "         0.0264, -0.0021, -0.0084,  0.0024, -0.0238, -0.0170, -0.0340,  0.0112,\n",
      "         0.0006, -0.0147, -0.0658, -0.0115, -0.0194,  0.0488, -0.0012, -0.0213,\n",
      "        -0.0061,  0.0081,  0.0046,  0.0109, -0.0238, -0.0204, -0.0424, -0.0294,\n",
      "         0.0030, -0.0076, -0.0243,  0.0322,  0.0148,  0.0023, -0.0446, -0.0311,\n",
      "        -0.0143, -0.0085, -0.0437, -0.0285,  0.0065, -0.0307, -0.0468, -0.0248,\n",
      "        -0.0055, -0.0173, -0.0310, -0.0172, -0.0494, -0.0057,  0.0707, -0.0389,\n",
      "         0.0638, -0.0477, -0.0510, -0.0475, -0.0109,  0.0074, -0.0260,  0.0003,\n",
      "        -0.0037, -0.0426,  0.0043, -0.0360, -0.0088, -0.0213, -0.0239, -0.0336,\n",
      "        -0.0395, -0.0117, -0.0274, -0.0287,  0.0455, -0.0349,  0.0065, -0.0363,\n",
      "        -0.0106,  0.0051, -0.0027, -0.0216, -0.0166, -0.0216, -0.0499,  0.0101,\n",
      "         0.0036, -0.0426, -0.0264, -0.0295,  0.0313,  0.0044, -0.0298, -0.0662,\n",
      "         0.0149, -0.0444,  0.0337,  0.0071, -0.0288, -0.0200, -0.0626, -0.0157,\n",
      "        -0.0316,  0.0030,  0.0160,  0.0129, -0.0124, -0.0289,  0.0185,  0.0086,\n",
      "        -0.0091, -0.0101, -0.0593, -0.0446, -0.0338, -0.0096, -0.0177, -0.0203,\n",
      "        -0.0528,  0.0263, -0.0556, -0.0057, -0.0572, -0.0028, -0.0135, -0.0216,\n",
      "        -0.0199,  0.0177, -0.0514, -0.0519,  0.0001,  0.0004,  0.0491,  0.0061,\n",
      "        -0.0154,  0.0199, -0.0310, -0.0262, -0.0017, -0.0116, -0.0065, -0.0043,\n",
      "        -0.0340,  0.0135, -0.0057,  0.0157, -0.0393,  0.0222,  0.0399,  0.0528,\n",
      "        -0.0245, -0.0698, -0.0389,  0.0124, -0.0158, -0.0367,  0.0031, -0.0233,\n",
      "        -0.0310, -0.0464, -0.0040, -0.0422, -0.0239, -0.0512,  0.0151,  0.0188,\n",
      "        -0.0392,  0.0059, -0.0278,  0.0586,  0.0010, -0.0318, -0.0009, -0.0020,\n",
      "         0.0171, -0.0324, -0.0003,  0.0245,  0.0299,  0.0068, -0.0602, -0.0046,\n",
      "         0.0101,  0.0484, -0.0176,  0.0193, -0.0273, -0.0338, -0.0480, -0.0378,\n",
      "        -0.0408, -0.0314, -0.0313, -0.0471, -0.0127, -0.0020, -0.0506,  0.0234,\n",
      "         0.0123, -0.0122, -0.0163, -0.0281,  0.0160, -0.0439,  0.0503, -0.0430,\n",
      "        -0.0300,  0.0366,  0.0543, -0.0453, -0.0388,  0.0076, -0.0082, -0.0268,\n",
      "        -0.0213, -0.0333,  0.0120,  0.0045, -0.0200,  0.0403, -0.0220, -0.0347,\n",
      "         0.0410, -0.0149, -0.0252, -0.0249, -0.0116, -0.0237,  0.0312, -0.0600])), ('3.weight', tensor([[-0.0411, -0.0378,  0.0481,  ...,  0.0484, -0.0691,  0.0482],\n",
      "        [-0.0214, -0.0293,  0.0879,  ...,  0.0101, -0.0734,  0.0510],\n",
      "        [-0.1310, -0.0348,  0.0058,  ...,  0.0016, -0.0887,  0.0942],\n",
      "        ...,\n",
      "        [-0.0267,  0.0109,  0.0057,  ...,  0.0262, -0.0277,  0.0147],\n",
      "        [ 0.0430,  0.0883, -0.0597,  ...,  0.0568,  0.0954, -0.0548],\n",
      "        [-0.0787, -0.0237, -0.0519,  ...,  0.0117,  0.0058,  0.0619]])), ('3.bias', tensor([-6.5583e-02,  2.3154e-02, -3.6025e-02,  9.5174e-02,  3.6254e-02,\n",
      "        -7.2742e-02,  2.9106e-02,  6.2240e-02,  1.7085e-02,  2.5768e-02,\n",
      "         6.8722e-03,  2.6153e-02,  1.6909e-02,  9.2107e-02, -6.4423e-04,\n",
      "        -1.3342e-02,  6.5962e-02, -1.5862e-02,  5.3566e-02, -4.4076e-03,\n",
      "         3.5854e-02, -2.0666e-02, -1.2552e-02, -1.9238e-02, -3.8179e-02,\n",
      "        -6.0219e-03,  2.6119e-02,  1.2368e-02,  3.0472e-02,  8.5000e-02,\n",
      "        -1.3772e-02, -3.4152e-02, -8.8036e-03, -3.8642e-02, -3.2361e-02,\n",
      "        -7.3230e-02,  7.6408e-02,  6.9840e-02,  2.5925e-02, -2.6220e-02,\n",
      "         1.3004e-02, -1.0427e-03,  4.8017e-02,  3.5804e-02,  6.4338e-03,\n",
      "         6.6247e-02, -4.0609e-03, -4.0797e-02, -7.0638e-03,  3.9552e-03,\n",
      "        -6.8746e-02, -1.0034e-01,  8.5212e-02, -5.8667e-02,  1.0520e-01,\n",
      "        -1.5373e-02,  2.7377e-02,  2.0232e-02, -2.1149e-02, -8.8462e-03,\n",
      "        -4.3299e-02,  4.2306e-02,  3.6085e-02,  2.8836e-02,  8.1326e-02,\n",
      "         3.2759e-02, -5.6091e-03,  2.9893e-02, -1.4543e-02,  8.9615e-02,\n",
      "         2.6314e-02, -5.7912e-02,  6.8314e-02,  3.9965e-02, -2.6251e-02,\n",
      "        -3.7666e-03, -5.4455e-02,  3.0670e-02, -7.1779e-02,  3.0194e-02,\n",
      "         9.0521e-02,  9.0599e-02, -1.0471e-02, -5.9196e-02,  8.9625e-03,\n",
      "         4.8281e-02, -3.1859e-02, -2.1395e-03,  3.4442e-02, -9.6536e-02,\n",
      "         1.5150e-02, -2.0613e-03,  3.3460e-02,  1.0150e-04, -3.7292e-02,\n",
      "         1.3835e-02,  6.4895e-02, -4.3077e-02,  1.1438e-02,  5.1525e-02,\n",
      "        -2.5730e-02,  3.9306e-02,  5.6190e-03, -8.7690e-02,  5.1530e-02,\n",
      "         6.0572e-02, -8.8471e-02,  4.3302e-02,  1.6708e-02, -3.8199e-02,\n",
      "         8.1025e-03,  3.7126e-02,  1.9570e-02, -7.3511e-03, -2.1652e-02,\n",
      "        -2.1109e-02,  6.4984e-02,  1.0264e-01, -1.6922e-02,  1.4501e-02,\n",
      "        -2.0006e-02,  7.4786e-02,  5.3976e-02, -1.1856e-02, -3.2624e-02,\n",
      "        -4.9350e-02,  9.6758e-02, -3.6679e-03])), ('6.weight', tensor([[-1.1401e-01, -1.4953e-02, -6.7941e-02,  ...,  5.2792e-02,\n",
      "         -2.9096e-03,  5.7292e-02],\n",
      "        [ 2.5998e-02, -8.5555e-02,  2.6918e-02,  ...,  7.2161e-02,\n",
      "         -1.7829e-02,  1.3939e-01],\n",
      "        [ 8.3104e-02, -1.0355e-02,  8.8939e-02,  ..., -1.2005e-02,\n",
      "         -9.7056e-03,  2.0286e-03],\n",
      "        ...,\n",
      "        [-1.2601e-01, -1.2774e-01, -1.6399e-01,  ...,  5.6293e-02,\n",
      "          7.3997e-02, -1.7623e-03],\n",
      "        [ 6.7218e-04,  7.6284e-02,  1.6413e-01,  ...,  1.6735e-01,\n",
      "         -6.7303e-02, -6.4638e-02],\n",
      "        [-1.6173e-02, -7.3387e-02, -1.1623e-04,  ..., -1.0812e-01,\n",
      "          5.0720e-02, -1.2220e-01]])), ('6.bias', tensor([-0.0294,  0.0823,  0.1139,  0.1187, -0.0755, -0.0560,  0.0051,  0.0147,\n",
      "         0.0089,  0.1343,  0.0326,  0.0200,  0.1095, -0.0368,  0.0244,  0.0147,\n",
      "         0.0259,  0.0757, -0.0009, -0.0687, -0.0237,  0.1519,  0.1176,  0.0262,\n",
      "         0.0493, -0.0346,  0.0031, -0.0331, -0.0359, -0.0385,  0.0525, -0.0464,\n",
      "         0.0525,  0.0688,  0.0746,  0.1293, -0.0016, -0.0294, -0.0378,  0.0960,\n",
      "        -0.0155,  0.0619,  0.0521,  0.0941, -0.0077,  0.0234, -0.0668,  0.0500,\n",
      "         0.0203,  0.0516, -0.0144, -0.0718,  0.0965,  0.1099,  0.0306, -0.0627,\n",
      "         0.0437,  0.1318, -0.0293,  0.0832,  0.0170, -0.0090, -0.0650,  0.1893])), ('9.weight', tensor([[-9.6290e-02, -1.3258e-01, -8.7186e-02, -1.0907e-01, -1.5673e-01,\n",
      "          8.1905e-02, -5.8897e-02, -9.1020e-02,  3.9074e-02,  5.3010e-02,\n",
      "         -1.9476e-01,  9.5412e-02,  1.9982e-02,  9.3282e-02,  2.8000e-02,\n",
      "          4.4400e-02,  6.6623e-02,  4.9247e-02, -3.4384e-02, -7.2358e-02,\n",
      "          8.6819e-02,  1.2543e-02,  7.8896e-02,  1.2547e-01, -4.8052e-02,\n",
      "          9.4385e-02, -1.2029e-01, -8.9305e-02, -1.3470e-01, -1.5213e-01,\n",
      "          1.0081e-01, -1.5949e-01,  9.2761e-02,  3.6099e-02,  9.2145e-02,\n",
      "         -3.3487e-02,  5.8893e-02,  8.1415e-02, -4.6240e-02, -4.4576e-02,\n",
      "         -1.1621e-01,  5.0285e-02,  8.3130e-02, -1.3157e-01,  9.5474e-02,\n",
      "          3.5050e-02, -1.1450e-01,  7.5207e-02, -1.8076e-02, -4.6408e-02,\n",
      "          6.2409e-02, -1.3175e-02, -1.5795e-01, -4.3468e-02, -6.8000e-02,\n",
      "          1.3760e-02, -1.0090e-01,  1.0520e-02, -4.1695e-02, -1.2313e-01,\n",
      "         -8.3159e-02, -5.6531e-02,  5.6615e-02,  5.9973e-02],\n",
      "        [ 7.1416e-02, -8.3931e-02, -1.4999e-01, -9.5918e-02,  1.2114e-01,\n",
      "          6.2775e-02, -6.9773e-03, -1.2578e-01, -1.8640e-01,  6.1290e-02,\n",
      "          3.2622e-02, -1.8543e-01, -2.9967e-02, -4.9480e-02, -6.9708e-02,\n",
      "          6.6239e-03, -2.0850e-01, -4.8207e-03,  6.4832e-02, -1.7073e-01,\n",
      "         -1.5248e-02, -1.7130e-01,  9.8841e-02, -2.5993e-02, -3.0298e-02,\n",
      "          1.3111e-01, -1.4341e-01, -8.3435e-02, -6.5278e-02, -2.7373e-01,\n",
      "         -1.3242e-01,  2.6511e-02,  1.2410e-01, -2.1577e-01,  4.2768e-02,\n",
      "         -1.7951e-01, -1.0298e-01,  4.8853e-02, -1.9543e-01, -7.5096e-02,\n",
      "          9.8496e-02, -1.4906e-01,  8.1415e-02,  7.8582e-02, -1.2621e-01,\n",
      "          5.8128e-02,  1.2378e-01, -9.1667e-02,  9.7862e-02, -8.9879e-02,\n",
      "          7.6107e-02,  9.5542e-02, -1.0603e-01, -7.6868e-02, -1.2126e-01,\n",
      "          7.0941e-02,  1.5294e-01, -1.9096e-01, -2.1554e-01, -1.9311e-01,\n",
      "         -9.2571e-02,  7.4255e-02,  1.0601e-01, -8.7786e-02],\n",
      "        [ 9.3008e-02,  4.7331e-02, -1.5464e-03,  1.1366e-01, -7.4621e-02,\n",
      "          5.3617e-02, -6.1243e-02,  1.0415e-01, -1.8168e-01,  7.0292e-02,\n",
      "          7.6815e-02,  8.7659e-02, -4.2151e-02, -5.2377e-03, -9.0479e-02,\n",
      "         -1.0022e-01,  3.9783e-02,  8.5566e-02, -1.5354e-02, -9.4759e-03,\n",
      "         -1.1870e-02,  1.8760e-02,  1.2489e-01, -8.8964e-02, -1.3614e-01,\n",
      "         -1.3028e-01, -1.4531e-01, -6.7674e-02,  5.1359e-02, -1.7202e-01,\n",
      "          5.5221e-03, -1.3273e-01, -1.5337e-01,  1.8162e-02,  1.0994e-01,\n",
      "         -1.0677e-01, -1.4035e-02, -1.0385e-01, -8.6859e-02,  5.2062e-02,\n",
      "         -1.3462e-02,  4.1651e-02, -1.3533e-01,  4.8903e-02,  1.0288e-01,\n",
      "          1.0292e-01, -1.2647e-01, -9.3699e-02, -5.4412e-02, -1.0472e-01,\n",
      "         -4.7063e-02,  8.8008e-02, -1.1451e-01, -4.7884e-02, -1.8338e-01,\n",
      "         -1.1930e-02, -9.1963e-02,  1.1815e-01, -2.1794e-01,  8.2699e-02,\n",
      "         -1.1827e-01,  3.5981e-02, -1.1086e-01,  4.8546e-02],\n",
      "        [-7.1939e-02, -7.6700e-02,  1.0041e-01, -1.2009e-01, -1.4825e-01,\n",
      "         -7.5404e-02, -1.5200e-01,  2.6522e-02,  4.9608e-03,  3.3485e-02,\n",
      "         -2.1566e-02, -1.0739e-01,  1.0757e-01,  6.6557e-02,  9.6821e-02,\n",
      "         -6.1385e-02, -7.4928e-02,  6.5977e-02,  1.3149e-01, -2.5354e-01,\n",
      "          1.3687e-01,  2.3155e-02,  3.5695e-02,  5.1275e-02,  1.1769e-01,\n",
      "          1.2490e-01, -6.3704e-02, -1.6428e-01, -1.6244e-01, -1.9245e-01,\n",
      "          6.0573e-03, -5.7233e-02,  1.1455e-01, -1.6349e-01,  2.9709e-02,\n",
      "         -1.0158e-01, -6.4530e-02, -9.3483e-02, -2.4063e-01, -2.6152e-03,\n",
      "          4.5542e-02,  2.2394e-03,  1.1930e-01, -5.3276e-02, -7.3231e-02,\n",
      "          7.4034e-02,  1.3418e-01, -2.3045e-02,  1.1555e-02, -2.7325e-01,\n",
      "          6.2278e-02, -3.9896e-02,  5.7264e-02,  1.4134e-02,  3.2377e-02,\n",
      "          1.0987e-01, -3.7498e-02, -7.5184e-02,  1.1986e-02,  1.0402e-01,\n",
      "         -1.2565e-01,  7.1137e-02, -4.6554e-02,  6.8666e-02],\n",
      "        [ 5.9701e-02,  7.0029e-02,  8.8363e-02,  8.6606e-02, -3.7731e-02,\n",
      "          3.2672e-02, -3.8140e-03,  9.8403e-02, -8.0044e-02,  8.5610e-02,\n",
      "          6.8538e-02,  6.3538e-02, -1.4580e-01, -9.2738e-02,  3.4113e-02,\n",
      "          6.7538e-02,  5.0480e-02, -5.7523e-02,  1.0432e-01,  4.2485e-03,\n",
      "         -1.2177e-01,  6.0774e-02, -8.5711e-02,  6.6401e-02, -9.7765e-02,\n",
      "          5.7525e-02, -1.3633e-01, -1.9662e-01, -6.1381e-02, -2.0332e-01,\n",
      "         -1.7784e-01, -1.1425e-01, -9.9450e-02, -1.7931e-01, -6.2840e-02,\n",
      "         -1.1198e-01,  7.0863e-02, -1.8820e-01,  3.6205e-02, -1.0027e-01,\n",
      "          4.6111e-02, -2.2024e-01,  7.7875e-02,  4.6559e-04,  8.2028e-02,\n",
      "          1.2016e-01, -1.4353e-01, -1.9955e-01,  4.7539e-02, -1.3882e-01,\n",
      "         -4.8186e-02, -1.0136e-01,  3.3076e-02,  1.2384e-02, -5.9924e-02,\n",
      "         -6.1011e-02, -1.5107e-01, -5.5874e-02, -2.2160e-01,  1.1698e-01,\n",
      "         -6.4422e-02,  4.1672e-02, -2.0208e-01,  8.4244e-03],\n",
      "        [-1.4049e-01, -5.5585e-03,  7.4961e-02, -1.2847e-01,  1.1058e-01,\n",
      "          5.7836e-02,  1.5932e-02, -2.2940e-02,  3.1654e-03, -1.9052e-01,\n",
      "          6.3212e-02, -1.7397e-01,  9.5210e-02, -3.2885e-02, -1.8914e-01,\n",
      "          9.7367e-03, -2.6982e-01, -2.0727e-02, -1.8332e-01,  8.8186e-02,\n",
      "          6.6013e-04, -1.3434e-01,  1.3477e-01, -2.1602e-01,  1.2854e-02,\n",
      "         -2.6095e-01,  1.1191e-01,  4.5590e-02, -8.2291e-02,  5.3742e-02,\n",
      "          8.3926e-02,  1.0942e-02, -1.5419e-02,  1.1488e-01, -3.2335e-01,\n",
      "          2.7156e-02, -1.2982e-02,  6.0294e-02, -1.6787e-02, -1.4779e-01,\n",
      "         -1.2095e-01, -3.3478e-01, -3.1627e-01, -1.3141e-02,  9.1183e-02,\n",
      "         -2.4488e-01,  6.3956e-02,  6.8447e-02,  5.9657e-02, -4.0927e-02,\n",
      "          8.6765e-02, -1.2044e-02,  8.4029e-02, -9.3350e-03,  9.7583e-02,\n",
      "          7.3829e-03, -1.0569e-01, -4.0556e-02, -1.5779e-01, -1.8306e-01,\n",
      "          1.2078e-01, -2.0669e-01,  7.1839e-02, -1.4523e-01],\n",
      "        [-2.5595e-02,  9.5863e-02,  1.0017e-01,  5.5463e-02,  3.0516e-02,\n",
      "          8.5716e-02, -1.7048e-01,  9.6320e-02,  3.9505e-02,  6.2963e-02,\n",
      "         -9.3019e-02,  9.3191e-02,  1.6441e-02, -1.2394e-01,  6.5662e-03,\n",
      "          1.0073e-01,  4.1441e-02,  3.1335e-02, -7.6790e-02, -5.5916e-02,\n",
      "          1.1903e-01,  6.1417e-03,  3.5092e-02,  1.2316e-01, -7.9201e-02,\n",
      "         -5.4857e-02, -1.7534e-01, -1.5592e-01, -5.9001e-02, -2.6758e-01,\n",
      "          5.7256e-02, -9.2056e-04,  5.1574e-02,  5.7372e-02, -4.2858e-02,\n",
      "         -1.4628e-01, -3.6915e-02,  8.1214e-02,  1.0283e-01, -6.3452e-02,\n",
      "         -1.6161e-01,  2.6348e-02, -3.0098e-02, -5.5432e-02, -5.8935e-03,\n",
      "          1.0977e-01, -1.4395e-02,  6.9508e-02, -1.3682e-03, -2.1998e-02,\n",
      "         -5.0461e-02,  4.5233e-02, -1.5710e-01, -5.4831e-02, -9.0636e-02,\n",
      "         -1.0095e-01, -1.2523e-01,  7.8972e-02, -3.3252e-02,  8.4882e-02,\n",
      "         -8.9181e-02, -8.4411e-02, -3.0337e-02,  4.0991e-02],\n",
      "        [-2.2083e-01,  1.1059e-01, -1.0613e-01, -3.7527e-02,  7.0097e-02,\n",
      "          3.5166e-02,  6.8907e-02, -2.3649e-01,  9.8044e-02,  1.8309e-02,\n",
      "          2.2175e-02, -1.4726e-01,  6.1599e-02,  6.2750e-02, -5.2564e-02,\n",
      "         -1.4990e-01, -3.6670e-01, -2.1704e-01, -3.3108e-01, -6.4647e-02,\n",
      "         -8.9012e-02, -3.1081e-01,  4.4855e-02, -2.0260e-01,  8.0815e-02,\n",
      "         -3.4682e-01,  8.5377e-02,  5.6135e-02,  9.1445e-02,  6.5806e-02,\n",
      "         -7.4416e-02,  1.0852e-01, -3.2495e-01,  1.1389e-01, -1.5274e-01,\n",
      "         -4.3355e-02,  1.0635e-01,  1.7159e-03, -1.5228e-01, -2.0082e-01,\n",
      "          1.4359e-02, -5.3108e-01, -2.4339e-01, -2.0755e-03, -1.3760e-01,\n",
      "         -2.2099e-01, -1.2169e-01,  1.8068e-02, -9.4910e-02,  8.3403e-02,\n",
      "         -4.5648e-02, -3.7699e-02,  8.4109e-02,  1.0616e-01,  7.2545e-02,\n",
      "         -7.0414e-02,  3.2907e-02, -1.5637e-01, -4.7229e-02, -1.2104e-01,\n",
      "          1.2420e-01, -3.2036e-01,  6.9894e-02, -3.4248e-02],\n",
      "        [-1.8184e-01, -1.5735e-01,  8.4266e-02,  7.3584e-02, -1.2249e-01,\n",
      "         -5.3354e-02,  8.9682e-02,  2.6798e-02, -1.7222e-01, -5.2879e-02,\n",
      "         -5.7986e-02,  1.0726e-01, -6.3733e-02,  1.5775e-01,  6.8542e-02,\n",
      "          6.3722e-02, -1.3791e-01, -7.9338e-02, -1.6829e-01,  2.2124e-02,\n",
      "          8.3927e-02, -1.1728e-02, -6.3121e-02,  4.6421e-02,  7.8204e-03,\n",
      "         -7.4792e-02, -6.1370e-02, -1.8925e-01,  1.2405e-02, -1.3292e-01,\n",
      "         -8.5325e-02, -1.4218e-01, -1.3629e-01,  8.6831e-02, -1.3824e-01,\n",
      "          9.2855e-02,  1.3393e-01, -1.3611e-01,  1.1944e-01, -1.2666e-01,\n",
      "         -7.8857e-02, -8.1609e-02, -9.8908e-02, -2.4441e-01, -6.7936e-02,\n",
      "         -1.3216e-01, -7.6921e-02, -1.4921e-01,  8.3423e-02,  6.5453e-02,\n",
      "         -6.3166e-02, -1.0269e-02,  8.8826e-02,  1.7025e-01,  4.7478e-02,\n",
      "          1.3483e-02, -4.4136e-02,  8.9867e-02, -2.1287e-01, -2.2058e-01,\n",
      "          9.3829e-02,  1.4975e-02,  8.4485e-02,  5.8296e-02],\n",
      "        [-1.7884e-01, -9.2574e-02, -1.9252e-01,  4.4802e-02, -9.1473e-02,\n",
      "         -1.5487e-01,  4.1162e-02, -1.9472e-01,  3.7310e-02, -1.6760e-01,\n",
      "          1.1250e-01, -5.5428e-02,  5.7675e-02, -1.2097e-01,  3.1338e-03,\n",
      "          2.3052e-02, -2.1660e-01, -1.7187e-01, -2.1197e-01, -9.3301e-02,\n",
      "         -6.8246e-02, -3.5444e-01, -6.6514e-02, -1.0652e-01,  6.5215e-02,\n",
      "         -1.9885e-01,  1.1737e-01,  6.5421e-02,  1.0291e-01,  1.6147e-02,\n",
      "          9.4479e-02,  9.6720e-02, -1.0984e-01,  1.1410e-01, -1.4253e-01,\n",
      "          9.8457e-03,  1.1058e-01,  8.6753e-02, -1.6419e-01, -1.1106e-01,\n",
      "         -1.2587e-01, -2.8568e-01, -2.1443e-01, -1.1912e-01,  9.6955e-02,\n",
      "         -2.2528e-01,  1.2558e-01,  7.8796e-02, -1.5936e-01,  5.2777e-02,\n",
      "         -3.2741e-02, -8.6573e-02,  7.3390e-02, -4.6412e-02, -1.1729e-01,\n",
      "          8.3446e-03,  5.2218e-02, -5.4819e-02, -8.5389e-03, -2.7739e-01,\n",
      "          1.1533e-01, -2.2743e-01,  3.6141e-04, -2.6744e-01]])), ('9.bias', tensor([-0.0565, -0.0279,  0.1148,  0.0852, -0.0270, -0.1219,  0.1397, -0.0573,\n",
      "        -0.0347, -0.0424]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights & Bias \\n\\n\", model1.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the saved model architecture. If we create a model with a different architecture, this fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nn.Sequential(nn.Linear(784,250),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(250,125),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(125,63),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(63,10),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([256, 784]) from checkpoint, the shape in current model is torch.Size([250, 784]).\n\tsize mismatch for 0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([250]).\n\tsize mismatch for 3.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([125, 250]).\n\tsize mismatch for 3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([125]).\n\tsize mismatch for 6.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([63, 125]).\n\tsize mismatch for 6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([63]).\n\tsize mismatch for 9.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 63]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a628f7be4a8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict_saved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1045\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1046\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 0.weight: copying a param with shape torch.Size([256, 784]) from checkpoint, the shape in current model is torch.Size([250, 784]).\n\tsize mismatch for 0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([250]).\n\tsize mismatch for 3.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([125, 250]).\n\tsize mismatch for 3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([125]).\n\tsize mismatch for 6.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([63, 125]).\n\tsize mismatch for 6.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([63]).\n\tsize mismatch for 9.weight: copying a param with shape torch.Size([10, 64]) from checkpoint, the shape in current model is torch.Size([10, 63])."
     ]
    }
   ],
   "source": [
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model2.load_state_dict(state_dict_saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Model with Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the 'model_save.pth', along with the state dict. To do this, we build a dictionary with all the information we need to compeletely rebuild the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model with model dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter               # for getting specific layers (hidden layers) while saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\"input_size\" : 784,\n",
    "              \"output_size\" : 10,\n",
    "              \"hidden_layers\" : [each.out_features for each in itemgetter(0,3,6,9)(model)],  #0,3,6,9 - hidden layers with weights & bias\n",
    "              \"state_dict\" : model.state_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, 'model_save2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Model dimensions, Weights & Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint1 = torch.load('model_save2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = checkpoint1['input_size']\n",
    "out_size = checkpoint1['output_size']\n",
    "hidden_size = checkpoint1['hidden_layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = nn.Sequential(nn.Linear(in_size,hidden_size[0]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(hidden_size[0],hidden_size[1]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(hidden_size[1],hidden_size[2]),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Dropout(p=0.2),\n",
    "                     nn.Linear(hidden_size[2],hidden_size[3]),\n",
    "                     nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[ 0.0301, -0.0315, -0.0308,  ...,  0.0137,  0.0169, -0.0145],\n",
      "        [-0.0268, -0.0189,  0.0197,  ..., -0.0048,  0.0333,  0.0240],\n",
      "        [-0.0108, -0.0253,  0.0045,  ..., -0.0233,  0.0235, -0.0331],\n",
      "        ...,\n",
      "        [-0.0050,  0.0349, -0.0294,  ..., -0.0225, -0.0229, -0.0093],\n",
      "        [ 0.0040, -0.0037,  0.0231,  ...,  0.0267, -0.0193,  0.0309],\n",
      "        [ 0.0218, -0.0288, -0.0341,  ..., -0.0172,  0.0066,  0.0084]])), ('0.bias', tensor([ 0.0031, -0.0126, -0.0191,  0.0073,  0.0050,  0.0050,  0.0215, -0.0007,\n",
      "         0.0352, -0.0305, -0.0122,  0.0111,  0.0002,  0.0048, -0.0108,  0.0161,\n",
      "         0.0106, -0.0210,  0.0275,  0.0090, -0.0332,  0.0268,  0.0081, -0.0313,\n",
      "         0.0187,  0.0276, -0.0255,  0.0249, -0.0115, -0.0241, -0.0166,  0.0152,\n",
      "        -0.0239,  0.0200, -0.0352, -0.0293,  0.0312, -0.0018, -0.0202,  0.0044,\n",
      "         0.0318, -0.0301,  0.0125,  0.0346,  0.0303,  0.0287, -0.0307,  0.0094,\n",
      "        -0.0043,  0.0349, -0.0263,  0.0160,  0.0083, -0.0342,  0.0087, -0.0338,\n",
      "         0.0188, -0.0232,  0.0284,  0.0078,  0.0059,  0.0225, -0.0348,  0.0202,\n",
      "        -0.0023, -0.0153, -0.0093,  0.0181,  0.0312, -0.0038, -0.0112, -0.0161,\n",
      "        -0.0307, -0.0185,  0.0282, -0.0072,  0.0143,  0.0338, -0.0189,  0.0048,\n",
      "        -0.0141,  0.0106,  0.0122,  0.0321,  0.0206,  0.0029, -0.0277,  0.0353,\n",
      "        -0.0150,  0.0044,  0.0231, -0.0190,  0.0320,  0.0326, -0.0254,  0.0314,\n",
      "         0.0141, -0.0008, -0.0102, -0.0191, -0.0232, -0.0157, -0.0042,  0.0270,\n",
      "        -0.0046, -0.0276, -0.0081,  0.0244, -0.0228,  0.0069,  0.0054,  0.0148,\n",
      "         0.0261, -0.0059,  0.0080,  0.0244, -0.0352, -0.0284,  0.0329,  0.0137,\n",
      "         0.0252,  0.0263, -0.0285,  0.0167, -0.0041,  0.0014, -0.0268, -0.0284,\n",
      "         0.0187, -0.0178,  0.0073, -0.0217, -0.0048,  0.0286, -0.0079,  0.0319,\n",
      "        -0.0041, -0.0235,  0.0282, -0.0253,  0.0053, -0.0248,  0.0328, -0.0207,\n",
      "         0.0021, -0.0285, -0.0240, -0.0178, -0.0135, -0.0228, -0.0079, -0.0283,\n",
      "         0.0205, -0.0254,  0.0068,  0.0088,  0.0347, -0.0108,  0.0021,  0.0215,\n",
      "         0.0335, -0.0145, -0.0339,  0.0116, -0.0214, -0.0139,  0.0109,  0.0115,\n",
      "        -0.0224,  0.0328, -0.0150, -0.0056, -0.0246, -0.0089, -0.0049,  0.0045,\n",
      "         0.0079,  0.0174,  0.0188, -0.0067,  0.0031,  0.0018,  0.0265,  0.0122,\n",
      "        -0.0090,  0.0350, -0.0214, -0.0309, -0.0132, -0.0342,  0.0148,  0.0029,\n",
      "        -0.0212,  0.0042, -0.0174,  0.0258,  0.0322, -0.0014, -0.0058,  0.0131,\n",
      "        -0.0177, -0.0042, -0.0058,  0.0271,  0.0027, -0.0170,  0.0346,  0.0315,\n",
      "        -0.0071,  0.0032, -0.0047,  0.0229,  0.0024,  0.0145, -0.0221, -0.0191,\n",
      "         0.0056,  0.0310, -0.0181, -0.0071, -0.0088,  0.0300, -0.0187, -0.0228,\n",
      "        -0.0021, -0.0168,  0.0101,  0.0333,  0.0104,  0.0255,  0.0303, -0.0352,\n",
      "        -0.0145, -0.0147,  0.0225,  0.0134, -0.0025,  0.0043, -0.0181, -0.0205,\n",
      "        -0.0215, -0.0191,  0.0123, -0.0187, -0.0151, -0.0156, -0.0050, -0.0232,\n",
      "         0.0257,  0.0306,  0.0118,  0.0286, -0.0321, -0.0307,  0.0264, -0.0048])), ('3.weight', tensor([[ 0.0011,  0.0043, -0.0262,  ...,  0.0031, -0.0589,  0.0516],\n",
      "        [ 0.0040,  0.0137, -0.0070,  ...,  0.0580, -0.0389, -0.0209],\n",
      "        [-0.0177,  0.0252,  0.0108,  ..., -0.0452, -0.0216, -0.0308],\n",
      "        ...,\n",
      "        [-0.0126,  0.0388, -0.0065,  ...,  0.0566, -0.0064, -0.0042],\n",
      "        [ 0.0502, -0.0382,  0.0425,  ..., -0.0413,  0.0247, -0.0188],\n",
      "        [ 0.0224, -0.0569, -0.0154,  ..., -0.0375,  0.0552, -0.0260]])), ('3.bias', tensor([ 0.0116, -0.0479,  0.0585, -0.0260,  0.0464,  0.0529,  0.0255, -0.0231,\n",
      "         0.0192, -0.0467,  0.0222, -0.0176, -0.0591, -0.0370, -0.0262, -0.0106,\n",
      "         0.0334, -0.0386, -0.0174,  0.0147, -0.0221,  0.0025,  0.0146, -0.0468,\n",
      "        -0.0211, -0.0262, -0.0452,  0.0082, -0.0082,  0.0325,  0.0175,  0.0452,\n",
      "        -0.0247, -0.0403, -0.0505,  0.0255,  0.0312, -0.0114,  0.0575,  0.0185,\n",
      "         0.0293, -0.0507, -0.0199,  0.0159, -0.0443,  0.0225, -0.0467, -0.0181,\n",
      "        -0.0264, -0.0617, -0.0133,  0.0098, -0.0581, -0.0083,  0.0321, -0.0553,\n",
      "        -0.0076,  0.0388, -0.0185,  0.0237, -0.0115,  0.0338,  0.0247,  0.0349,\n",
      "        -0.0381,  0.0221, -0.0068, -0.0281, -0.0403, -0.0043,  0.0573, -0.0276,\n",
      "        -0.0109,  0.0319, -0.0024,  0.0007, -0.0589,  0.0480, -0.0402,  0.0426,\n",
      "         0.0114,  0.0252, -0.0459,  0.0021, -0.0135, -0.0231, -0.0083, -0.0192,\n",
      "         0.0235, -0.0498,  0.0228,  0.0601, -0.0265, -0.0284, -0.0593,  0.0257,\n",
      "        -0.0418,  0.0567, -0.0189,  0.0607, -0.0194,  0.0503, -0.0079, -0.0575,\n",
      "        -0.0049, -0.0411,  0.0283, -0.0086,  0.0051,  0.0324,  0.0217,  0.0241,\n",
      "        -0.0061,  0.0396, -0.0549, -0.0286,  0.0040,  0.0311, -0.0199,  0.0161,\n",
      "        -0.0561,  0.0343,  0.0200,  0.0436,  0.0015,  0.0498,  0.0535,  0.0243])), ('6.weight', tensor([[ 0.0797,  0.0804, -0.0071,  ...,  0.0199,  0.0598,  0.0638],\n",
      "        [ 0.0297,  0.0354, -0.0097,  ..., -0.0466,  0.0060,  0.0643],\n",
      "        [ 0.0278, -0.0149, -0.0644,  ...,  0.0264, -0.0172,  0.0412],\n",
      "        ...,\n",
      "        [-0.0008, -0.0866,  0.0184,  ..., -0.0245,  0.0804, -0.0525],\n",
      "        [ 0.0683,  0.0420,  0.0779,  ..., -0.0299, -0.0341, -0.0555],\n",
      "        [-0.0646,  0.0394,  0.0741,  ...,  0.0205, -0.0315,  0.0598]])), ('6.bias', tensor([ 0.0849,  0.0060,  0.0771, -0.0750, -0.0443, -0.0763, -0.0684, -0.0152,\n",
      "        -0.0191, -0.0371, -0.0850, -0.0164,  0.0065,  0.0099,  0.0171, -0.0372,\n",
      "        -0.0474, -0.0451,  0.0183,  0.0171, -0.0414,  0.0030, -0.0480,  0.0358,\n",
      "        -0.0718,  0.0346, -0.0764, -0.0768,  0.0210, -0.0108, -0.0727,  0.0528,\n",
      "        -0.0657,  0.0609, -0.0585,  0.0146, -0.0440, -0.0166, -0.0368, -0.0477,\n",
      "         0.0559, -0.0266,  0.0257, -0.0091, -0.0627,  0.0307,  0.0010, -0.0078,\n",
      "        -0.0820,  0.0131,  0.0516,  0.0179, -0.0623, -0.0146, -0.0356,  0.0826,\n",
      "         0.0021, -0.0790, -0.0795, -0.0315,  0.0642,  0.0291,  0.0796,  0.0811])), ('9.weight', tensor([[-0.0074,  0.1096,  0.1055,  0.0577,  0.1007,  0.0037,  0.0121, -0.0481,\n",
      "          0.0556, -0.0671, -0.0814, -0.0843,  0.0619, -0.0364,  0.0726, -0.0218,\n",
      "          0.0205,  0.0725,  0.0667, -0.0848, -0.0780,  0.0973, -0.1227,  0.1097,\n",
      "         -0.0170, -0.0099,  0.0772,  0.0246,  0.0731, -0.0924, -0.0090,  0.1106,\n",
      "         -0.0090,  0.1167,  0.0416, -0.0945,  0.0697,  0.0780,  0.0576,  0.0458,\n",
      "          0.0243, -0.0810, -0.0583, -0.0653, -0.0386,  0.0689, -0.0388, -0.0094,\n",
      "         -0.0603,  0.0947,  0.0624, -0.0389, -0.0950, -0.0341,  0.0956,  0.0127,\n",
      "          0.0064,  0.1110, -0.0636, -0.0218,  0.0151,  0.0922,  0.0019, -0.0568],\n",
      "        [ 0.0469,  0.0322,  0.0992, -0.0103,  0.0885,  0.0194,  0.0398, -0.0918,\n",
      "         -0.0539, -0.1102, -0.0446, -0.1054,  0.0855, -0.1086, -0.1007,  0.0261,\n",
      "          0.1090, -0.0438, -0.0241, -0.0193, -0.0523, -0.0160,  0.0621, -0.0621,\n",
      "          0.0947,  0.0499,  0.1176, -0.0564,  0.0340,  0.0326, -0.0731, -0.0121,\n",
      "          0.0811, -0.0794,  0.0498,  0.0985,  0.0515, -0.1002, -0.0914,  0.0349,\n",
      "         -0.0574,  0.0581, -0.0297,  0.0177,  0.0621, -0.1135, -0.1171, -0.0586,\n",
      "          0.0299, -0.0142, -0.0632, -0.0191, -0.0197,  0.0417, -0.0935, -0.1056,\n",
      "         -0.1211,  0.1053, -0.0540, -0.0556,  0.0255,  0.0933, -0.0310,  0.0876],\n",
      "        [-0.0648,  0.0675,  0.0470, -0.0084, -0.0845,  0.1233, -0.0456,  0.0195,\n",
      "          0.0378, -0.1140, -0.0439,  0.0888, -0.1019,  0.1141, -0.0370,  0.0578,\n",
      "          0.1203,  0.0066,  0.1079, -0.0592,  0.1245,  0.0853,  0.0898, -0.1061,\n",
      "         -0.0201, -0.0054, -0.0541, -0.0444,  0.0771,  0.1081, -0.0946,  0.0271,\n",
      "          0.0107,  0.0049, -0.0121,  0.0157, -0.0257,  0.1058, -0.0924, -0.0755,\n",
      "         -0.0359,  0.0251, -0.1183, -0.1212,  0.0030,  0.0093, -0.0060, -0.0722,\n",
      "         -0.1178, -0.0694,  0.1105, -0.0402, -0.0294,  0.0099,  0.0072,  0.0592,\n",
      "         -0.1108, -0.1213,  0.0708, -0.1045,  0.0284,  0.0530,  0.0645, -0.1199],\n",
      "        [-0.0964,  0.0195,  0.0510,  0.0396,  0.0750,  0.0486, -0.0428, -0.0307,\n",
      "         -0.0337, -0.0976,  0.1138, -0.0709,  0.0346, -0.0085,  0.1143,  0.0962,\n",
      "          0.0935,  0.0424,  0.0559,  0.0854, -0.0530,  0.0933, -0.1115,  0.1061,\n",
      "          0.0004, -0.0969,  0.0860,  0.0173,  0.0922, -0.0453,  0.0024,  0.1140,\n",
      "         -0.1036,  0.1014, -0.0450, -0.1000,  0.0182, -0.0833,  0.0936,  0.1229,\n",
      "          0.1232, -0.0444, -0.0665, -0.0954,  0.0348, -0.0085,  0.0868,  0.0785,\n",
      "          0.0682, -0.0005, -0.0600,  0.0563,  0.0084, -0.0257, -0.1001, -0.0527,\n",
      "         -0.0659,  0.0026,  0.1002, -0.0656,  0.1200,  0.0415, -0.0918, -0.0526],\n",
      "        [ 0.0904, -0.0067,  0.0124,  0.0652,  0.0902, -0.0941, -0.0664,  0.0007,\n",
      "          0.0348,  0.0428, -0.0447,  0.0056, -0.1169,  0.1169,  0.0152, -0.0475,\n",
      "         -0.0256,  0.0515, -0.0983, -0.0582, -0.0932, -0.0628,  0.1069,  0.0561,\n",
      "          0.0491, -0.0947, -0.0662, -0.0780,  0.0835,  0.0597,  0.0318, -0.1004,\n",
      "         -0.0524, -0.0594,  0.0771, -0.0700, -0.0863, -0.0104,  0.0675, -0.0596,\n",
      "         -0.0821, -0.0848, -0.0930, -0.0419,  0.0360, -0.0764,  0.0842, -0.1201,\n",
      "          0.0235, -0.1044,  0.0647,  0.1042, -0.0676,  0.0573,  0.0642,  0.1074,\n",
      "          0.0606, -0.1196, -0.0242,  0.0035,  0.0259, -0.0626,  0.0791, -0.0102],\n",
      "        [-0.0669,  0.0231, -0.1116,  0.0591,  0.0963, -0.0777,  0.0184, -0.0801,\n",
      "         -0.0266,  0.0851,  0.0054, -0.1220,  0.0345, -0.0710, -0.0592,  0.0055,\n",
      "         -0.0350, -0.0117, -0.1106,  0.1230,  0.1188, -0.0972,  0.0850, -0.0651,\n",
      "         -0.0607, -0.0913,  0.0485,  0.0885, -0.0700, -0.1219, -0.0196, -0.0861,\n",
      "          0.0519,  0.0738, -0.0936,  0.0190, -0.0136, -0.0727, -0.0663, -0.1198,\n",
      "          0.0759,  0.0432, -0.0960,  0.0565, -0.0409, -0.1199,  0.0971, -0.1101,\n",
      "         -0.0487, -0.0112,  0.0749, -0.0679, -0.0143, -0.0561, -0.0627, -0.0924,\n",
      "          0.0567,  0.0719,  0.0685,  0.1046, -0.1049, -0.0513, -0.0339,  0.1171],\n",
      "        [-0.0499, -0.0389,  0.0770,  0.0871,  0.0335,  0.0498,  0.0905,  0.0463,\n",
      "         -0.0972,  0.0856, -0.0691,  0.0257, -0.0714,  0.0260, -0.0526,  0.0372,\n",
      "         -0.0597, -0.0871, -0.0739,  0.0169, -0.0212, -0.0129,  0.1153,  0.0937,\n",
      "          0.0132, -0.0533,  0.0645,  0.0331, -0.0391, -0.0163,  0.1021,  0.0573,\n",
      "         -0.0629,  0.1058,  0.0768,  0.0655,  0.0797,  0.0504, -0.0394,  0.1237,\n",
      "          0.0035,  0.1086, -0.0899, -0.1025, -0.0973, -0.0169,  0.0870,  0.0572,\n",
      "         -0.0625, -0.1229, -0.0225,  0.1180,  0.0769,  0.0135,  0.0075,  0.0951,\n",
      "         -0.1113, -0.0799,  0.0544,  0.1065,  0.0450, -0.0952,  0.0028, -0.0018],\n",
      "        [ 0.0723,  0.1153,  0.0331,  0.1180,  0.1249,  0.0234,  0.0314,  0.0556,\n",
      "         -0.1164, -0.0803,  0.0568, -0.0608, -0.0099,  0.1134, -0.0615, -0.0551,\n",
      "         -0.0233,  0.0025,  0.0882,  0.0639, -0.0294, -0.0893,  0.0589,  0.0811,\n",
      "          0.1059, -0.0685, -0.0576, -0.0906,  0.1239,  0.0339, -0.1245,  0.0835,\n",
      "          0.0521, -0.0861,  0.0692, -0.0765,  0.0202, -0.0351, -0.0165, -0.0317,\n",
      "          0.0830, -0.0976,  0.0630, -0.0080, -0.0669, -0.0934, -0.0395, -0.0175,\n",
      "         -0.1229, -0.1246, -0.0951,  0.0346,  0.1238,  0.0018, -0.0231, -0.0544,\n",
      "         -0.1219,  0.1241, -0.0307, -0.0885, -0.0155,  0.0624, -0.0750, -0.0567],\n",
      "        [ 0.1072,  0.0743,  0.1037, -0.0843,  0.1100,  0.0820, -0.0199,  0.0482,\n",
      "         -0.0178, -0.0297, -0.0091,  0.0738, -0.0220,  0.1159, -0.1196, -0.0681,\n",
      "         -0.1180,  0.0432, -0.1186,  0.0354, -0.0512, -0.0269, -0.0128, -0.0143,\n",
      "         -0.0864, -0.0713,  0.0077,  0.0766, -0.0380, -0.0463, -0.1186,  0.1001,\n",
      "          0.0958, -0.1007,  0.0709,  0.0158,  0.0918,  0.0864, -0.1121, -0.0863,\n",
      "          0.0510, -0.0691, -0.0256,  0.1245,  0.0025,  0.0724, -0.0130, -0.0460,\n",
      "         -0.0102, -0.0918,  0.1211,  0.1036, -0.0660,  0.0186,  0.1115,  0.0708,\n",
      "         -0.0941,  0.0142,  0.1040, -0.1083, -0.0268, -0.0648, -0.1225, -0.1086],\n",
      "        [ 0.0106,  0.1139,  0.0293, -0.0350, -0.0285,  0.0798,  0.0309,  0.1026,\n",
      "          0.1106,  0.0072,  0.0235,  0.0142, -0.0280,  0.0077,  0.0763, -0.0277,\n",
      "         -0.0565, -0.0273, -0.0380, -0.1111,  0.0258, -0.0509,  0.0429, -0.0974,\n",
      "          0.0162, -0.0235, -0.0491, -0.0907,  0.0285,  0.1031, -0.0861, -0.0323,\n",
      "         -0.0924,  0.0349, -0.0390, -0.0540, -0.0632,  0.0927, -0.0653, -0.0247,\n",
      "          0.0772, -0.0209, -0.0665,  0.0115, -0.0998, -0.1185, -0.0365, -0.0807,\n",
      "          0.1037,  0.0388,  0.0411,  0.1043, -0.0762, -0.0660, -0.0521,  0.0774,\n",
      "          0.0057, -0.0696, -0.0429,  0.0871, -0.0065, -0.1127,  0.0577,  0.0899]])), ('9.bias', tensor([-0.1197, -0.0273,  0.0472,  0.0779,  0.0249,  0.0411, -0.1010,  0.0286,\n",
      "         0.0118, -0.0747]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Weights & Bias \\n\\n\", model3.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.load_state_dict(checkpoint1['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights & Bias \n",
      "\n",
      " OrderedDict([('0.weight', tensor([[-1.0629e-02,  2.3848e-02,  1.9177e-02,  ..., -2.4077e-02,\n",
      "         -9.6044e-05,  5.7990e-03],\n",
      "        [ 3.1818e-03,  3.5432e-02,  5.1608e-02,  ...,  1.5174e-02,\n",
      "          2.4117e-02, -6.1167e-03],\n",
      "        [ 6.7755e-02,  6.0934e-02,  6.1954e-02,  ...,  5.0990e-02,\n",
      "          6.7887e-02,  3.7037e-02],\n",
      "        ...,\n",
      "        [ 1.2702e-02,  6.7123e-02,  3.4306e-02,  ...,  1.4496e-02,\n",
      "          4.1974e-02,  4.2661e-02],\n",
      "        [-1.0375e-02, -1.4728e-02,  1.7473e-02,  ...,  3.5640e-02,\n",
      "          1.0475e-02,  1.3153e-02],\n",
      "        [ 3.7357e-02,  3.2882e-02,  6.8365e-02,  ...,  7.8092e-03,\n",
      "          2.7375e-02,  4.6199e-03]])), ('0.bias', tensor([-0.0096, -0.0223, -0.0626, -0.0365, -0.0339,  0.0192, -0.0418, -0.0289,\n",
      "        -0.0135, -0.0173, -0.0139, -0.0338, -0.0147, -0.0206,  0.0100, -0.0203,\n",
      "        -0.0236,  0.0318, -0.0084,  0.0175,  0.0152, -0.0269, -0.0035,  0.0122,\n",
      "        -0.0835, -0.0497, -0.0235,  0.0139,  0.0343, -0.0369,  0.0085, -0.0328,\n",
      "         0.0264, -0.0021, -0.0084,  0.0024, -0.0238, -0.0170, -0.0340,  0.0112,\n",
      "         0.0006, -0.0147, -0.0658, -0.0115, -0.0194,  0.0488, -0.0012, -0.0213,\n",
      "        -0.0061,  0.0081,  0.0046,  0.0109, -0.0238, -0.0204, -0.0424, -0.0294,\n",
      "         0.0030, -0.0076, -0.0243,  0.0322,  0.0148,  0.0023, -0.0446, -0.0311,\n",
      "        -0.0143, -0.0085, -0.0437, -0.0285,  0.0065, -0.0307, -0.0468, -0.0248,\n",
      "        -0.0055, -0.0173, -0.0310, -0.0172, -0.0494, -0.0057,  0.0707, -0.0389,\n",
      "         0.0638, -0.0477, -0.0510, -0.0475, -0.0109,  0.0074, -0.0260,  0.0003,\n",
      "        -0.0037, -0.0426,  0.0043, -0.0360, -0.0088, -0.0213, -0.0239, -0.0336,\n",
      "        -0.0395, -0.0117, -0.0274, -0.0287,  0.0455, -0.0349,  0.0065, -0.0363,\n",
      "        -0.0106,  0.0051, -0.0027, -0.0216, -0.0166, -0.0216, -0.0499,  0.0101,\n",
      "         0.0036, -0.0426, -0.0264, -0.0295,  0.0313,  0.0044, -0.0298, -0.0662,\n",
      "         0.0149, -0.0444,  0.0337,  0.0071, -0.0288, -0.0200, -0.0626, -0.0157,\n",
      "        -0.0316,  0.0030,  0.0160,  0.0129, -0.0124, -0.0289,  0.0185,  0.0086,\n",
      "        -0.0091, -0.0101, -0.0593, -0.0446, -0.0338, -0.0096, -0.0177, -0.0203,\n",
      "        -0.0528,  0.0263, -0.0556, -0.0057, -0.0572, -0.0028, -0.0135, -0.0216,\n",
      "        -0.0199,  0.0177, -0.0514, -0.0519,  0.0001,  0.0004,  0.0491,  0.0061,\n",
      "        -0.0154,  0.0199, -0.0310, -0.0262, -0.0017, -0.0116, -0.0065, -0.0043,\n",
      "        -0.0340,  0.0135, -0.0057,  0.0157, -0.0393,  0.0222,  0.0399,  0.0528,\n",
      "        -0.0245, -0.0698, -0.0389,  0.0124, -0.0158, -0.0367,  0.0031, -0.0233,\n",
      "        -0.0310, -0.0464, -0.0040, -0.0422, -0.0239, -0.0512,  0.0151,  0.0188,\n",
      "        -0.0392,  0.0059, -0.0278,  0.0586,  0.0010, -0.0318, -0.0009, -0.0020,\n",
      "         0.0171, -0.0324, -0.0003,  0.0245,  0.0299,  0.0068, -0.0602, -0.0046,\n",
      "         0.0101,  0.0484, -0.0176,  0.0193, -0.0273, -0.0338, -0.0480, -0.0378,\n",
      "        -0.0408, -0.0314, -0.0313, -0.0471, -0.0127, -0.0020, -0.0506,  0.0234,\n",
      "         0.0123, -0.0122, -0.0163, -0.0281,  0.0160, -0.0439,  0.0503, -0.0430,\n",
      "        -0.0300,  0.0366,  0.0543, -0.0453, -0.0388,  0.0076, -0.0082, -0.0268,\n",
      "        -0.0213, -0.0333,  0.0120,  0.0045, -0.0200,  0.0403, -0.0220, -0.0347,\n",
      "         0.0410, -0.0149, -0.0252, -0.0249, -0.0116, -0.0237,  0.0312, -0.0600])), ('3.weight', tensor([[-0.0411, -0.0378,  0.0481,  ...,  0.0484, -0.0691,  0.0482],\n",
      "        [-0.0214, -0.0293,  0.0879,  ...,  0.0101, -0.0734,  0.0510],\n",
      "        [-0.1310, -0.0348,  0.0058,  ...,  0.0016, -0.0887,  0.0942],\n",
      "        ...,\n",
      "        [-0.0267,  0.0109,  0.0057,  ...,  0.0262, -0.0277,  0.0147],\n",
      "        [ 0.0430,  0.0883, -0.0597,  ...,  0.0568,  0.0954, -0.0548],\n",
      "        [-0.0787, -0.0237, -0.0519,  ...,  0.0117,  0.0058,  0.0619]])), ('3.bias', tensor([-6.5583e-02,  2.3154e-02, -3.6025e-02,  9.5174e-02,  3.6254e-02,\n",
      "        -7.2742e-02,  2.9106e-02,  6.2240e-02,  1.7085e-02,  2.5768e-02,\n",
      "         6.8722e-03,  2.6153e-02,  1.6909e-02,  9.2107e-02, -6.4423e-04,\n",
      "        -1.3342e-02,  6.5962e-02, -1.5862e-02,  5.3566e-02, -4.4076e-03,\n",
      "         3.5854e-02, -2.0666e-02, -1.2552e-02, -1.9238e-02, -3.8179e-02,\n",
      "        -6.0219e-03,  2.6119e-02,  1.2368e-02,  3.0472e-02,  8.5000e-02,\n",
      "        -1.3772e-02, -3.4152e-02, -8.8036e-03, -3.8642e-02, -3.2361e-02,\n",
      "        -7.3230e-02,  7.6408e-02,  6.9840e-02,  2.5925e-02, -2.6220e-02,\n",
      "         1.3004e-02, -1.0427e-03,  4.8017e-02,  3.5804e-02,  6.4338e-03,\n",
      "         6.6247e-02, -4.0609e-03, -4.0797e-02, -7.0638e-03,  3.9552e-03,\n",
      "        -6.8746e-02, -1.0034e-01,  8.5212e-02, -5.8667e-02,  1.0520e-01,\n",
      "        -1.5373e-02,  2.7377e-02,  2.0232e-02, -2.1149e-02, -8.8462e-03,\n",
      "        -4.3299e-02,  4.2306e-02,  3.6085e-02,  2.8836e-02,  8.1326e-02,\n",
      "         3.2759e-02, -5.6091e-03,  2.9893e-02, -1.4543e-02,  8.9615e-02,\n",
      "         2.6314e-02, -5.7912e-02,  6.8314e-02,  3.9965e-02, -2.6251e-02,\n",
      "        -3.7666e-03, -5.4455e-02,  3.0670e-02, -7.1779e-02,  3.0194e-02,\n",
      "         9.0521e-02,  9.0599e-02, -1.0471e-02, -5.9196e-02,  8.9625e-03,\n",
      "         4.8281e-02, -3.1859e-02, -2.1395e-03,  3.4442e-02, -9.6536e-02,\n",
      "         1.5150e-02, -2.0613e-03,  3.3460e-02,  1.0150e-04, -3.7292e-02,\n",
      "         1.3835e-02,  6.4895e-02, -4.3077e-02,  1.1438e-02,  5.1525e-02,\n",
      "        -2.5730e-02,  3.9306e-02,  5.6190e-03, -8.7690e-02,  5.1530e-02,\n",
      "         6.0572e-02, -8.8471e-02,  4.3302e-02,  1.6708e-02, -3.8199e-02,\n",
      "         8.1025e-03,  3.7126e-02,  1.9570e-02, -7.3511e-03, -2.1652e-02,\n",
      "        -2.1109e-02,  6.4984e-02,  1.0264e-01, -1.6922e-02,  1.4501e-02,\n",
      "        -2.0006e-02,  7.4786e-02,  5.3976e-02, -1.1856e-02, -3.2624e-02,\n",
      "        -4.9350e-02,  9.6758e-02, -3.6679e-03])), ('6.weight', tensor([[-1.1401e-01, -1.4953e-02, -6.7941e-02,  ...,  5.2792e-02,\n",
      "         -2.9096e-03,  5.7292e-02],\n",
      "        [ 2.5998e-02, -8.5555e-02,  2.6918e-02,  ...,  7.2161e-02,\n",
      "         -1.7829e-02,  1.3939e-01],\n",
      "        [ 8.3104e-02, -1.0355e-02,  8.8939e-02,  ..., -1.2005e-02,\n",
      "         -9.7056e-03,  2.0286e-03],\n",
      "        ...,\n",
      "        [-1.2601e-01, -1.2774e-01, -1.6399e-01,  ...,  5.6293e-02,\n",
      "          7.3997e-02, -1.7623e-03],\n",
      "        [ 6.7218e-04,  7.6284e-02,  1.6413e-01,  ...,  1.6735e-01,\n",
      "         -6.7303e-02, -6.4638e-02],\n",
      "        [-1.6173e-02, -7.3387e-02, -1.1623e-04,  ..., -1.0812e-01,\n",
      "          5.0720e-02, -1.2220e-01]])), ('6.bias', tensor([-0.0294,  0.0823,  0.1139,  0.1187, -0.0755, -0.0560,  0.0051,  0.0147,\n",
      "         0.0089,  0.1343,  0.0326,  0.0200,  0.1095, -0.0368,  0.0244,  0.0147,\n",
      "         0.0259,  0.0757, -0.0009, -0.0687, -0.0237,  0.1519,  0.1176,  0.0262,\n",
      "         0.0493, -0.0346,  0.0031, -0.0331, -0.0359, -0.0385,  0.0525, -0.0464,\n",
      "         0.0525,  0.0688,  0.0746,  0.1293, -0.0016, -0.0294, -0.0378,  0.0960,\n",
      "        -0.0155,  0.0619,  0.0521,  0.0941, -0.0077,  0.0234, -0.0668,  0.0500,\n",
      "         0.0203,  0.0516, -0.0144, -0.0718,  0.0965,  0.1099,  0.0306, -0.0627,\n",
      "         0.0437,  0.1318, -0.0293,  0.0832,  0.0170, -0.0090, -0.0650,  0.1893])), ('9.weight', tensor([[-9.6290e-02, -1.3258e-01, -8.7186e-02, -1.0907e-01, -1.5673e-01,\n",
      "          8.1905e-02, -5.8897e-02, -9.1020e-02,  3.9074e-02,  5.3010e-02,\n",
      "         -1.9476e-01,  9.5412e-02,  1.9982e-02,  9.3282e-02,  2.8000e-02,\n",
      "          4.4400e-02,  6.6623e-02,  4.9247e-02, -3.4384e-02, -7.2358e-02,\n",
      "          8.6819e-02,  1.2543e-02,  7.8896e-02,  1.2547e-01, -4.8052e-02,\n",
      "          9.4385e-02, -1.2029e-01, -8.9305e-02, -1.3470e-01, -1.5213e-01,\n",
      "          1.0081e-01, -1.5949e-01,  9.2761e-02,  3.6099e-02,  9.2145e-02,\n",
      "         -3.3487e-02,  5.8893e-02,  8.1415e-02, -4.6240e-02, -4.4576e-02,\n",
      "         -1.1621e-01,  5.0285e-02,  8.3130e-02, -1.3157e-01,  9.5474e-02,\n",
      "          3.5050e-02, -1.1450e-01,  7.5207e-02, -1.8076e-02, -4.6408e-02,\n",
      "          6.2409e-02, -1.3175e-02, -1.5795e-01, -4.3468e-02, -6.8000e-02,\n",
      "          1.3760e-02, -1.0090e-01,  1.0520e-02, -4.1695e-02, -1.2313e-01,\n",
      "         -8.3159e-02, -5.6531e-02,  5.6615e-02,  5.9973e-02],\n",
      "        [ 7.1416e-02, -8.3931e-02, -1.4999e-01, -9.5918e-02,  1.2114e-01,\n",
      "          6.2775e-02, -6.9773e-03, -1.2578e-01, -1.8640e-01,  6.1290e-02,\n",
      "          3.2622e-02, -1.8543e-01, -2.9967e-02, -4.9480e-02, -6.9708e-02,\n",
      "          6.6239e-03, -2.0850e-01, -4.8207e-03,  6.4832e-02, -1.7073e-01,\n",
      "         -1.5248e-02, -1.7130e-01,  9.8841e-02, -2.5993e-02, -3.0298e-02,\n",
      "          1.3111e-01, -1.4341e-01, -8.3435e-02, -6.5278e-02, -2.7373e-01,\n",
      "         -1.3242e-01,  2.6511e-02,  1.2410e-01, -2.1577e-01,  4.2768e-02,\n",
      "         -1.7951e-01, -1.0298e-01,  4.8853e-02, -1.9543e-01, -7.5096e-02,\n",
      "          9.8496e-02, -1.4906e-01,  8.1415e-02,  7.8582e-02, -1.2621e-01,\n",
      "          5.8128e-02,  1.2378e-01, -9.1667e-02,  9.7862e-02, -8.9879e-02,\n",
      "          7.6107e-02,  9.5542e-02, -1.0603e-01, -7.6868e-02, -1.2126e-01,\n",
      "          7.0941e-02,  1.5294e-01, -1.9096e-01, -2.1554e-01, -1.9311e-01,\n",
      "         -9.2571e-02,  7.4255e-02,  1.0601e-01, -8.7786e-02],\n",
      "        [ 9.3008e-02,  4.7331e-02, -1.5464e-03,  1.1366e-01, -7.4621e-02,\n",
      "          5.3617e-02, -6.1243e-02,  1.0415e-01, -1.8168e-01,  7.0292e-02,\n",
      "          7.6815e-02,  8.7659e-02, -4.2151e-02, -5.2377e-03, -9.0479e-02,\n",
      "         -1.0022e-01,  3.9783e-02,  8.5566e-02, -1.5354e-02, -9.4759e-03,\n",
      "         -1.1870e-02,  1.8760e-02,  1.2489e-01, -8.8964e-02, -1.3614e-01,\n",
      "         -1.3028e-01, -1.4531e-01, -6.7674e-02,  5.1359e-02, -1.7202e-01,\n",
      "          5.5221e-03, -1.3273e-01, -1.5337e-01,  1.8162e-02,  1.0994e-01,\n",
      "         -1.0677e-01, -1.4035e-02, -1.0385e-01, -8.6859e-02,  5.2062e-02,\n",
      "         -1.3462e-02,  4.1651e-02, -1.3533e-01,  4.8903e-02,  1.0288e-01,\n",
      "          1.0292e-01, -1.2647e-01, -9.3699e-02, -5.4412e-02, -1.0472e-01,\n",
      "         -4.7063e-02,  8.8008e-02, -1.1451e-01, -4.7884e-02, -1.8338e-01,\n",
      "         -1.1930e-02, -9.1963e-02,  1.1815e-01, -2.1794e-01,  8.2699e-02,\n",
      "         -1.1827e-01,  3.5981e-02, -1.1086e-01,  4.8546e-02],\n",
      "        [-7.1939e-02, -7.6700e-02,  1.0041e-01, -1.2009e-01, -1.4825e-01,\n",
      "         -7.5404e-02, -1.5200e-01,  2.6522e-02,  4.9608e-03,  3.3485e-02,\n",
      "         -2.1566e-02, -1.0739e-01,  1.0757e-01,  6.6557e-02,  9.6821e-02,\n",
      "         -6.1385e-02, -7.4928e-02,  6.5977e-02,  1.3149e-01, -2.5354e-01,\n",
      "          1.3687e-01,  2.3155e-02,  3.5695e-02,  5.1275e-02,  1.1769e-01,\n",
      "          1.2490e-01, -6.3704e-02, -1.6428e-01, -1.6244e-01, -1.9245e-01,\n",
      "          6.0573e-03, -5.7233e-02,  1.1455e-01, -1.6349e-01,  2.9709e-02,\n",
      "         -1.0158e-01, -6.4530e-02, -9.3483e-02, -2.4063e-01, -2.6152e-03,\n",
      "          4.5542e-02,  2.2394e-03,  1.1930e-01, -5.3276e-02, -7.3231e-02,\n",
      "          7.4034e-02,  1.3418e-01, -2.3045e-02,  1.1555e-02, -2.7325e-01,\n",
      "          6.2278e-02, -3.9896e-02,  5.7264e-02,  1.4134e-02,  3.2377e-02,\n",
      "          1.0987e-01, -3.7498e-02, -7.5184e-02,  1.1986e-02,  1.0402e-01,\n",
      "         -1.2565e-01,  7.1137e-02, -4.6554e-02,  6.8666e-02],\n",
      "        [ 5.9701e-02,  7.0029e-02,  8.8363e-02,  8.6606e-02, -3.7731e-02,\n",
      "          3.2672e-02, -3.8140e-03,  9.8403e-02, -8.0044e-02,  8.5610e-02,\n",
      "          6.8538e-02,  6.3538e-02, -1.4580e-01, -9.2738e-02,  3.4113e-02,\n",
      "          6.7538e-02,  5.0480e-02, -5.7523e-02,  1.0432e-01,  4.2485e-03,\n",
      "         -1.2177e-01,  6.0774e-02, -8.5711e-02,  6.6401e-02, -9.7765e-02,\n",
      "          5.7525e-02, -1.3633e-01, -1.9662e-01, -6.1381e-02, -2.0332e-01,\n",
      "         -1.7784e-01, -1.1425e-01, -9.9450e-02, -1.7931e-01, -6.2840e-02,\n",
      "         -1.1198e-01,  7.0863e-02, -1.8820e-01,  3.6205e-02, -1.0027e-01,\n",
      "          4.6111e-02, -2.2024e-01,  7.7875e-02,  4.6559e-04,  8.2028e-02,\n",
      "          1.2016e-01, -1.4353e-01, -1.9955e-01,  4.7539e-02, -1.3882e-01,\n",
      "         -4.8186e-02, -1.0136e-01,  3.3076e-02,  1.2384e-02, -5.9924e-02,\n",
      "         -6.1011e-02, -1.5107e-01, -5.5874e-02, -2.2160e-01,  1.1698e-01,\n",
      "         -6.4422e-02,  4.1672e-02, -2.0208e-01,  8.4244e-03],\n",
      "        [-1.4049e-01, -5.5585e-03,  7.4961e-02, -1.2847e-01,  1.1058e-01,\n",
      "          5.7836e-02,  1.5932e-02, -2.2940e-02,  3.1654e-03, -1.9052e-01,\n",
      "          6.3212e-02, -1.7397e-01,  9.5210e-02, -3.2885e-02, -1.8914e-01,\n",
      "          9.7367e-03, -2.6982e-01, -2.0727e-02, -1.8332e-01,  8.8186e-02,\n",
      "          6.6013e-04, -1.3434e-01,  1.3477e-01, -2.1602e-01,  1.2854e-02,\n",
      "         -2.6095e-01,  1.1191e-01,  4.5590e-02, -8.2291e-02,  5.3742e-02,\n",
      "          8.3926e-02,  1.0942e-02, -1.5419e-02,  1.1488e-01, -3.2335e-01,\n",
      "          2.7156e-02, -1.2982e-02,  6.0294e-02, -1.6787e-02, -1.4779e-01,\n",
      "         -1.2095e-01, -3.3478e-01, -3.1627e-01, -1.3141e-02,  9.1183e-02,\n",
      "         -2.4488e-01,  6.3956e-02,  6.8447e-02,  5.9657e-02, -4.0927e-02,\n",
      "          8.6765e-02, -1.2044e-02,  8.4029e-02, -9.3350e-03,  9.7583e-02,\n",
      "          7.3829e-03, -1.0569e-01, -4.0556e-02, -1.5779e-01, -1.8306e-01,\n",
      "          1.2078e-01, -2.0669e-01,  7.1839e-02, -1.4523e-01],\n",
      "        [-2.5595e-02,  9.5863e-02,  1.0017e-01,  5.5463e-02,  3.0516e-02,\n",
      "          8.5716e-02, -1.7048e-01,  9.6320e-02,  3.9505e-02,  6.2963e-02,\n",
      "         -9.3019e-02,  9.3191e-02,  1.6441e-02, -1.2394e-01,  6.5662e-03,\n",
      "          1.0073e-01,  4.1441e-02,  3.1335e-02, -7.6790e-02, -5.5916e-02,\n",
      "          1.1903e-01,  6.1417e-03,  3.5092e-02,  1.2316e-01, -7.9201e-02,\n",
      "         -5.4857e-02, -1.7534e-01, -1.5592e-01, -5.9001e-02, -2.6758e-01,\n",
      "          5.7256e-02, -9.2056e-04,  5.1574e-02,  5.7372e-02, -4.2858e-02,\n",
      "         -1.4628e-01, -3.6915e-02,  8.1214e-02,  1.0283e-01, -6.3452e-02,\n",
      "         -1.6161e-01,  2.6348e-02, -3.0098e-02, -5.5432e-02, -5.8935e-03,\n",
      "          1.0977e-01, -1.4395e-02,  6.9508e-02, -1.3682e-03, -2.1998e-02,\n",
      "         -5.0461e-02,  4.5233e-02, -1.5710e-01, -5.4831e-02, -9.0636e-02,\n",
      "         -1.0095e-01, -1.2523e-01,  7.8972e-02, -3.3252e-02,  8.4882e-02,\n",
      "         -8.9181e-02, -8.4411e-02, -3.0337e-02,  4.0991e-02],\n",
      "        [-2.2083e-01,  1.1059e-01, -1.0613e-01, -3.7527e-02,  7.0097e-02,\n",
      "          3.5166e-02,  6.8907e-02, -2.3649e-01,  9.8044e-02,  1.8309e-02,\n",
      "          2.2175e-02, -1.4726e-01,  6.1599e-02,  6.2750e-02, -5.2564e-02,\n",
      "         -1.4990e-01, -3.6670e-01, -2.1704e-01, -3.3108e-01, -6.4647e-02,\n",
      "         -8.9012e-02, -3.1081e-01,  4.4855e-02, -2.0260e-01,  8.0815e-02,\n",
      "         -3.4682e-01,  8.5377e-02,  5.6135e-02,  9.1445e-02,  6.5806e-02,\n",
      "         -7.4416e-02,  1.0852e-01, -3.2495e-01,  1.1389e-01, -1.5274e-01,\n",
      "         -4.3355e-02,  1.0635e-01,  1.7159e-03, -1.5228e-01, -2.0082e-01,\n",
      "          1.4359e-02, -5.3108e-01, -2.4339e-01, -2.0755e-03, -1.3760e-01,\n",
      "         -2.2099e-01, -1.2169e-01,  1.8068e-02, -9.4910e-02,  8.3403e-02,\n",
      "         -4.5648e-02, -3.7699e-02,  8.4109e-02,  1.0616e-01,  7.2545e-02,\n",
      "         -7.0414e-02,  3.2907e-02, -1.5637e-01, -4.7229e-02, -1.2104e-01,\n",
      "          1.2420e-01, -3.2036e-01,  6.9894e-02, -3.4248e-02],\n",
      "        [-1.8184e-01, -1.5735e-01,  8.4266e-02,  7.3584e-02, -1.2249e-01,\n",
      "         -5.3354e-02,  8.9682e-02,  2.6798e-02, -1.7222e-01, -5.2879e-02,\n",
      "         -5.7986e-02,  1.0726e-01, -6.3733e-02,  1.5775e-01,  6.8542e-02,\n",
      "          6.3722e-02, -1.3791e-01, -7.9338e-02, -1.6829e-01,  2.2124e-02,\n",
      "          8.3927e-02, -1.1728e-02, -6.3121e-02,  4.6421e-02,  7.8204e-03,\n",
      "         -7.4792e-02, -6.1370e-02, -1.8925e-01,  1.2405e-02, -1.3292e-01,\n",
      "         -8.5325e-02, -1.4218e-01, -1.3629e-01,  8.6831e-02, -1.3824e-01,\n",
      "          9.2855e-02,  1.3393e-01, -1.3611e-01,  1.1944e-01, -1.2666e-01,\n",
      "         -7.8857e-02, -8.1609e-02, -9.8908e-02, -2.4441e-01, -6.7936e-02,\n",
      "         -1.3216e-01, -7.6921e-02, -1.4921e-01,  8.3423e-02,  6.5453e-02,\n",
      "         -6.3166e-02, -1.0269e-02,  8.8826e-02,  1.7025e-01,  4.7478e-02,\n",
      "          1.3483e-02, -4.4136e-02,  8.9867e-02, -2.1287e-01, -2.2058e-01,\n",
      "          9.3829e-02,  1.4975e-02,  8.4485e-02,  5.8296e-02],\n",
      "        [-1.7884e-01, -9.2574e-02, -1.9252e-01,  4.4802e-02, -9.1473e-02,\n",
      "         -1.5487e-01,  4.1162e-02, -1.9472e-01,  3.7310e-02, -1.6760e-01,\n",
      "          1.1250e-01, -5.5428e-02,  5.7675e-02, -1.2097e-01,  3.1338e-03,\n",
      "          2.3052e-02, -2.1660e-01, -1.7187e-01, -2.1197e-01, -9.3301e-02,\n",
      "         -6.8246e-02, -3.5444e-01, -6.6514e-02, -1.0652e-01,  6.5215e-02,\n",
      "         -1.9885e-01,  1.1737e-01,  6.5421e-02,  1.0291e-01,  1.6147e-02,\n",
      "          9.4479e-02,  9.6720e-02, -1.0984e-01,  1.1410e-01, -1.4253e-01,\n",
      "          9.8457e-03,  1.1058e-01,  8.6753e-02, -1.6419e-01, -1.1106e-01,\n",
      "         -1.2587e-01, -2.8568e-01, -2.1443e-01, -1.1912e-01,  9.6955e-02,\n",
      "         -2.2528e-01,  1.2558e-01,  7.8796e-02, -1.5936e-01,  5.2777e-02,\n",
      "         -3.2741e-02, -8.6573e-02,  7.3390e-02, -4.6412e-02, -1.1729e-01,\n",
      "          8.3446e-03,  5.2218e-02, -5.4819e-02, -8.5389e-03, -2.7739e-01,\n",
      "          1.1533e-01, -2.2743e-01,  3.6141e-04, -2.6744e-01]])), ('9.bias', tensor([-0.0565, -0.0279,  0.1148,  0.0852, -0.0270, -0.1219,  0.1397, -0.0573,\n",
      "        -0.0347, -0.0424]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights & Bias \\n\\n\", model3.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
